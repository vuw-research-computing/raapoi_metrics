{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26f3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from plotnine import (\n",
    "    aes,\n",
    "    element_text,\n",
    "    facet_wrap,\n",
    "    geom_bar,\n",
    "    geom_col,\n",
    "    ggplot,\n",
    "    ggsave,\n",
    "    guides,\n",
    "    labs,\n",
    "    scale_fill_gradient,\n",
    "    scale_x_date,\n",
    "    theme,\n",
    ")\n",
    "from mizani.formatters import date_format\n",
    "from typing import Optional\n",
    "\n",
    "def preprocess_data(df):\n",
    "    '''\n",
    "    Load the dataframe\n",
    "    Do some preprocessing of the input data, such as fixing account allocations\n",
    "    '''\n",
    "\n",
    "    # df = pd.read_csv('../dfout_all.csv', dtype={15: str})\n",
    "\n",
    "    #Fix jiaowa account info to ferrier rather than sbs\n",
    "    mask = (df['User'] == 'jiaowa') & (df['Account'] == 'sbs')\n",
    "    df.loc[mask, 'Account'] = 'ferrier'\n",
    "\n",
    "    # Mapping of old account names to new ones\n",
    "    account_mapping = {\n",
    "        'scpslab206': 'scps', \n",
    "        'scpslab306': 'scps',\n",
    "        'spacejam': 'scps',\n",
    "        'phys414': 'scps',\n",
    "        'students': 'scps',\n",
    "        'cad': 'admin',\n",
    "        'root': 'admin'\n",
    "    }\n",
    "\n",
    "    # Replace account names\n",
    "    df['Account'] = df['Account'].replace(account_mapping)\n",
    "\n",
    "    # currently we use a fix usd to nzd exchange rate to calculate aws cost\n",
    "    usd_to_nzd = 1.62\n",
    "    df.aws_cost = df.aws_cost * usd_to_nzd\n",
    "\n",
    "    # set dates as datetime and create columns for month and year\n",
    "    df['Start'] = pd.to_datetime(df['Start'])\n",
    "    df['Submit'] = pd.to_datetime(df['Submit'])\n",
    "    df['End'] = pd.to_datetime(df['End'])\n",
    "    df['Year'] = df['Start'].dt.year\n",
    "    df['Month'] = df['Start'].dt.month\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_plot(df: pd.DataFrame, x_column: str, title: str, subtitle: str, filename: str, width: Optional[int] = 20) -> None:\n",
    "    if x_column == 'Year':\n",
    "        width = 0.7  # A value of 0.7 is commonly used when you have yearly data.\n",
    "    elif x_column == 'YearMonth':\n",
    "        width = 20  # This width can be adjusted based on how wide you want the bars to be.\n",
    "\n",
    "    plot = (\n",
    "        ggplot(df, aes(x=x_column, y='UniqueUsers', fill='UniqueUsers'))\n",
    "        + geom_bar(stat='identity', width=width)\n",
    "        + scale_fill_gradient(low=\"blue\", high=\"red\")\n",
    "        + labs(x='Date', y='Unique Users', title=title, subtitle=subtitle, fill='UniqueUsers')\n",
    "        + theme(axis_text_x=element_text(angle=45, hjust=1),  # rotate x-axis labels 45 degrees\n",
    "                plot_title=element_text(hjust=0.5),  # center title\n",
    "                plot_subtitle=element_text(hjust=0.5))  # center subtitle\n",
    "        + guides(fill=False)  # remove color bar\n",
    "    )\n",
    "\n",
    "    # Save the plot\n",
    "    # ggsave(plot, filename=filename, format='png', dpi=300)\n",
    "    return plot\n",
    "\n",
    "\n",
    "def plot_unique_users_per_month(df):\n",
    "    \n",
    "    # Group by 'Account', 'Year', 'Month' and 'User', then count unique 'User'\n",
    "    unique_users = df.groupby(['Account', 'Year', 'Month', 'User']).size().reset_index().rename(columns={0:'count'})\n",
    "    print(unique_users.head())\n",
    "\n",
    "    # Now group by 'Account', 'Year' and 'Month' and count unique 'User'\n",
    "    unique_users_per_month = unique_users.groupby(['Account', 'Year', 'Month']).size().reset_index().rename(columns={0:'UniqueUsers'})\n",
    "    \n",
    "    # Convert 'Year' and 'Month' to integer, then to string, combine them, and convert to datetime\n",
    "    unique_users_per_month['YearMonth'] = pd.to_datetime(unique_users_per_month['Year'].astype(int).astype(str) + '-' + unique_users_per_month['Month'].astype(int).astype(str))\n",
    "   \n",
    "    # Capitalize 'Account'\n",
    "    unique_users_per_month['Account'] = unique_users_per_month['Account'].str.upper()\n",
    "\n",
    "    accounts = unique_users_per_month['Account'].unique()\n",
    "\n",
    "    # Create the directory if it doesn't already exist\n",
    "    if not os.path.exists('plots/monthly_users'):\n",
    "        os.makedirs('plots/monthly_users')\n",
    "\n",
    "    for account in accounts:\n",
    "        account_data = unique_users_per_month[unique_users_per_month['Account'] == account]\n",
    "        generate_plot(account_data, 'YearMonth', 'R훮poi', f'Unique {account} Users Per Month', f'plots/monthly_users/{account}_users_per_month.png')\n",
    "        \n",
    "    # Produce the total unique users per month\n",
    "    start_time = time.time()\n",
    "    # For the total unique users per month, group the original DataFrame by Year and Month and sum the unique users\n",
    "    total_users_per_month = unique_users_per_month.groupby(['YearMonth'])['UniqueUsers'].sum().reset_index()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Creating total unique users took:', elapsed_time, 'seconds')\n",
    "\n",
    "    generate_plot(total_users_per_month, 'YearMonth', 'R훮poi', 'Total Unique Users Per Month', 'plots/monthly_users/total_users_per_month.png')\n",
    "\n",
    "def plot_unique_users_per_year(df):\n",
    "    unique_users_per_year = df.groupby(['Account', 'Year', 'User']).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "    # Now group by 'Account' and 'Year' and count unique 'User'\n",
    "    unique_users_per_year = unique_users_per_year.groupby(['Account', 'Year']).size().reset_index().rename(columns={0:'UniqueUsers'})\n",
    "    accounts = unique_users_per_year['Account'].unique()\n",
    "\n",
    "    # Create the directory if it doesn't already exist\n",
    "    if not os.path.exists('plots/yearly_users'):\n",
    "        os.makedirs('plots/yearly_users/')\n",
    "\n",
    "    for account in accounts:\n",
    "        account_data = unique_users_per_year[unique_users_per_year['Account'] == account]\n",
    "        generate_plot(account_data, 'Year', 'R훮poi', f'Unique {account} Users Per Year', f'plots/yearly_users/{account}_users_per_year.png')\n",
    "    \n",
    "\n",
    "    # Produce the total unique users per year\n",
    "    start_time = time.time()\n",
    "    # For the total unique users per year, group the original DataFrame by Year and Month and sum the unique users\n",
    "    total_users_per_year = unique_users_per_year.groupby(['Year'])['UniqueUsers'].sum().reset_index()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Creating total unique users took:', elapsed_time, 'seconds')\n",
    "\n",
    "    # For total users\n",
    "    generate_plot(total_users_per_year, 'Year', 'R훮poi', 'Total Unique Users Per Year', 'plots/yearly_users/total_users_per_year.png')\n",
    "\n",
    "\n",
    "\n",
    "def plot_costs_per_year(df):\n",
    "    # Group by 'Account' and 'Year' and sum 'aws_cost' and 'nesi_cost'\n",
    "    cost_per_year = df.groupby(['Account', 'Year']).agg({'aws_cost': 'sum', 'nesi_cost': 'sum'}).reset_index()\n",
    "\n",
    "    # Convert 'Year' to integer, then to string, and convert to datetime\n",
    "    cost_per_year['Year'] = pd.to_datetime(cost_per_year['Year'].astype(int).astype(str))\n",
    "\n",
    "    \n",
    "\n",
    "    # Capitalize 'Account'\n",
    "    cost_per_year['Account'] = cost_per_year['Account'].str.upper()\n",
    "\n",
    "    accounts = cost_per_year['Account'].unique()\n",
    "\n",
    "    # Ensure the directories exist\n",
    "    os.makedirs('plots/yearly_costs/aws/', exist_ok=True)\n",
    "    os.makedirs('plots/yearly_costs/nesi/', exist_ok=True)\n",
    "\n",
    "    for account in accounts:\n",
    "        account_data = cost_per_year[cost_per_year['Account'] == account]\n",
    "\n",
    "        for cost_type in ['aws_cost', 'nesi_cost']:\n",
    "            cost_title = 'AWS cost' if cost_type == 'aws_cost' else 'NeSi cost'\n",
    "            cost_subtitle = 'Based on 2020 best matched instance for given core count' if cost_type == 'aws_cost' else ' '\n",
    "            save_folder = 'plots/yearly_costs/aws/' if cost_type == 'aws_cost' else 'plots/yearly_costs/nesi/'\n",
    "\n",
    "            plot = (\n",
    "                ggplot(account_data, aes(x='Year', y=cost_type, fill=cost_type))\n",
    "                + geom_col()  # using geom_col instead of geom_bar with stat='identity'\n",
    "                + scale_fill_gradient(low = \"blue\", high = \"red\")\n",
    "                + labs(x='Year', y='Cost', title=f'{cost_title} for {account} Per Year', subtitle=cost_subtitle, fill=cost_type)\n",
    "                + theme(axis_text_x = element_text(angle = 45, hjust = 1),  # rotate x-axis labels 45 degrees\n",
    "                        plot_title=element_text(hjust=0.5),  # center title\n",
    "                        plot_subtitle=element_text(hjust=0.5))  # center subtitle\n",
    "                + guides(fill=False)  # remove color bar\n",
    "                + scale_x_date(date_breaks='1 year', labels=date_format('%Y'))  # set x-axis breaks and labels\n",
    "            )\n",
    "            \n",
    "            print(plot)\n",
    "\n",
    "            # Save the plot\n",
    "            # plot.save(f\"{save_folder}{account}_{cost_type}.png\")\n",
    "\n",
    "\n",
    "def plot_costs_per_month(df):\n",
    "    # Group by 'Account', 'Year' and 'Month' and sum 'aws_cost' and 'nesi_cost'\n",
    "    cost_per_month = df.groupby(['Account', 'Year', 'Month']).agg({'aws_cost': 'sum', 'nesi_cost': 'sum'}).reset_index()\n",
    "\n",
    "    # Convert 'Year' and 'Month' to integer, then to string, combine them, and convert to datetime\n",
    "    cost_per_month['YearMonth'] = pd.to_datetime(cost_per_month['Year'].astype(int).astype(str) + '-' + cost_per_month['Month'].astype(int).astype(str))\n",
    "\n",
    "    accounts = cost_per_month['Account'].unique()\n",
    "\n",
    "    # Capitalize 'Account'\n",
    "    cost_per_month['Account'] = cost_per_month['Account'].str.upper()\n",
    "\n",
    "    # Ensure the directories exist\n",
    "    os.makedirs('plots/monthly_costs/aws/', exist_ok=True)\n",
    "    os.makedirs('plots/monthly_costs/nesi/', exist_ok=True)\n",
    "\n",
    "    for account in accounts:\n",
    "        account_data = cost_per_month[cost_per_month['Account'] == account]\n",
    "\n",
    "        for cost_type in ['aws_cost', 'nesi_cost']:\n",
    "            cost_title = 'AWS cost' if cost_type == 'aws_cost' else 'NeSi cost'\n",
    "            cost_subtitle = 'Based on 2020 best matched instance for given core count' if cost_type == 'aws_cost' else ' '\n",
    "            save_folder = 'plots/monthly_costs/aws/' if cost_type == 'aws_cost' else 'plots/monthly_costs/nesi/'\n",
    "\n",
    "            plot = (\n",
    "                ggplot(account_data, aes(x='YearMonth', y=cost_type, fill=cost_type))\n",
    "                + geom_bar(stat='identity', width=20)  # adjust the width as needed\n",
    "                + scale_fill_gradient(low = \"blue\", high = \"red\")\n",
    "                + labs(x='Date', y='Cost', title=f'{cost_title} for {account} Per Month', subtitle=cost_subtitle, fill=cost_type)\n",
    "                + theme(axis_text_x = element_text(angle = 45, hjust = 1),  # rotate x-axis labels 45 degrees\n",
    "                        plot_title=element_text(hjust=0.5),  # center title\n",
    "                        plot_subtitle=element_text(hjust=0.5))  # center subtitle\n",
    "                + guides(fill=False)  # remove color bar\n",
    "            )\n",
    "            \n",
    "            print(plot)\n",
    "\n",
    "            # Save the plot\n",
    "        # plot.save(f\"{save_folder}{account}_{cost_type}.png\")\n",
    "\n",
    "############################################################\n",
    "# Plot wait times for jobs to start from submit time with y axis as time in seconds and x axis as the number of jobs\n",
    "import pandas as pd\n",
    "from plotnine import (\n",
    "    ggplot,\n",
    "    aes,\n",
    "    geom_bar,\n",
    "    geom_col, # geom_col is suitable for pre-summarized data\n",
    "    scale_fill_gradient,\n",
    "    labs,\n",
    "    theme,\n",
    "    element_text,\n",
    "    guides,\n",
    ")\n",
    "import os # Import os for directory creation\n",
    "\n",
    "def plot_submit_start_time(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Orchestrates plotting of:\n",
    "    1. Total wait time per month for each account (jobs >= 4 hours wait time).\n",
    "    2. Total wait time for each unique job (jobs >= 4 hours wait time).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'Start', 'Submit', 'Account', and 'JobID' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a copy to avoid modifying the original DataFrame passed into the function\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # --- Plotting Wait Time Per Account Per Month ---\n",
    "\n",
    "    # Ensure 'Start' and 'Submit' columns are datetime objects\n",
    "    df_copy['Start'] = pd.to_datetime(df_copy['Start'], errors='coerce')\n",
    "    df_copy['Submit'] = pd.to_datetime(df_copy['Submit'], errors='coerce')\n",
    "\n",
    "    # Drop rows where 'Start' or 'Submit' could not be converted to datetime\n",
    "    df_copy.dropna(subset=['Start', 'Submit'], inplace=True)\n",
    "\n",
    "    # Calculate the difference between 'Start' and 'Submit' in seconds\n",
    "    df_copy['WaitTime'] = (df_copy['Start'] - df_copy['Submit']).dt.total_seconds()\n",
    "\n",
    "    # Only keep rows where 'WaitTime' is greater than or equal to 4 hours (14400 seconds)\n",
    "    df_filtered_accounts = df_copy[df_copy['WaitTime'] >= 14400]\n",
    "\n",
    "    if df_filtered_accounts.empty:\n",
    "        print(\"No data meets the criteria (WaitTime >= 4 hours) for per-account plotting.\")\n",
    "    else:\n",
    "        # Convert 'WaitTime' from seconds to hours for better readability on the plot\n",
    "        df_filtered_accounts['WaitTime'] = df_filtered_accounts['WaitTime'] / 3600\n",
    "\n",
    "        # Extract Year and Month from the 'Submit' time\n",
    "        df_filtered_accounts['Year'] = df_filtered_accounts['Submit'].dt.year\n",
    "        df_filtered_accounts['Month'] = df_filtered_accounts['Submit'].dt.month\n",
    "\n",
    "        # Group by 'Account', 'Year', and 'Month' and sum the 'WaitTime'\n",
    "        wait_time_per_month = df_filtered_accounts.groupby(['Account', 'Year', 'Month']).agg(\n",
    "            WaitTime=('WaitTime', 'sum')\n",
    "        ).reset_index()\n",
    "\n",
    "        # Create 'YearMonth' column as a datetime object for chronological plotting\n",
    "        wait_time_per_month['YearMonth'] = pd.to_datetime(\n",
    "            wait_time_per_month['Year'].astype(str)\n",
    "            + '-'\n",
    "            + wait_time_per_month['Month'].astype(str)\n",
    "            + '-01'\n",
    "        )\n",
    "\n",
    "        # Get a list of unique accounts to iterate through and generate a plot for each\n",
    "        accounts = wait_time_per_month['Account'].unique()\n",
    "\n",
    "        # Create the directory for saving plots if it doesn't exist\n",
    "        plots_dir_accounts = \"plots/wait_times_per_account\"\n",
    "        os.makedirs(plots_dir_accounts, exist_ok=True)\n",
    "\n",
    "        # Loop through each unique account to create and save a plot\n",
    "        for account in accounts:\n",
    "            account_data = wait_time_per_month[\n",
    "                wait_time_per_month['Account'] == account\n",
    "            ].copy()\n",
    "\n",
    "            plot_account = (\n",
    "                ggplot(account_data, aes(x='YearMonth', y='WaitTime', fill='WaitTime'))\n",
    "                + geom_bar(stat='identity', width=20)\n",
    "                + scale_fill_gradient(low=\"blue\", high=\"red\")\n",
    "                + labs(\n",
    "                    x='Date',\n",
    "                    y='Wait Time (hours)',\n",
    "                    title=f'Wait Time for {account} Per Month',\n",
    "                    subtitle='Total Wait Time Per Month (Jobs >= 4 hours Wait Time)',\n",
    "                    fill='WaitTime'\n",
    "                )\n",
    "                + theme(\n",
    "                    axis_text_x=element_text(angle=45, hjust=1),\n",
    "                    plot_title=element_text(hjust=0.5),\n",
    "                    plot_subtitle=element_text(hjust=0.5)\n",
    "                )\n",
    "                + guides(fill=False)\n",
    "            )\n",
    "\n",
    "            print(f\"Generating plot for account: {account}\")\n",
    "            print(plot_account)\n",
    "            plot_filename_account = os.path.join(plots_dir_accounts, f\"{account}_wait_time_per_month.png\")\n",
    "            # plot_account.save(plot_filename_account)\n",
    "            print(f\"Saved plot: {plot_filename_account}\")\n",
    "\n",
    "\n",
    "    # --- Plotting Total Wait Time Per Job ---\n",
    "\n",
    "    # We reuse the df_copy that has already been converted to datetime and dropped NaT\n",
    "    # Calculate the difference between 'Start' and 'Submit' in seconds\n",
    "    # (re-calculate if df_filtered_accounts modified df_copy, but here it's on a copy)\n",
    "    df_copy['WaitTime'] = (df_copy['Start'] - df_copy['Submit']).dt.total_seconds()\n",
    "\n",
    "    # Only keep rows where 'WaitTime' is greater than or equal to 4 hours (14400 seconds)\n",
    "    df_filtered_jobs = df_copy[df_copy['WaitTime'] >= 14400]\n",
    "\n",
    "    if df_filtered_jobs.empty:\n",
    "        print(\"No data meets the criteria (WaitTime >= 4 hours) to plot total wait time per job.\")\n",
    "        return\n",
    "\n",
    "    # Convert 'WaitTime' from seconds to hours for better readability\n",
    "    df_filtered_jobs['WaitTime'] = df_filtered_jobs['WaitTime'] / 3600\n",
    "\n",
    "    # Group by 'JobID' and sum the 'WaitTime'\n",
    "    total_wait_time_per_job = df_filtered_jobs.groupby('JobID').agg(\n",
    "        TotalWaitTime=('WaitTime', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    if total_wait_time_per_job.empty:\n",
    "        print(\"No job data after aggregation to plot total wait time per job.\")\n",
    "        return\n",
    "\n",
    "    # --- IMPORTANT FIX: Order the 'JobID' categories explicitly ---\n",
    "    # Sort the DataFrame by TotalWaitTime in ascending order\n",
    "    total_wait_time_per_job = total_wait_time_per_job.sort_values(\n",
    "        by='TotalWaitTime', ascending=True\n",
    "    )\n",
    "    # Convert 'JobID' column to an ordered categorical type based on the sorted order.\n",
    "    # plotnine will then respect this order on the x-axis, achieving the 'reorder' effect.\n",
    "    total_wait_time_per_job['JobID'] = pd.Categorical(\n",
    "        total_wait_time_per_job['JobID'],\n",
    "        categories=total_wait_time_per_job['JobID'], # Use the current order as the categories\n",
    "        ordered=True\n",
    "    )\n",
    "\n",
    "    # Create the directory for saving plots if it doesn't exist\n",
    "    plots_dir_jobs = \"plots/total_job_wait_times\"\n",
    "    os.makedirs(plots_dir_jobs, exist_ok=True)\n",
    "\n",
    "    # Create the plot using plotnine\n",
    "    plot_jobs = (\n",
    "        ggplot(total_wait_time_per_job, aes(x='JobID', y='TotalWaitTime', fill='TotalWaitTime'))\n",
    "        + geom_col(width=0.7)\n",
    "        + scale_fill_gradient(low=\"blue\", high=\"red\")\n",
    "        + labs(\n",
    "            x='Job ID',\n",
    "            y='Total Wait Time (hours)',\n",
    "            title='Total Wait Time Per Job',\n",
    "            subtitle='Sum of Wait Times (Jobs >= 4 hours Wait Time)',\n",
    "            fill='TotalWaitTime'\n",
    "        )\n",
    "        + theme(\n",
    "            axis_text_x=element_text(angle=90, hjust=1),\n",
    "            plot_title=element_text(hjust=0.5),\n",
    "            plot_subtitle=element_text(hjust=0.5)\n",
    "        )\n",
    "        + guides(fill=False)\n",
    "    )\n",
    "\n",
    "    print(\"Generating plot for total wait time per job:\")\n",
    "    print(plot_jobs)\n",
    "    plot_filename_jobs = os.path.join(plots_dir_jobs, \"total_wait_time_per_job.png\")\n",
    "    # plot_jobs.save(plot_filename_jobs)\n",
    "    print(f\"Saved plot: {plot_filename_jobs}\")\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "\n",
    "\n",
    "##################################\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import (\n",
    "    ggplot,\n",
    "    aes,\n",
    "    geom_col,\n",
    "    scale_fill_gradient,\n",
    "    labs,\n",
    "    theme,\n",
    "    element_text,\n",
    "    guides,\n",
    ")\n",
    "import os\n",
    "import concurrent.futures\n",
    "import traceback\n",
    "\n",
    "def _process_df_chunk(chunk_df):\n",
    "    \"\"\"\n",
    "    Helper function to process a chunk of the DataFrame in parallel.\n",
    "    Performs datetime conversion, wait time calculation, and initial filtering.\n",
    "\n",
    "    Args:\n",
    "        chunk_df (pd.DataFrame): A chunk of the original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed chunk with 'WaitTime' and relevant columns, or an empty DataFrame if no data meets criteria.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Explicitly create a deep copy to prevent SettingWithCopyWarning\n",
    "        chunk_df = chunk_df.copy(deep=True)\n",
    "\n",
    "        # Ensure 'Start' and 'Submit' columns are datetime objects\n",
    "        chunk_df['Start'] = pd.to_datetime(chunk_df['Start'], errors='coerce')\n",
    "        chunk_df['Submit'] = pd.to_datetime(chunk_df['Submit'], errors='coerce')\n",
    "\n",
    "        # Drop rows where 'Start' or 'Submit' could not be converted to datetime (i.e., they are NaT)\n",
    "        chunk_df.dropna(subset=['Start', 'Submit'], inplace=True)\n",
    "\n",
    "        # Calculate the difference between 'Start' and 'Submit' in seconds\n",
    "        chunk_df['WaitTime'] = (chunk_df['Start'] - chunk_df['Submit']).dt.total_seconds()\n",
    "\n",
    "        # Only keep rows where 'WaitTime' is greater than or equal to 4 hours (14400 seconds)\n",
    "        chunk_df = chunk_df[chunk_df['WaitTime'] >= 14400]\n",
    "\n",
    "        # Convert 'WaitTime' from seconds to hours for better readability\n",
    "        chunk_df['WaitTime'] = chunk_df['WaitTime'] / 3600\n",
    "\n",
    "        # Select only the necessary columns ('JobID' and 'WaitTime')\n",
    "        # This reduces memory usage when returning processed chunks\n",
    "        return chunk_df[['JobID', 'WaitTime']]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing DataFrame chunk: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return pd.DataFrame() # Return empty DataFrame on error\n",
    "\n",
    "\n",
    "def plot_total_wait_time_per_jobid_multiprocessed(df, num_chunks=None, plot_dpi=150):\n",
    "    \"\"\"\n",
    "    Plots the total wait time for each unique JobID, using multiprocessing\n",
    "    for faster data preprocessing and aggregation.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'Start', 'Submit', and 'JobID' columns.\n",
    "        num_chunks (int, optional): Number of chunks to split the DataFrame into for\n",
    "                                    parallel processing. If None, defaults to os.cpu_count().\n",
    "        plot_dpi (int, optional): Resolution of the saved plot image in dots per inch.\n",
    "                                  Lower values (e.g., 96, 150) result in smaller files and faster saving.\n",
    "                                  Defaults to 150.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Starting data preprocessing with multiprocessing...\")\n",
    "\n",
    "    if num_chunks is None:\n",
    "        num_chunks = os.cpu_count() # Use all available CPU cores by default\n",
    "\n",
    "    # Split the DataFrame into chunks for parallel processing\n",
    "    # Using numpy.array_split for more even distribution, especially for smaller DataFrames\n",
    "    df_chunks = [chunk for chunk in np.array_split(df, num_chunks) if not chunk.empty]\n",
    "\n",
    "    processed_chunks = []\n",
    "    # Use ProcessPoolExecutor to parallelize chunk processing\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=num_chunks) as executor:\n",
    "        futures = [executor.submit(_process_df_chunk, chunk) for chunk in df_chunks]\n",
    "\n",
    "        for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "            try:\n",
    "                processed_chunk = future.result()\n",
    "                if not processed_chunk.empty:\n",
    "                    processed_chunks.append(processed_chunk)\n",
    "                print(f\"Finished processing chunk {i+1}/{len(df_chunks)}.\")\n",
    "            except Exception as exc:\n",
    "                print(f'A chunk processing generated an exception: {exc}')\n",
    "                traceback.print_exc()\n",
    "\n",
    "    # Concatenate all processed chunks back into a single DataFrame\n",
    "    if not processed_chunks:\n",
    "        print(\"No data remained after multiprocessing and filtering. No plot will be generated.\")\n",
    "        return\n",
    "\n",
    "    combined_df = pd.concat(processed_chunks).reset_index(drop=True)\n",
    "\n",
    "    # If no data remains after filtering in any chunk, print a message and exit\n",
    "    if combined_df.empty:\n",
    "        print(\"No data meets the criteria (WaitTime >= 4 hours) after initial filtering and combining. No plot will be generated.\")\n",
    "        return\n",
    "\n",
    "    print(\"Finished parallel data preprocessing. Starting aggregation...\")\n",
    "\n",
    "    # Group by 'JobID' and sum the 'WaitTime'\n",
    "    total_wait_time_per_jobid = combined_df.groupby('JobID').agg(\n",
    "        TotalWaitTime=('WaitTime', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # If total_wait_time_per_jobid is empty after aggregation, print a message and exit\n",
    "    if total_wait_time_per_jobid.empty:\n",
    "        print(\"No JobID data after aggregation to plot total wait time per JobID.\")\n",
    "        return\n",
    "\n",
    "    # Order the 'JobID' categories explicitly by 'TotalWaitTime' for plotting\n",
    "    total_wait_time_per_jobid = total_wait_time_per_jobid.sort_values(\n",
    "        by='TotalWaitTime', ascending=True\n",
    "    )\n",
    "    total_wait_time_per_jobid['JobID'] = pd.Categorical(\n",
    "        total_wait_time_per_jobid['JobID'],\n",
    "        categories=total_wait_time_per_jobid['JobID'],\n",
    "        ordered=True\n",
    "    )\n",
    "\n",
    "    # Create the directory for saving plots if it doesn't exist\n",
    "    plots_dir = \"plots/total_jobid_wait_times\"\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Generating plot with DPI: {plot_dpi}...\")\n",
    "    # Create the plot using plotnine (this part remains single-threaded as it's one plot)\n",
    "    plot = (\n",
    "        ggplot(total_wait_time_per_jobid, aes(x='JobID', y='TotalWaitTime', fill='TotalWaitTime'))\n",
    "        + geom_col(width=0.7)\n",
    "        + scale_fill_gradient(low=\"blue\", high=\"red\")\n",
    "        + labs(\n",
    "            x='JobID',\n",
    "            y='Total Wait Time (hours)',\n",
    "            title='Total Wait Time Per Unique JobID',\n",
    "            subtitle='Sum of Wait Times (>= 4 hours) for Each JobID',\n",
    "            fill='TotalWaitTime'\n",
    "        )\n",
    "        + theme(\n",
    "            axis_text_x=element_text(angle=90, hjust=1),\n",
    "            plot_title=element_text(hjust=0.5),\n",
    "            plot_subtitle=element_text(hjust=0.5)\n",
    "        )\n",
    "        + guides(fill=False)\n",
    "    )\n",
    "\n",
    "    # Save the generated plot to a file, using the specified DPI\n",
    "    plot_filename = os.path.join(plots_dir, \"total_wait_time_per_jobid.png\")\n",
    "    # plot.save(plot_filename, dpi=plot_dpi) # Added dpi parameter\n",
    "    print(f\"Successfully saved plot: {plot_filename}\")\n",
    "\n",
    "#########################\n",
    "\n",
    "\n",
    "#########################\n",
    "\n",
    "'''\n",
    "Each unique user and wait time for their jobs \n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import (\n",
    "    ggplot,\n",
    "    aes,\n",
    "    geom_col,\n",
    "    scale_fill_gradient,\n",
    "    labs,\n",
    "    theme,\n",
    "    element_text,\n",
    "    guides,\n",
    ")\n",
    "import os\n",
    "import concurrent.futures\n",
    "import traceback\n",
    "\n",
    "def _process_df_chunk(chunk_df):\n",
    "    \"\"\"\n",
    "    Helper function to process a chunk of the DataFrame in parallel.\n",
    "    Performs datetime conversion, wait time calculation, and initial filtering.\n",
    "\n",
    "    Args:\n",
    "        chunk_df (pd.DataFrame): A chunk of the original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed chunk with 'Account', 'JobID', 'WaitTime',\n",
    "                      or an empty DataFrame if no data meets criteria.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Explicitly create a deep copy to prevent SettingWithCopyWarning\n",
    "        chunk_df = chunk_df.copy(deep=True)\n",
    "\n",
    "        # Ensure 'Start' and 'Submit' columns are datetime objects\n",
    "        chunk_df['Start'] = pd.to_datetime(chunk_df['Start'], errors='coerce')\n",
    "        chunk_df['Submit'] = pd.to_datetime(chunk_df['Submit'], errors='coerce')\n",
    "\n",
    "        # Drop rows where 'Start' or 'Submit' could not be converted to datetime (i.e., they are NaT)\n",
    "        chunk_df.dropna(subset=['Start', 'Submit'], inplace=True)\n",
    "\n",
    "        # Calculate the difference between 'Start' and 'Submit' in seconds\n",
    "        chunk_df['WaitTime'] = (chunk_df['Start'] - chunk_df['Submit']).dt.total_seconds()\n",
    "\n",
    "        # Only keep rows where 'WaitTime' is greater than or equal to 4 hours (14400 seconds)\n",
    "        chunk_df = chunk_df[chunk_df['WaitTime'] >= 14400]\n",
    "\n",
    "        # Convert 'WaitTime' from seconds to hours for better readability\n",
    "        chunk_df['WaitTime'] = chunk_df['WaitTime'] / 3600\n",
    "\n",
    "        # Select only the necessary columns ('Account', 'JobID', and 'WaitTime')\n",
    "        return chunk_df[['Account', 'JobID', 'WaitTime']]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing DataFrame chunk: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return pd.DataFrame() # Return empty DataFrame on error\n",
    "\n",
    "def _plot_single_user_jobs(user_data_for_plot, account_name, base_plots_dir, plot_dpi):\n",
    "    \"\"\"\n",
    "    Helper function to plot and save a single user's job wait time data.\n",
    "    This function will be executed in a separate process.\n",
    "\n",
    "    Args:\n",
    "        user_data_for_plot (pd.DataFrame): DataFrame containing wait time data for a single user's jobs.\n",
    "        account_name (str): The account name for the current plot.\n",
    "        base_plots_dir (str): The base directory where plots should be saved.\n",
    "        plot_dpi (int): Resolution of the saved plot image in dots per inch.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if user_data_for_plot.empty:\n",
    "            print(f\"No valid data for Account: {account_name}. Skipping plot.\")\n",
    "            return\n",
    "\n",
    "        # Ensure JobID is ordered by TotalWaitTime for consistent plotting\n",
    "        user_data_for_plot = user_data_for_plot.sort_values(\n",
    "            by='TotalWaitTime', ascending=True\n",
    "        )\n",
    "        user_data_for_plot['JobID'] = pd.Categorical(\n",
    "            user_data_for_plot['JobID'],\n",
    "            categories=user_data_for_plot['JobID'],\n",
    "            ordered=True\n",
    "        )\n",
    "\n",
    "        # Define a specific directory for each account to keep plots organized\n",
    "        account_plots_dir = os.path.join(base_plots_dir, str(account_name))\n",
    "        os.makedirs(account_plots_dir, exist_ok=True)\n",
    "\n",
    "        # Create the plot using plotnine\n",
    "        plot = (\n",
    "            ggplot(user_data_for_plot, aes(x='JobID', y='TotalWaitTime', fill='TotalWaitTime'))\n",
    "            + geom_col(width=0.7)\n",
    "            + scale_fill_gradient(low=\"blue\", high=\"red\")\n",
    "            + labs(\n",
    "                x='JobID',\n",
    "                y='Total Wait Time (hours)',\n",
    "                title=f'Total Wait Time for Jobs by User: {account_name}',\n",
    "                subtitle='Sum of Wait Times (>= 4 hours) for Each JobID',\n",
    "                fill='TotalWaitTime'\n",
    "            )\n",
    "            + theme(\n",
    "                axis_text_x=element_text(angle=90, hjust=1), # Rotate x-axis labels\n",
    "                plot_title=element_text(hjust=0.5),\n",
    "                plot_subtitle=element_text(hjust=0.5)\n",
    "            )\n",
    "            + guides(fill=False)\n",
    "        )\n",
    "\n",
    "        # Sanitize account name for filename to avoid issues with special characters\n",
    "        sanitized_account_name = (\n",
    "            str(account_name)\n",
    "            .replace('/', '_')\n",
    "            .replace('\\\\', '_')\n",
    "            .replace(':', '_')\n",
    "            .replace('*', '_')\n",
    "            .replace('?', '_')\n",
    "            .replace('\"', '_')\n",
    "            .replace('<', '_')\n",
    "            .replace('>', '_')\n",
    "            .replace('|', '_')\n",
    "        )\n",
    "        plot_filename = os.path.join(account_plots_dir, f\"{sanitized_account_name}_jobs_wait_time.png\")\n",
    "        # plot.save(plot_filename, dpi=plot_dpi)\n",
    "        print(f\"Successfully saved plot for User: {account_name} to {plot_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting for User: {account_name}: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "def plot_jobs_per_user_wait_times_multiprocessed(df, num_chunks=None, plot_dpi=150):\n",
    "    \"\"\"\n",
    "    Plots the total wait time for each JobID, grouped by unique user (Account),\n",
    "    using multiprocessing for faster data preprocessing and plot generation.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'Start', 'Submit', 'Account', and 'JobID' columns.\n",
    "        num_chunks (int, optional): Number of chunks to split the DataFrame into for\n",
    "                                    parallel processing. If None, defaults to os.cpu_count().\n",
    "        plot_dpi (int, optional): Resolution of the saved plot image in dots per inch.\n",
    "                                  Defaults to 150.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Starting initial data preprocessing with multiprocessing...\")\n",
    "\n",
    "    if num_chunks is None:\n",
    "        num_chunks = os.cpu_count()\n",
    "\n",
    "    df_chunks = [chunk for chunk in np.array_split(df, num_chunks) if not chunk.empty]\n",
    "\n",
    "    processed_chunks = []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=num_chunks) as executor:\n",
    "        futures = [executor.submit(_process_df_chunk, chunk) for chunk in df_chunks]\n",
    "\n",
    "        for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "            try:\n",
    "                processed_chunk = future.result()\n",
    "                if not processed_chunk.empty:\n",
    "                    processed_chunks.append(processed_chunk)\n",
    "                print(f\"Finished processing chunk {i+1}/{len(df_chunks)}.\")\n",
    "            except Exception as exc:\n",
    "                print(f'A chunk processing generated an exception: {exc}')\n",
    "                traceback.print_exc()\n",
    "\n",
    "    if not processed_chunks:\n",
    "        print(\"No data remained after multiprocessing and initial filtering. No plots will be generated.\")\n",
    "        return\n",
    "\n",
    "    combined_df = pd.concat(processed_chunks).reset_index(drop=True)\n",
    "\n",
    "    if combined_df.empty:\n",
    "        print(\"No data meets the criteria (WaitTime >= 4 hours) after initial filtering and combining. No plots will be generated.\")\n",
    "        return\n",
    "\n",
    "    print(\"Finished parallel data preprocessing. Starting user-wise aggregation...\")\n",
    "\n",
    "    # Group by 'Account' and 'JobID' to get total wait time per job for each user\n",
    "    total_wait_time_per_user_job = combined_df.groupby(['Account', 'JobID']).agg(\n",
    "        TotalWaitTime=('WaitTime', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    if total_wait_time_per_user_job.empty:\n",
    "        print(\"No job data after user-wise aggregation. No plots will be generated.\")\n",
    "        return\n",
    "\n",
    "    # Create the base directory for saving plots if it doesn't exist\n",
    "    base_plots_dir = \"plots/user_job_wait_times\" # New directory for user-specific plots\n",
    "    os.makedirs(base_plots_dir, exist_ok=True)\n",
    "\n",
    "    # Get unique accounts to iterate through\n",
    "    unique_accounts = total_wait_time_per_user_job['Account'].unique()\n",
    "    print(f\"Found {len(unique_accounts)} unique users to plot.\")\n",
    "\n",
    "    print(\"Generating plots for each user in parallel...\")\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for account in unique_accounts:\n",
    "            # Filter the aggregated data for the current user\n",
    "            user_data = total_wait_time_per_user_job[\n",
    "                total_wait_time_per_user_job['Account'] == account\n",
    "            ].copy() # .copy() is important to avoid SettingWithCopyWarning in worker processes\n",
    "\n",
    "            futures.append(\n",
    "                executor.submit(\n",
    "                    _plot_single_user_jobs, user_data, account, base_plots_dir, plot_dpi\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result() # Re-raise any exceptions from worker processes\n",
    "            except Exception as exc:\n",
    "                print(f'An error occurred during plotting a user\\'s jobs: {exc}')\n",
    "                traceback.print_exc()\n",
    "\n",
    "    print(\"All user job plots finished generating.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_all_slurm():\n",
    "    '''\n",
    "    Preprocess and then plot all the raapoi user and estimated cost data.\n",
    "    '''\n",
    "    df = pd.read_csv('raapoi_metrics/raapoi_data.csv', dtype={15: str})\n",
    "    df = preprocess_data(df)\n",
    "\n",
    "    plot_unique_users_per_month(df)\n",
    "    plot_unique_users_per_year(df)\n",
    "    plot_costs_per_year(df)\n",
    "    # plot_costs_per_month(df) # debug\n",
    "    # plot_submit_start_time(df) # optimize\n",
    "    # plot_total_wait_time_per_jobid_multiprocessed(df, num_chunks=os.cpu_count())\n",
    "    # plot_jobs_per_user_wait_times_multiprocessed(df, num_chunks=os.cpu_count(), plot_dpi=150)\n",
    "    \n",
    "plot_all_slurm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ca5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from plotnine import (\n",
    "    aes,\n",
    "    element_text,\n",
    "    facet_wrap,\n",
    "    geom_bar,\n",
    "    geom_col,\n",
    "    ggplot,\n",
    "    ggsave,\n",
    "    guides,\n",
    "    labs,\n",
    "    scale_fill_gradient,\n",
    "    scale_x_date,\n",
    "    theme,\n",
    ")\n",
    "from mizani.formatters import date_format\n",
    "from typing import Optional, List\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def memfix(inmem):\n",
    "    if pd.isnull(inmem):\n",
    "        outmem = 0\n",
    "    else:\n",
    "        outmem = float(str(inmem).strip('M'))\n",
    "    return outmem \n",
    "\n",
    "def preprocess_data(df):\n",
    "    '''\n",
    "    Load the dataframe\n",
    "    Do some preprocessing of the input data, such as fixing account allocations\n",
    "    '''\n",
    "\n",
    "    # df = pd.read_csv('../dfout_all.csv', dtype={15: str})\n",
    "\n",
    "    #Fix jiaowa account info to ferrier rather than sbs\n",
    "    mask = (df['User'] == 'jiaowa') & (df['Account'] == 'sbs')\n",
    "    df.loc[mask, 'Account'] = 'ferrier'\n",
    "\n",
    "    # Mapping of old account names to new ones\n",
    "    account_mapping = {\n",
    "        'scpslab206': 'scps', \n",
    "        'scpslab306': 'scps',\n",
    "        'spacejam': 'scps',\n",
    "        'phys414': 'scps',\n",
    "        'students': 'scps',\n",
    "        'cad': 'admin',\n",
    "        'root': 'admin'\n",
    "    }\n",
    "\n",
    "    # Replace account names\n",
    "    df['Account'] = df['Account'].replace(account_mapping)\n",
    "\n",
    "    # currently we use a fix usd to nzd exchange rate to calculate aws cost\n",
    "    usd_to_nzd = 1.62\n",
    "    df.aws_cost = df.aws_cost * usd_to_nzd\n",
    "\n",
    "    # set dates as datetime and create columns for month and year\n",
    "    df['Start'] = pd.to_datetime(df['Start'])\n",
    "    df['Submit'] = pd.to_datetime(df['Submit'])\n",
    "    df['End'] = pd.to_datetime(df['End'])\n",
    "    df['Year'] = df['Start'].dt.year\n",
    "    df['Month'] = df['Start'].dt.month\n",
    "    df['Wait'] = df['Start'] - df ['Submit']\n",
    "    \n",
    "    # memfix\n",
    "    df['ReqMem'] = df['ReqMem'].apply(memfix)\n",
    "\n",
    "    return df\n",
    "\n",
    "'''\n",
    "Preprocess and then plot all the raapoi user and estimated cost data.\n",
    "'''\n",
    "df = pd.read_csv('raapoi_metrics/raapoi_data.csv', dtype={15: str})\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Create a common plot function with consistent aesthetics\n",
    "def common_plot(df: pd.DataFrame, x: str, y: str, title: str, xlabel: str, ylabel: str, color: str = 'blue', kind: str = 'line', ax: Optional[plt.Axes] = None, ylim: Optional[tuple] = None):\n",
    "    '''\n",
    "    Common plotting function for consistent aesthetics.\n",
    "    Can plot on a specific axes if 'ax' is provided, otherwise creates a new figure.\n",
    "    '''\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        current_ax = plt.gca()\n",
    "    else:\n",
    "        current_ax = ax\n",
    "\n",
    "    if kind == 'line':\n",
    "        sns.lineplot(data=df, x=x, y=y, color=color, ax=current_ax)\n",
    "    # elif kind == 'bar':\n",
    "    #     sns.barplot(data=df, x=x, y=y, color=color, ax=current_ax)\n",
    "    elif kind == 'bar':\n",
    "        barplot_container = sns.barplot(data=df, x=x, y=y, color=color, ax=current_ax)\n",
    "        show_bar_labels = True\n",
    "        bar_label_fmt = '{:.0f}'  # Format for bar labels\n",
    "        if show_bar_labels:\n",
    "            # Check if bar_label is available (Matplotlib 3.4+)\n",
    "            if hasattr(current_ax, 'bar_label'):\n",
    "                current_ax.bar_label(barplot_container.containers[0], fmt=bar_label_fmt, padding=3, rotation=90)\n",
    "            else:\n",
    "                # Fallback for older Matplotlib versions (less ideal positioning)\n",
    "                for p in current_ax.patches:\n",
    "                    current_ax.text(p.get_x() + p.get_width() / 2.,\n",
    "                                    p.get_height(),\n",
    "                                    f'{p.get_height():.2f}',\n",
    "                                    ha='center', va='bottom', fontsize=9, color='black')\n",
    "\n",
    "\n",
    "\n",
    "    current_ax.set_title(title)\n",
    "    current_ax.set_xlabel(xlabel)\n",
    "    current_ax.set_ylabel(ylabel)\n",
    "    current_ax.tick_params(axis='x', rotation=90)\n",
    "    # current_ax.set_ylim(0, 200)\n",
    "\n",
    "    # Apply y-limit if provided\n",
    "    if ylim is not None:\n",
    "        current_ax.set_ylim(ylim[0], ylim[1])\n",
    "        \n",
    "    if ax is None:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a1c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data for jobs per partition\n",
    "jobs_per_partition = df['Partition'].value_counts().reset_index()\n",
    "jobs_per_partition.columns = ['Partition', 'JobCount']\n",
    "\n",
    "# Calculate total number of jobs\n",
    "total_jobs = jobs_per_partition['JobCount'].sum()\n",
    "\n",
    "# Calculate percentage of jobs for each partition\n",
    "jobs_per_partition['Percentage'] = (jobs_per_partition['JobCount'] / total_jobs) * 100\n",
    "\n",
    "# Display the percentage distribution in a table\n",
    "print(\"Percentage Distribution of Jobs per Partition:\")\n",
    "print(jobs_per_partition.sort_values(by='Percentage', ascending=False).to_string(index=False))\n",
    "\n",
    "# Plotting percentage distribution as a pie chart\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pie(jobs_per_partition['Percentage'], labels=jobs_per_partition['Partition'], autopct='%1.1f%%', startangle=140, pctdistance=0.85)\n",
    "plt.title('Percentage Distribution of Jobs per Partition')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a685f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_jobs_over_time_per_partition(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plots the number of jobs for each partition over time.\n",
    "    The time unit is derived from the 'Start' column (Year-Month).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing job data.\n",
    "                          Must have 'Start' (datetime) and 'Partition' columns.\n",
    "    \"\"\"\n",
    "    # Ensure 'Start' column is datetime, crucial for time-based plotting\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['Start']):\n",
    "        print(\"Warning: 'Start' column is not datetime. Attempting conversion.\")\n",
    "        df['Start'] = pd.to_datetime(df['Start'], errors='coerce')\n",
    "        df.dropna(subset=['Start'], inplace=True) # Drop rows where conversion failed\n",
    "\n",
    "    # Create a 'YearMonth' column for chronological ordering\n",
    "    df['YearMonth'] = df['Start'].dt.to_period('M').astype(str)\n",
    "\n",
    "    # Aggregate data: count jobs per partition per YearMonth\n",
    "    jobs_over_time = df.groupby(['YearMonth', 'Partition']).size().reset_index(name='JobCount')\n",
    "\n",
    "    # Create the plot using seaborn.\n",
    "    # hue='Partition' will create a separate line for each partition.\n",
    "    plt.figure(figsize=(15, 8)) # Increased figure size for better readability\n",
    "    sns.lineplot(\n",
    "        data=jobs_over_time,\n",
    "        x='YearMonth',\n",
    "        y='JobCount',\n",
    "        hue='Partition',\n",
    "        marker='o', # Add markers to points\n",
    "        ax=plt.gca()\n",
    "    )\n",
    "\n",
    "    plt.title('Number of Jobs per Partition Over Time')\n",
    "    plt.xlabel('Time (Year-Month)')\n",
    "    plt.ylabel('Number of Jobs')\n",
    "    plt.xticks(rotation=90) # Rotate x-axis labels for better readability\n",
    "    plt.grid(True, linestyle='--', alpha=0.7) # Add a grid for easier reading\n",
    "    plt.legend(title='Partition', bbox_to_anchor=(1.05, 1), loc='upper left') # Place legend outside plot area\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig('number_of_jobs_per_partition_over_time.png')\n",
    "    plt.close() # Close the figure to free memory\n",
    "    print(\"Plot 'number_of_jobs_per_partition_over_time.png' saved successfully.\")\n",
    "\n",
    "plot_jobs_over_time_per_partition(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99296d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "def plot_jobs_over_time_per_partition(df: pd.DataFrame, partitions: Optional[List[str]] = None):\n",
    "    \"\"\"\n",
    "    Plots the number of jobs for specified partitions over time as a bar chart,\n",
    "    using the common_plot function for consistent aesthetics.\n",
    "    The time unit is derived from the 'Start' column (Year-Month).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing job data.\n",
    "                          Must have 'Start' (datetime) and 'Partition' columns.\n",
    "        partitions (Optional[List[str]]): A list of partition names to plot.\n",
    "                                          If None, all partitions will be plotted.\n",
    "    \"\"\"\n",
    "    # Ensure 'Start' column is datetime, crucial for time-based plotting\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['Start']):\n",
    "        print(\"Warning: 'Start' column is not datetime. Attempting conversion.\")\n",
    "        df['Start'] = pd.to_datetime(df['Start'], errors='coerce')\n",
    "        df.dropna(subset=['Start'], inplace=True) # Drop rows where conversion failed\n",
    "\n",
    "    # Filter by specified partitions if the argument is provided\n",
    "    if partitions:\n",
    "        df_filtered = df[df['Partition'].isin(partitions)].copy()\n",
    "        if df_filtered.empty:\n",
    "            print(f\"No data found for the specified partitions: {', '.join(partitions)}\")\n",
    "            return\n",
    "    else:\n",
    "        df_filtered = df.copy()\n",
    "\n",
    "\n",
    "    # Create a 'YearMonth' column for chronological ordering\n",
    "    df_filtered['YearMonth'] = df_filtered['Start'].dt.to_period('M').astype(str)\n",
    "\n",
    "    # Aggregate data: count jobs per partition per YearMonth\n",
    "    jobs_over_time = df_filtered.groupby(['YearMonth', 'Partition']).size().reset_index(name='JobCount')\n",
    "\n",
    "    # Create a combined 'YearMonth-Partition' for x-axis labels\n",
    "    jobs_over_time['TimePartition'] = jobs_over_time['YearMonth'] + ' - ' + jobs_over_time['Partition']\n",
    "\n",
    "    title_suffix = f\" for {', '.join(partitions)}\" if partitions else \" for All Partitions\"\n",
    "    plot_title = f'Number of Jobs per Partition Over Time (Bar Chart){title_suffix}'\n",
    "    file_name = f'number_of_jobs_per_partition_over_time_bar_chart{title_suffix.replace(\" \", \"_\").replace(\",\", \"\").lower()}.png'\n",
    "\n",
    "    common_plot(\n",
    "        df=jobs_over_time,\n",
    "        x='TimePartition',\n",
    "        y='JobCount',\n",
    "        title=plot_title,\n",
    "        xlabel='Time (Year-Month) - Partition',\n",
    "        ylabel='Number of Jobs',\n",
    "        color='skyblue', # Default color for now, common_plot doesn't support hue directly\n",
    "        kind='bar'\n",
    "    )\n",
    "    print(f\"Plot '{file_name}' saved successfully.\")\n",
    "    \n",
    "    \n",
    "# Call the function\n",
    "plot_jobs_over_time_per_partition(df, partitions=['parallel'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6add1216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print header and first row\n",
    "\n",
    "# print 1st row as list\n",
    "print(\"DataFrame Header:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"First Row as List:\")\n",
    "# Convert the first row to a list and print it\n",
    "print(df.head(1).values.tolist()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d5904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Optional, Dict\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Load the dataframe\n",
    "    Do some preprocessing of the input data, such as fixing account allocations\n",
    "    '''\n",
    "    # Make a copy to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "\n",
    "    # Fix jiaowa account info to ferrier rather than sbs\n",
    "    mask = (df['User'] == 'jiaowa') & (df['Account'] == 'sbs')\n",
    "    df.loc[mask, 'Account'] = 'ferrier'\n",
    "\n",
    "    # Mapping of old account names to new ones\n",
    "    account_mapping = {\n",
    "        'scpslab206': 'scps',\n",
    "        'scpslab306': 'scps',\n",
    "        'spacejam': 'scps',\n",
    "        'phys414': 'scps',\n",
    "        'students': 'scps',\n",
    "        'cad': 'admin',\n",
    "        'root': 'admin'\n",
    "    }\n",
    "\n",
    "    # Replace account names\n",
    "    df['Account'] = df['Account'].replace(account_mapping)\n",
    "\n",
    "    # Currently we use a fixed USD to NZD exchange rate to calculate AWS cost\n",
    "    usd_to_nzd = 1.62\n",
    "    df['aws_cost'] = df['aws_cost'] * usd_to_nzd\n",
    "\n",
    "    # Set dates as datetime and create columns for month and year\n",
    "    # Ensure columns exist before accessing .dt\n",
    "    if 'Start' in df.columns:\n",
    "        df['Start'] = pd.to_datetime(df['Start'])\n",
    "        df['Year'] = df['Start'].dt.year\n",
    "        df['Month'] = df['Start'].dt.month\n",
    "    if 'Submit' in df.columns:\n",
    "        df['Submit'] = pd.to_datetime(df['Submit'])\n",
    "    if 'End' in df.columns:\n",
    "        df['End'] = pd.to_datetime(df['End'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_plot(df: pd.DataFrame, x_column: str, title: str, subtitle: str, filename: str, width: Optional[float] = None) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Generates a bar plot using Matplotlib/Seaborn.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data to plot.\n",
    "        x_column (str): Name of the column to use for the x-axis (e.g., 'YearMonth').\n",
    "        title (str): Main title of the plot.\n",
    "        subtitle (str): Subtitle of the plot.\n",
    "        filename (str): Desired filename for saving the plot (not used for display).\n",
    "        width (Optional[float]): Placeholder for bar width; Matplotlib handles this more\n",
    "                                 automatically or through `width` parameter in `plt.bar`.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: The Matplotlib Figure object containing the plot.\n",
    "    \"\"\"\n",
    "    # Determine figure size based on number of unique x-axis values for better readability\n",
    "    num_x_values = len(df[x_column].unique())\n",
    "    fig_width = max(8, num_x_values * 0.5) # Min width 8, scale up with more bars\n",
    "    fig_height = 6\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "    # Use Seaborn for a nice bar plot\n",
    "    # The 'UniqueUsers' column will automatically determine bar height and color intensity\n",
    "    # using a sequential colormap.\n",
    "    sns.barplot(x=x_column, y='UniqueUsers', data=df, color='skyblue', ax=ax) # Reds_d gives red gradient\n",
    "\n",
    "    # Add labels and titles\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Unique Users')\n",
    "    ax.set_title(f\"{title}\\n{subtitle}\", loc='center', wrap=True) # Combined title and subtitle, centered\n",
    "\n",
    "    # Rotate x-axis labels for better readability if they are dates or long strings\n",
    "    if df[x_column].dtype == '<M8[ns]': # Check if x_column is datetime\n",
    "        fig.autofmt_xdate(rotation=45, ha='right') # Automatically format and rotate date labels\n",
    "    else:\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right') # General rotation for other types\n",
    "        \n",
    "    # Set y-axis limits: from 0 to slightly above the maximum 'UniqueUsers' for padding\n",
    "    max_users = df['UniqueUsers'].max()\n",
    "    ax.set_ylim(0, max_users * 1.10) # 10% padding above max value\n",
    "\n",
    "    # Improve layout to prevent labels from overlapping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Saving the plot is optional here, as the primary goal is display.\n",
    "    # If you still want to save, uncomment the line below.\n",
    "    # plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    # Close the plot to prevent it from being displayed twice if plt.show() is called later\n",
    "    # plt.close(fig) # Commenting out plt.close() as we want to return the figure for display\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_unique_users_per_month(df: pd.DataFrame) -> Dict[str, plt.Figure]:\n",
    "    \"\"\"\n",
    "    Generates and saves monthly unique user plots for each account and a total.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing 'Account', 'Year', 'Month', and 'User' columns.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, plt.Figure]: A dictionary where keys are plot names (e.g., 'Account A Monthly Users')\n",
    "                               and values are the generated Matplotlib Figure objects.\n",
    "                               These objects can then be displayed in an interactive environment.\n",
    "    \"\"\"\n",
    "    all_plots = {} # Dictionary to store all generated Matplotlib Figure objects\n",
    "\n",
    "    # Group by 'Account', 'Year', 'Month' and 'User', then count unique 'User'\n",
    "    # This step ensures each user within an account for a given month is counted only once.\n",
    "    unique_users = df.groupby(['Account', 'Year', 'Month', 'User'], dropna=False).size().reset_index().rename(columns={0:'count'})\n",
    "    print(\"Head of unique_users after initial grouping:\")\n",
    "    print(unique_users.head())\n",
    "\n",
    "    # Now group by 'Account', 'Year' and 'Month' and count unique 'User'\n",
    "    # This gives us the total unique users per account per month.\n",
    "    unique_users_per_month = unique_users.groupby(['Account', 'Year', 'Month'], dropna=False).size().reset_index().rename(columns={0:'UniqueUsers'})\n",
    "\n",
    "    # Convert 'Year' and 'Month' to integer, then to string, combine them, and convert to datetime\n",
    "    # This creates a proper datetime object for plotting on the x-axis.\n",
    "    # Handle potential NaN values from grouping (e.g., if 'Year' or 'Month' were missing)\n",
    "    unique_users_per_month = unique_users_per_month.dropna(subset=['Year', 'Month']) # Drop rows where Year/Month might be NaN after grouping\n",
    "    unique_users_per_month['YearMonth'] = pd.to_datetime(\n",
    "        unique_users_per_month['Year'].astype(int).astype(str) + '-' +\n",
    "        unique_users_per_month['Month'].astype(int).astype(str)\n",
    "    )\n",
    "\n",
    "    # Capitalize 'Account' names for consistent labeling and file naming\n",
    "    unique_users_per_month['Account'] = unique_users_per_month['Account'].str.upper()\n",
    "\n",
    "    accounts = unique_users_per_month['Account'].unique()\n",
    "\n",
    "    # Create the directory for plots if it doesn't already exist\n",
    "    plot_dir = 'plots/monthly_users'\n",
    "    if not os.path.exists(plot_dir):\n",
    "        os.makedirs(plot_dir)\n",
    "        print(f\"Created directory: {plot_dir}\")\n",
    "\n",
    "    # Generate and store plots for each individual account\n",
    "    print(\"\\nGenerating plots for individual accounts...\")\n",
    "    for account in accounts:\n",
    "        account_data = unique_users_per_month[unique_users_per_month['Account'] == account].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "        plot_title_str = f'Unique {account} Users Per Month'\n",
    "        file_path = os.path.join(plot_dir, f'{account.replace(\" \", \"_\").lower()}_users_per_month.png')\n",
    "\n",
    "        # Call generate_plot and store the returned Matplotlib Figure object\n",
    "        current_fig = generate_plot(\n",
    "            df=account_data,\n",
    "            x_column='YearMonth',\n",
    "            title='R훮poi', # Assuming 'R훮poi' is a constant title or placeholder\n",
    "            subtitle=plot_title_str,\n",
    "            filename=file_path\n",
    "        )\n",
    "        all_plots[plot_title_str] = current_fig\n",
    "        print(f\"Generated plot for {account}: {file_path}\")\n",
    "\n",
    "    # Produce the total unique users per month plot\n",
    "    start_time = time.time()\n",
    "\n",
    "    # For the total unique users per month, group the aggregated unique_users_per_month\n",
    "    # DataFrame by YearMonth and sum the 'UniqueUsers' across all accounts.\n",
    "    total_users_per_month = unique_users_per_month.groupby(['YearMonth'])['UniqueUsers'].sum().reset_index()\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'\\nCreating total unique users data took: {elapsed_time:.4f} seconds')\n",
    "\n",
    "    total_plot_title_str = 'Total Unique Users Per Month'\n",
    "    total_file_path = os.path.join(plot_dir, 'total_users_per_month.png')\n",
    "    total_fig = generate_plot(\n",
    "        df=total_users_per_month,\n",
    "        x_column='YearMonth',\n",
    "        title='R훮poi', # Assuming 'R훮poi' is a constant title or placeholder\n",
    "        subtitle=total_plot_title_str,\n",
    "        filename=total_file_path\n",
    "    )\n",
    "    all_plots[total_plot_title_str] = total_fig\n",
    "    print(f\"Generated total unique users plot: {total_file_path}\")\n",
    "\n",
    "    return all_plots\n",
    "\n",
    "def plot_all_slurm():\n",
    "    '''\n",
    "    Preprocess and then plot all the raapoi user and estimated cost data.\n",
    "    '''\n",
    "    # Load your data\n",
    "    # IMPORTANT: Replace 'data.csv' with the actual path to your CSV file.\n",
    "    # If running in the same directory as the script, 'data.csv' is fine.\n",
    "    # If it's a different path (e.g., from the provided example '/nfs/scratch/duggalro/ex_python/raapoi_metrics/raapoi_data.csv'), use that.\n",
    "    try:\n",
    "        df = pd.read_csv('/nfs/scratch/duggalro/ex_python/raapoi_metrics/raapoi_data.csv', dtype={15: str})\n",
    "        print(\"Loaded data.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"data.csv not found. Please ensure the CSV file is in the correct directory or update the path.\")\n",
    "        return # Exit if data isn't found\n",
    "\n",
    "    df = preprocess_data(df)\n",
    "\n",
    "    # Get the dictionary of generated plots\n",
    "    generated_plots = plot_unique_users_per_month(df)\n",
    "\n",
    "    # Iterate through the plots and display each one\n",
    "    print(\"\\n--- Displaying all generated plots ---\")\n",
    "    for plot_name, plot_fig in generated_plots.items():\n",
    "        print(f\"\\n--- Displaying: {plot_name} ---\")\n",
    "        # Display the figure in the Jupyter Notebook\n",
    "        # plt.show() is often not strictly necessary in a notebook if the figure is the last output,\n",
    "        # but it can ensure proper rendering, especially if you have multiple figures.\n",
    "        # plt.show() also closes the figure automatically after display.\n",
    "        # If you want to keep the figure open for further manipulation, you can omit plt.show()\n",
    "        # and simply have 'plot_fig' as the last line in a cell.\n",
    "        plt.show(plot_fig) # Pass the figure object to show\n",
    "\n",
    "# Call the main function to run the process\n",
    "plot_all_slurm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a84c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique_users_per_year(df: pd.DataFrame) -> Dict[str, plt.Figure]:\n",
    "    \"\"\"\n",
    "    Generates and saves yearly unique user plots for each account and a total.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing 'Account', 'Year', and 'User' columns.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, plt.Figure]: A dictionary where keys are plot names (e.g., 'Account A Yearly Users')\n",
    "                               and values are the generated Matplotlib Figure objects.\n",
    "    \"\"\"\n",
    "    all_plots_yearly = {}\n",
    "\n",
    "    unique_users_per_year_initial = df.groupby(['Account', 'Year', 'User'], dropna=False).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "    # Now group by 'Account' and 'Year' and count unique 'User'\n",
    "    unique_users_per_year = unique_users_per_year_initial.groupby(['Account', 'Year'], dropna=False).size().reset_index().rename(columns={0:'UniqueUsers'})\n",
    "    \n",
    "    # Capitalize 'Account'\n",
    "    unique_users_per_year['Account'] = unique_users_per_year['Account'].str.upper()\n",
    "\n",
    "    accounts = unique_users_per_year['Account'].unique()\n",
    "\n",
    "    # Create the directory if it doesn't already exist\n",
    "    plot_dir = 'plots/yearly_users'\n",
    "    if not os.path.exists(plot_dir):\n",
    "        os.makedirs(plot_dir)\n",
    "        print(f\"Created directory: {plot_dir}\")\n",
    "\n",
    "    print(\"\\nGenerating plots for individual accounts (yearly)...\")\n",
    "    for account in accounts:\n",
    "        account_data = unique_users_per_year[unique_users_per_year['Account'] == account].copy()\n",
    "        plot_title_str = f'Unique {account} Users Per Year'\n",
    "        file_path = os.path.join(plot_dir, f'{account.replace(\" \", \"_\").lower()}_users_per_year.png')\n",
    "\n",
    "        current_fig = generate_plot(\n",
    "            df=account_data,\n",
    "            x_column='Year',\n",
    "            title='R훮poi',\n",
    "            subtitle=plot_title_str,\n",
    "            filename=file_path\n",
    "        )\n",
    "        all_plots_yearly[plot_title_str] = current_fig\n",
    "        print(f\"Generated yearly plot for {account}: {file_path}\")\n",
    "\n",
    "    # Produce the total unique users per year\n",
    "    start_time = time.time()\n",
    "    total_users_per_year = unique_users_per_year.groupby(['Year'])['UniqueUsers'].sum().reset_index()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Creating total unique users took: {elapsed_time:.4f} seconds')\n",
    "\n",
    "    total_plot_title_str = 'Total Unique Users Per Year'\n",
    "    total_file_path = os.path.join(plot_dir, 'total_users_per_year.png')\n",
    "    total_fig = generate_plot(\n",
    "        df=total_users_per_year,\n",
    "        x_column='Year',\n",
    "        title='R훮poi',\n",
    "        subtitle=total_plot_title_str,\n",
    "        filename=total_file_path\n",
    "    )\n",
    "    all_plots_yearly[total_plot_title_str] = total_fig\n",
    "    print(f\"Generated total unique users yearly plot: {total_file_path}\")\n",
    "\n",
    "    return all_plots_yearly\n",
    "\n",
    "# Get the dictionary of yearly generated plots\n",
    "generated_yearly_plots = plot_unique_users_per_year(df)\n",
    "# Iterate through all yearly plots and display each one\n",
    "print(\"\\n--- Displaying all generated YEARLY plots ---\")\n",
    "for plot_name, plot_fig in generated_yearly_plots.items():\n",
    "    print(f\"\\n--- Displaying: {plot_name} ---\")\n",
    "    plt.show(plot_fig) # Pass the figure object to show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad354e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Optional, Dict\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Load the dataframe\n",
    "    Do some preprocessing of the input data, such as fixing account allocations\n",
    "    '''\n",
    "    # Make a copy to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "\n",
    "    # Fix jiaowa account info to ferrier rather than sbs\n",
    "    mask = (df['User'] == 'jiaowa') & (df['Account'] == 'sbs')\n",
    "    df.loc[mask, 'Account'] = 'ferrier'\n",
    "\n",
    "    # Mapping of old account names to new ones\n",
    "    account_mapping = {\n",
    "        'scpslab206': 'scps',\n",
    "        'scpslab306': 'scps',\n",
    "        'spacejam': 'scps',\n",
    "        'phys414': 'scps',\n",
    "        'students': 'scps',\n",
    "        'cad': 'admin',\n",
    "        'root': 'admin'\n",
    "    }\n",
    "\n",
    "    # Replace account names\n",
    "    df['Account'] = df['Account'].replace(account_mapping)\n",
    "\n",
    "    # Currently we use a fixed USD to NZD exchange rate to calculate AWS cost\n",
    "    usd_to_nzd = 1.62\n",
    "    df['aws_cost'] = df['aws_cost'] * usd_to_nzd\n",
    "\n",
    "    # Set dates as datetime and create columns for month and year\n",
    "    # Ensure columns exist before accessing .dt\n",
    "    if 'Start' in df.columns:\n",
    "        df['Start'] = pd.to_datetime(df['Start'])\n",
    "        df['Year'] = df['Start'].dt.year\n",
    "        df['Month'] = df['Start'].dt.month\n",
    "    if 'Submit' in df.columns:\n",
    "        df['Submit'] = pd.to_datetime(df['Submit'])\n",
    "    if 'End' in df.columns:\n",
    "        df['End'] = pd.to_datetime(df['End'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_plot(df: pd.DataFrame, x_column: str, title: str, subtitle: str, filename: str, width: Optional[float] = None) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Generates a bar plot using Matplotlib/Seaborn.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data to plot.\n",
    "        x_column (str): Name of the column to use for the x-axis (e.g., 'YearMonth').\n",
    "        title (str): Main title of the plot (e.g., 'R훮poi').\n",
    "        subtitle (str): Subtitle of the plot (e.g., 'Unique Account A Users Per Month').\n",
    "        filename (str): Desired filename for saving the plot (not used for display).\n",
    "        width (Optional[float]): Placeholder for bar width; Matplotlib handles this more\n",
    "                                 automatically or through `width` parameter in `plt.bar`.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: The Matplotlib Figure object containing the plot.\n",
    "    \"\"\"\n",
    "    # Use a fixed, decent figure size for consistent bar appearance\n",
    "    # Seaborn will adjust bar widths to fit this figure size.\n",
    "    fig_width = 10\n",
    "    fig_height = 6\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "    # Use Seaborn for a nice bar plot with a single soft color\n",
    "    sns.barplot(x=x_column, y='UniqueUsers', data=df, color='skyblue', ax=ax)\n",
    "\n",
    "    # Set self-defining x-axis label\n",
    "    x_label_map = {\n",
    "        'YearMonth': 'Date (Year-Month)',\n",
    "        'Year': 'Year'\n",
    "    }\n",
    "    ax.set_xlabel(x_label_map.get(x_column, 'Date')) # Default to 'Date' if x_column not in map\n",
    "    ax.set_ylabel('Unique Users')\n",
    "\n",
    "    # Create a more elaborative combined title\n",
    "    main_title_prefix = f\"{title} - Unique User Statistics\"\n",
    "    full_plot_title = f\"{main_title_prefix}\\n{subtitle}\"\n",
    "    ax.set_title(full_plot_title, loc='center', wrap=True, fontsize=14)\n",
    "\n",
    "    # Rotate x-axis labels for better readability if they are dates or long strings\n",
    "    if df[x_column].dtype == '<M8[ns]': # Check if x_column is datetime\n",
    "        fig.autofmt_xdate(rotation=45, ha='right') # Automatically format and rotate date labels\n",
    "    else:\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right') # General rotation for other types\n",
    "\n",
    "    # Set y-axis limits: from 0 to slightly above the maximum 'UniqueUsers' for padding\n",
    "    max_users = df['UniqueUsers'].max()\n",
    "    ax.set_ylim(0, max_users * 1.10) # 10% padding above max value\n",
    "\n",
    "\n",
    "    # Improve layout to prevent labels from overlapping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Saving the plot is optional here, as the primary goal is display.\n",
    "    # If you still want to save, uncomment the line below.\n",
    "    # plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_unique_users_per_month(df: pd.DataFrame) -> Dict[str, plt.Figure]:\n",
    "    \"\"\"\n",
    "    Generates and saves monthly unique user plots for each account and a total.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing 'Account', 'Year', 'Month', and 'User' columns.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, plt.Figure]: A dictionary where keys are plot names (e.g., 'Account A Monthly Users')\n",
    "                               and values are the generated Matplotlib Figure objects.\n",
    "                               These objects can then be displayed in an interactive environment.\n",
    "    \"\"\"\n",
    "    all_plots = {} # Dictionary to store all generated Matplotlib Figure objects\n",
    "\n",
    "    # Group by 'Account', 'Year', 'Month' and 'User', then count unique 'User'\n",
    "    # This step ensures each user within an account for a given month is counted only once.\n",
    "    unique_users = df.groupby(['Account', 'Year', 'Month', 'User'], dropna=False).size().reset_index().rename(columns={0:'count'})\n",
    "    print(\"Head of unique_users after initial grouping:\")\n",
    "    print(unique_users.head())\n",
    "\n",
    "    # Now group by 'Account', 'Year' and 'Month' and count unique 'User'\n",
    "    # This gives us the total unique users per account per month.\n",
    "    unique_users_per_month = unique_users.groupby(['Account', 'Year', 'Month'], dropna=False).size().reset_index().rename(columns={0:'UniqueUsers'})\n",
    "\n",
    "    # Convert 'Year' and 'Month' to integer, then to string, combine them, and convert to datetime\n",
    "    # This creates a proper datetime object for plotting on the x-axis.\n",
    "    # Handle potential NaN values from grouping (e.g., if 'Year' or 'Month' were missing)\n",
    "    unique_users_per_month = unique_users_per_month.dropna(subset=['Year', 'Month']) # Drop rows where Year/Month might be NaN after grouping\n",
    "    unique_users_per_month['YearMonth'] = pd.to_datetime(\n",
    "        unique_users_per_month['Year'].astype(int).astype(str) + '-' +\n",
    "        unique_users_per_month['Month'].astype(int).astype(str)\n",
    "    )\n",
    "\n",
    "    # Capitalize 'Account' names for consistent labeling and file naming\n",
    "    unique_users_per_month['Account'] = unique_users_per_month['Account'].str.upper()\n",
    "\n",
    "    accounts = unique_users_per_month['Account'].unique()\n",
    "\n",
    "    # Create the directory for plots if it doesn't already exist\n",
    "    plot_dir = 'plots/monthly_users'\n",
    "    if not os.path.exists(plot_dir):\n",
    "        os.makedirs(plot_dir)\n",
    "        print(f\"Created directory: {plot_dir}\")\n",
    "\n",
    "    # Generate and store plots for each individual account\n",
    "    print(\"\\nGenerating plots for individual accounts...\")\n",
    "    for account in accounts:\n",
    "        account_data = unique_users_per_month[unique_users_per_month['Account'] == account].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "        plot_title_str = f'Unique {account} Users Per Month'\n",
    "        file_path = os.path.join(plot_dir, f'{account.replace(\" \", \"_\").lower()}_users_per_month.png')\n",
    "\n",
    "        # Call generate_plot and store the returned Matplotlib Figure object\n",
    "        current_fig = generate_plot(\n",
    "            df=account_data,\n",
    "            x_column='YearMonth',\n",
    "            title='R훮poi', # Assuming 'R훮poi' is a constant title or placeholder\n",
    "            subtitle=plot_title_str,\n",
    "            filename=file_path\n",
    "        )\n",
    "        all_plots[plot_title_str] = current_fig\n",
    "        print(f\"Generated plot for {account}: {file_path}\")\n",
    "\n",
    "    # Produce the total unique users per month plot\n",
    "    start_time = time.time()\n",
    "\n",
    "    # For the total unique users per month, group the aggregated unique_users_per_month\n",
    "    # DataFrame by YearMonth and sum the 'UniqueUsers' across all accounts.\n",
    "    total_users_per_month = unique_users_per_month.groupby(['YearMonth'])['UniqueUsers'].sum().reset_index()\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'\\nCreating total unique users took: {elapsed_time:.4f} seconds')\n",
    "\n",
    "    total_plot_title_str = 'Total Unique Users Per Month'\n",
    "    total_file_path = os.path.join(plot_dir, 'total_users_per_month.png')\n",
    "    total_fig = generate_plot(\n",
    "        df=total_users_per_month,\n",
    "        x_column='YearMonth',\n",
    "        title='R훮poi', # Assuming 'R훮poi' is a constant title or placeholder\n",
    "        subtitle=total_plot_title_str,\n",
    "        filename=total_file_path\n",
    "    )\n",
    "    all_plots[total_plot_title_str] = total_fig\n",
    "    print(f\"Generated total unique users plot: {total_file_path}\")\n",
    "\n",
    "    return all_plots\n",
    "\n",
    "def plot_unique_users_per_year(df: pd.DataFrame) -> Dict[str, plt.Figure]:\n",
    "    \"\"\"\n",
    "    Generates and saves yearly unique user plots for each account and a total.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing 'Account', 'Year', and 'User' columns.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, plt.Figure]: A dictionary where keys are plot names (e.g., 'Account A Yearly Users')\n",
    "                               and values are the generated Matplotlib Figure objects.\n",
    "    \"\"\"\n",
    "    all_plots_yearly = {}\n",
    "\n",
    "    unique_users_per_year_initial = df.groupby(['Account', 'Year', 'User'], dropna=False).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "    # Now group by 'Account' and 'Year' and count unique 'User'\n",
    "    unique_users_per_year = unique_users_per_year_initial.groupby(['Account', 'Year'], dropna=False).size().reset_index().rename(columns={0:'UniqueUsers'})\n",
    "\n",
    "    # Capitalize 'Account'\n",
    "    unique_users_per_year['Account'] = unique_users_per_year['Account'].str.upper()\n",
    "\n",
    "    accounts = unique_users_per_year['Account'].unique()\n",
    "\n",
    "    # Create the directory if it doesn't already exist\n",
    "    plot_dir = 'plots/yearly_users'\n",
    "    if not os.path.exists(plot_dir):\n",
    "        os.makedirs(plot_dir)\n",
    "        print(f\"Created directory: {plot_dir}\")\n",
    "\n",
    "    print(\"\\nGenerating plots for individual accounts (yearly)...\")\n",
    "    for account in accounts:\n",
    "        account_data = unique_users_per_year[unique_users_per_year['Account'] == account].copy()\n",
    "        plot_title_str = f'Unique {account} Users Per Year'\n",
    "        file_path = os.path.join(plot_dir, f'{account.replace(\" \", \"_\").lower()}_users_per_year.png')\n",
    "\n",
    "        current_fig = generate_plot(\n",
    "            df=account_data,\n",
    "            x_column='Year',\n",
    "            title='R훮poi',\n",
    "            subtitle=plot_title_str,\n",
    "            filename=file_path\n",
    "        )\n",
    "        all_plots_yearly[plot_title_str] = current_fig\n",
    "        print(f\"Generated yearly plot for {account}: {file_path}\")\n",
    "\n",
    "    # Produce the total unique users per year\n",
    "    start_time = time.time()\n",
    "    total_users_per_year = unique_users_per_year.groupby(['Year'])['UniqueUsers'].sum().reset_index()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Creating total unique users took: {elapsed_time:.4f} seconds')\n",
    "\n",
    "    total_plot_title_str = 'Total Unique Users Per Year'\n",
    "    total_file_path = os.path.join(plot_dir, 'total_users_per_year.png')\n",
    "    total_fig = generate_plot(\n",
    "        df=total_users_per_year,\n",
    "        x_column='Year',\n",
    "        title='R훮poi',\n",
    "        subtitle=total_plot_title_str,\n",
    "        filename=total_file_path\n",
    "    )\n",
    "    all_plots_yearly[total_plot_title_str] = total_fig\n",
    "    print(f\"Generated total unique users yearly plot: {total_file_path}\")\n",
    "\n",
    "    return all_plots_yearly\n",
    "\n",
    "\n",
    "def plot_all_slurm():\n",
    "    '''\n",
    "    Preprocess and then plot all the raapoi user and estimated cost data.\n",
    "    '''\n",
    "    # Load your data\n",
    "    # IMPORTANT: Replace 'data.csv' with the actual path to your CSV file.\n",
    "    # If running in the same directory as the script, 'data.csv' is fine.\n",
    "    # If it's a different path (e.g., from the provided example '/nfs/scratch/duggalro/ex_python/raapoi_metrics/raapoi_data.csv'), use that.\n",
    "    try:\n",
    "        df = pd.read_csv('/nfs/scratch/duggalro/ex_python/raapoi_metrics/raapoi_data.csv', dtype={15: str})\n",
    "        print(\"Loaded data.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"data.csv not found. Please ensure the CSV file is in the correct directory or update the path.\")\n",
    "        return # Exit if data isn't found\n",
    "\n",
    "    df = preprocess_data(df)\n",
    "\n",
    "    # Get the dictionary of monthly generated plots\n",
    "    generated_monthly_plots = plot_unique_users_per_month(df)\n",
    "\n",
    "    # Get the dictionary of yearly generated plots\n",
    "    generated_yearly_plots = plot_unique_users_per_year(df)\n",
    "\n",
    "    # Iterate through all monthly plots and display each one\n",
    "    print(\"\\n--- Displaying all generated MONTHLY plots ---\")\n",
    "    for plot_name, plot_fig in generated_monthly_plots.items():\n",
    "        print(f\"\\n--- Displaying: {plot_name} ---\")\n",
    "        plt.show(plot_fig) # Pass the figure object to show\n",
    "\n",
    "    # Iterate through all yearly plots and display each one\n",
    "    print(\"\\n--- Displaying all generated YEARLY plots ---\")\n",
    "    for plot_name, plot_fig in generated_yearly_plots.items():\n",
    "        print(f\"\\n--- Displaying: {plot_name} ---\")\n",
    "        plt.show(plot_fig) # Pass the figure object to show\n",
    "\n",
    "\n",
    "# Call the main function to run the process\n",
    "plot_all_slurm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0dccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_unique_jobs_per_account_by_year(df: pd.DataFrame):\n",
    "    '''\n",
    "    Plots the number of unique jobs per account by year,\n",
    "    specifically for jobs with wait time >= 4 hours and count < 100.\n",
    "    Each year gets a subplot.\n",
    "    '''\n",
    "    # Ensure 'Wait' column is timedelta type.\n",
    "    if 'Wait' in df.columns and not pd.api.types.is_timedelta64_dtype(df['Wait']):\n",
    "        try:\n",
    "            df['Wait'] = pd.to_timedelta(df['Wait'])\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not convert 'Wait' column to timedelta. Error: {e}\")\n",
    "            print(\"Skipping unique jobs per account analysis.\")\n",
    "            return\n",
    "\n",
    "    if 'Wait' not in df.columns:\n",
    "        print(\"The 'Wait' column is not available or could not be processed for unique jobs per account analysis.\")\n",
    "        return\n",
    "\n",
    "    # Filter for jobs with wait time >= 4 hours (14400 seconds)\n",
    "    df_long_wait = df[df['Wait'].dt.total_seconds() >= 14400].copy()\n",
    "\n",
    "    # Group by Year and Account, then count unique JobIDs\n",
    "    # 'JobID' is assumed to be the unique job identifier\n",
    "    if 'JobID' not in df_long_wait.columns:\n",
    "        print(\"Error: 'JobID' column not found. Cannot count unique jobs.\")\n",
    "        return\n",
    "\n",
    "    unique_jobs_per_account_year = df_long_wait.groupby(['Year', 'Account'])['JobID'].nunique().reset_index(name='UniqueJobCount')\n",
    "\n",
    "    # Filter for counts less than 400\n",
    "    # unique_jobs_per_account_year_filtered = unique_jobs_per_account_year[unique_jobs_per_account_year['UniqueJobCount'] < 400]\n",
    "\n",
    "    # Get unique years for subplots\n",
    "    # years = sorted(unique_jobs_per_account_year_filtered['Year'].unique())\n",
    "    years= sorted(unique_jobs_per_account_year['Year'].unique())\n",
    "\n",
    "    if not years:\n",
    "        print(\"No data available after filtering for unique jobs with wait time >= 4 hours and count < 400.\")\n",
    "        return\n",
    "\n",
    "    # Determine grid size for subplots\n",
    "    n_years = len(years)\n",
    "    cols = 2  # Max 2 columns for subplots\n",
    "    rows = (n_years + cols - 1) // cols # Calculate rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 6 * rows), squeeze=False)\n",
    "    axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "    for i, year in enumerate(years):\n",
    "        # data_for_year = unique_jobs_per_account_year_filtered[unique_jobs_per_account_year_filtered['Year'] == year]\n",
    "        data_for_year = unique_jobs_per_account_year[unique_jobs_per_account_year['Year'] == year]\n",
    "        if not data_for_year.empty:\n",
    "            common_plot(data_for_year, 'Account', 'UniqueJobCount',\n",
    "                        f'Jobs (Wait >= 4hr) in {int(year)}',\n",
    "                        'Account', 'Number of Jobs', color='teal', kind='bar', ax=axes[i])\n",
    "            # yscale is log\n",
    "            axes[i].set_yscale('log')\n",
    "        else:\n",
    "            # Hide empty subplots\n",
    "            axes[i].set_visible(False)\n",
    "            # \n",
    "\n",
    "    # Hide any unused subplots if n_years is not a perfect multiple of cols\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    # super title\n",
    "    plt.suptitle('Number of Unique Jobs per Account by Year (Wait >= 4hr)', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create and plot number of unique jobs per account by year\n",
    "plot_unique_jobs_per_account_by_year(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163dcf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique_jobs_per_account_all_years(df: pd.DataFrame):\n",
    "    '''\n",
    "    Plots the number of unique jobs per account for each year in separate subplots.\n",
    "    Each subplot visualizes the distribution of unique job counts across different\n",
    "    accounts for a specific year. This function does not filter based on 'Wait' time\n",
    "    or job count thresholds, showing all unique jobs.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data,\n",
    "                         expected to have 'Year', 'Account', and 'JobID' columns.\n",
    "    '''\n",
    "    # Basic data validation\n",
    "    if 'JobID' not in df.columns:\n",
    "        print(\"Error: 'JobID' column not found. Cannot count unique jobs.\")\n",
    "        return\n",
    "    if 'Year' not in df.columns:\n",
    "        print(\"Error: 'Year' column not found. Please ensure data preprocessing has been run (df['Start'] converted to datetime).\")\n",
    "        return\n",
    "    if 'Account' not in df.columns:\n",
    "        print(\"Error: 'Account' column not found. Please ensure data preprocessing has been run.\")\n",
    "        return\n",
    "\n",
    "    # Group by Year and Account, then count unique JobIDs\n",
    "    # This captures the total unique jobs for each account in each year\n",
    "    unique_jobs_per_account_year = df.groupby(['Year', 'Account'])['JobID'].nunique().reset_index(name='UniqueJobCount')\n",
    "\n",
    "    # Get a sorted list of unique years present in the data for subplot creation\n",
    "    years = sorted(unique_jobs_per_account_year['Year'].unique())\n",
    "\n",
    "    if not years:\n",
    "        print(\"No data available to plot unique jobs per account by year after grouping.\")\n",
    "        return\n",
    "\n",
    "    # Determine the layout for subplots: 2 columns, rows calculated based on number of years\n",
    "    n_years = len(years)\n",
    "    cols = 2\n",
    "    rows = (n_years + cols - 1) // cols\n",
    "\n",
    "    # Create the figure and subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 6 * rows), squeeze=False)\n",
    "    axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "    # Iterate through each year and create a subplot\n",
    "    for i, year in enumerate(years):\n",
    "        # Filter data for the current year\n",
    "        data_for_year = unique_jobs_per_account_year[unique_jobs_per_account_year['Year'] == year]\n",
    "\n",
    "        if not data_for_year.empty:\n",
    "            # Use common_plot to draw a bar plot for the current year\n",
    "            common_plot(data_for_year, 'Account', 'UniqueJobCount',\n",
    "                        f'Unique Jobs by Account in {int(year)}', # Title for each subplot\n",
    "                        'Account', 'Number of Unique Jobs',\n",
    "                        color='steelblue', # Consistent color for these plots\n",
    "                        kind='bar',\n",
    "                        ax=axes[i]) # Pass the specific axes for the subplot\n",
    "            # yscale is log\n",
    "            axes[i].set_yscale('log')\n",
    "        else:\n",
    "            # If a year has no data after filtering (unlikely with this grouping, but good practice),\n",
    "            # hide its subplot to avoid empty frames.\n",
    "            axes[i].set_visible(False)\n",
    "\n",
    "    # Hide any remaining unused subplots if the total number of years doesn't fill the grid perfectly\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    \n",
    "    # Adjust layout to prevent overlapping titles/labels\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_unique_jobs_per_account_all_years(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique_users_per_month_all_years(df: pd.DataFrame):\n",
    "    '''\n",
    "    Plots the number of unique users per month for each year in separate subplots.\n",
    "    Each subplot visualizes the distribution of unique user counts across different\n",
    "    months for a specific year.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data,\n",
    "                         expected to have 'Year', 'Month', and 'User' columns.\n",
    "    '''\n",
    "    # Basic data validation\n",
    "    if 'User' not in df.columns:\n",
    "        print(\"Error: 'User' column not found. Cannot count unique users.\")\n",
    "        return\n",
    "    if 'Year' not in df.columns:\n",
    "        print(\"Error: 'Year' column not found. Please ensure data preprocessing has been run (df['Start'] converted to datetime).\")\n",
    "        return\n",
    "    if 'Month' not in df.columns:\n",
    "        print(\"Error: 'Month' column not found. Please ensure data preprocessing has been run (df['Start'] converted to datetime).\")\n",
    "        return\n",
    "\n",
    "    # Group by Year and Month, then count unique Users\n",
    "    # This captures the total unique users for each month in each year\n",
    "    unique_users_per_month_year = df.groupby(['Year', 'Month'])['User'].nunique().reset_index(name='UniqueUserCount')\n",
    "\n",
    "    # Ensure Month is treated as a category or sorted correctly for plotting\n",
    "    # You might want to map month numbers to names for better readability on plots\n",
    "    month_names = {\n",
    "        1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',\n",
    "        7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'\n",
    "    }\n",
    "    unique_users_per_month_year['MonthName'] = unique_users_per_month_year['Month'].map(month_names)\n",
    "\n",
    "    # Get a sorted list of unique years present in the data for subplot creation\n",
    "    years = sorted(unique_users_per_month_year['Year'].unique())\n",
    "\n",
    "    if not years:\n",
    "        print(\"No data available to plot unique users per month by year after grouping.\")\n",
    "        return\n",
    "\n",
    "    # Determine the layout for subplots: 2 columns, rows calculated based on number of years\n",
    "    n_years = len(years)\n",
    "    cols = 2\n",
    "    rows = (n_years + cols - 1) // cols\n",
    "\n",
    "    # Create the figure and subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 6 * rows), squeeze=False)\n",
    "    axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "    # Iterate through each year and create a subplot\n",
    "    for i, year in enumerate(years):\n",
    "        # Filter data for the current year\n",
    "        # Sort by Month to ensure chronological order on the x-axis\n",
    "        data_for_year = unique_users_per_month_year[unique_users_per_month_year['Year'] == year].sort_values(by='Month')\n",
    "\n",
    "        if not data_for_year.empty:\n",
    "            # Use common_plot to draw a bar plot for the current year\n",
    "            common_plot(data_for_year, 'MonthName', 'UniqueUserCount',\n",
    "                        f'Unique Users by Month in {int(year)}', # Title for each subplot\n",
    "                        'Month', 'Number of Unique Users',\n",
    "                        color='mediumseagreen', # A distinct consistent color for these plots\n",
    "                        kind='bar',\n",
    "                        ax=axes[i]) # Pass the specific axes for the subplot\n",
    "        else:\n",
    "            # If a year has no data after filtering, hide its subplot\n",
    "            axes[i].set_visible(False)\n",
    "\n",
    "    # Hide any remaining unused subplots if the total number of years doesn't fill the grid perfectly\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    # Adjust layout to prevent overlapping titles/labels\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_unique_users_per_month_all_years(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_jobs_by_hour_of_day(df: pd.DataFrame):\n",
    "    '''\n",
    "    Plots the number of job submissions by hour of the day across all years.\n",
    "    This helps identify peak usage hours for the system.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data,\n",
    "                         expected to have a 'Submit' (datetime) column.\n",
    "    '''\n",
    "    # Basic data validation\n",
    "    if 'Submit' not in df.columns:\n",
    "        print(\"Error: 'Submit' column not found. Please ensure data preprocessing has been run.\")\n",
    "        return\n",
    "\n",
    "    # Extract the hour from the 'Submit' datetime column\n",
    "    df['HourOfDay'] = df['Submit'].dt.hour\n",
    "\n",
    "    # Group by HourOfDay and count the number of jobs\n",
    "    jobs_by_hour = df.groupby('HourOfDay').size().reset_index(name='JobCount')\n",
    "\n",
    "    # Ensure all 24 hours are present, filling missing hours with 0 job count\n",
    "    all_hours = pd.DataFrame({'HourOfDay': range(24)})\n",
    "    jobs_by_hour = pd.merge(all_hours, jobs_by_hour, on='HourOfDay', how='left').fillna(0)\n",
    "\n",
    "    # Plot the data using common_plot\n",
    "    plt.figure(figsize=(12, 6)) # Create a single figure for this plot\n",
    "    common_plot(jobs_by_hour, 'HourOfDay', 'JobCount',\n",
    "                'Job Submissions by Hour of Day (All Years)',\n",
    "                'Hour of Day (0-23)', 'Number of Jobs',\n",
    "                color='purple', # A distinct color for this plot\n",
    "                kind='bar')\n",
    "\n",
    "    # Adjust x-axis ticks to show all hours clearly\n",
    "    plt.xticks(range(0, 24))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_jobs_by_hour_of_day(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad0aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique_users_per_month(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plots the total number of unique users per month using a filled line plot.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing job data.\n",
    "                          Must have 'Start' (datetime) and 'User' columns.\n",
    "    \"\"\"\n",
    "    # Ensure 'Start' column is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['Start']):\n",
    "        print(\"Warning: 'Start' column is not datetime. Attempting conversion.\")\n",
    "        df['Start'] = pd.to_datetime(df['Start'], errors='coerce')\n",
    "        df.dropna(subset=['Start'], inplace=True)\n",
    "\n",
    "    # Create a 'YearMonth' column for aggregation\n",
    "    df['YearMonth'] = df['Start'].dt.to_period('M')\n",
    "\n",
    "    # Group by YearMonth and count unique users\n",
    "    unique_users_per_month = df.groupby('YearMonth')['User'].nunique().reset_index(name='UniqueUserCount')\n",
    "\n",
    "    # Convert YearMonth back to string for plotting\n",
    "    unique_users_per_month['YearMonth'] = unique_users_per_month['YearMonth'].astype(str)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Use seaborn lineplot and then fill_between for the filled effect\n",
    "    sns.lineplot(\n",
    "        data=unique_users_per_month,\n",
    "        x='YearMonth',\n",
    "        y='UniqueUserCount',\n",
    "        marker='o',\n",
    "        color='teal',\n",
    "        ax=ax\n",
    "    )\n",
    "    # Fill the area under the line\n",
    "    ax.fill_between(\n",
    "        unique_users_per_month['YearMonth'],\n",
    "        unique_users_per_month['UniqueUserCount'],\n",
    "        color='teal',\n",
    "        alpha=0.3\n",
    "    )\n",
    "\n",
    "    ax.set_title('Total Unique Users Per Month')\n",
    "    ax.set_xlabel('Time (Year-Month)')\n",
    "    ax.set_ylabel('Number of Unique Users')\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig('total_unique_users_per_month.png')\n",
    "    plt.close()\n",
    "    print(\"Plot 'total_unique_users_per_month.png' saved successfully.\")\n",
    "    \n",
    "\n",
    "plot_unique_users_per_month(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique_users_per_account_over_time(df: pd.DataFrame, weeks: int = 1, accounts: Optional[List[str]] = None):\n",
    "    '''\n",
    "    Plots the total number of unique users per account over time in subplots.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Start' (datetime), 'User', and 'Account' columns.\n",
    "    - weeks (int): The number of past weeks for which to plot the data. Defaults to 1.\n",
    "    - accounts (Optional[List[str]]): A list of account names to plot.\n",
    "                                          If None, unique users for all *unique* accounts will be plotted\n",
    "                                          in separate subplots.\n",
    "    '''\n",
    "    # Filter df for the specified number of weeks\n",
    "    filter_date = pd.Timestamp.now() - pd.DateOffset(weeks=weeks)\n",
    "    df_filtered_time = df[df['Start'] >= filter_date].copy()\n",
    "\n",
    "    # Ensure 'Start' column is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_filtered_time['Start']):\n",
    "        print(\"Warning: 'Start' column is not datetime. Attempting conversion.\")\n",
    "        df_filtered_time['Start'] = pd.to_datetime(df_filtered_time['Start'], errors='coerce')\n",
    "        df_filtered_time.dropna(subset=['Start'], inplace=True) # Drop rows where conversion failed\n",
    "\n",
    "    # Determine which accounts to plot\n",
    "    if accounts:\n",
    "        accounts_to_plot = [a for a in accounts if a in df_filtered_time['Account'].unique()]\n",
    "        if not accounts_to_plot:\n",
    "            print(f\"No data found for the specified accounts: {', '.join(accounts)} in the last {weeks} weeks after time filtering.\")\n",
    "            return\n",
    "    else:\n",
    "        accounts_to_plot = df_filtered_time['Account'].unique().tolist()\n",
    "        if not accounts_to_plot:\n",
    "            print(f\"No accounts found in the data for the last {weeks} weeks.\")\n",
    "            return\n",
    "\n",
    "    # Create a 'YearMonth' column for chronological ordering\n",
    "    df_filtered_time['YearMonth'] = df_filtered_time['Start'].dt.to_period('M').astype(str)\n",
    "\n",
    "    # Set up subplots\n",
    "    num_accounts = len(accounts_to_plot)\n",
    "    if num_accounts == 0:\n",
    "        print(\"No accounts to plot.\")\n",
    "        return\n",
    "\n",
    "    n_cols = min(3, num_accounts) # Max 3 columns\n",
    "    n_rows = (num_accounts + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 8, n_rows * 6), squeeze=False)\n",
    "    axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "    # Iterate through each account and create a subplot\n",
    "    for i, account_name in enumerate(accounts_to_plot):\n",
    "        ax = axes[i] # Get the current subplot axis\n",
    "\n",
    "        # Filter data for the current account\n",
    "        df_account = df_filtered_time[df_filtered_time['Account'] == account_name].copy()\n",
    "\n",
    "        if df_account.empty:\n",
    "            ax.set_title(f'No Data for {account_name}')\n",
    "            ax.set_xlabel('Time (Year-Month)')\n",
    "            ax.set_ylabel('Number of Unique Users')\n",
    "            ax.tick_params(axis='x', rotation=90)#, ha='right')\n",
    "            ax.text(0.5, 0.5, 'No data', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "            continue\n",
    "\n",
    "        # Group by YearMonth and count unique users for this account\n",
    "        unique_users_account = df_account.groupby('YearMonth')['User'].nunique().reset_index(name='UniqueUserCount')\n",
    "\n",
    "        # Plot unique users per month for the current account\n",
    "        sns.lineplot(data=unique_users_account, x='YearMonth', y='UniqueUserCount',\n",
    "                     marker='o', color='purple', ax=ax)\n",
    "\n",
    "        ax.set_title(f'Unique Users for {account_name}', fontsize=12)\n",
    "        ax.set_xlabel('Time (Year-Month)', fontsize=10)\n",
    "        ax.set_ylabel('Number of Unique Users', fontsize=10)\n",
    "\n",
    "        # Rotate x-axis labels\n",
    "        ax.tick_params(axis='x', rotation=90)#, ha='right')\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "        # Add a grid\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "        # Set the y-axis limit\n",
    "        max_y_account = unique_users_account['UniqueUserCount'].max()\n",
    "        ax.set_ylim(bottom=0, top=max_y_account * 1.1 if max_y_account > 0 else 1) # Ensure min 1 if no users\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Overall title for the figure\n",
    "    overall_title_suffix = f\" for selected accounts: {', '.join(accounts_to_plot)}\" if accounts else \" for All Accounts\"\n",
    "    fig.suptitle(f'Total Unique Users Per Account Over Time{overall_title_suffix}', fontsize=18, y=1.02)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    file_name = f'unique_users_per_account_over_time{overall_title_suffix.replace(\" \", \"_\").replace(\",\", \"\").lower()}.png'\n",
    "    # plt.savefig(file_name)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(f\"Plot '{file_name}' saved successfully.\")\n",
    "    \n",
    "plot_unique_users_per_account_over_time(df, weeks=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb4b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique_users_per_account_over_time(df: pd.DataFrame, weeks: int = 1, accounts: Optional[List[str]] = None):\n",
    "    '''\n",
    "    Plots the total number of unique users per account over time in subplots, using bar plots.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Start' (datetime), 'User', and 'Account' columns.\n",
    "    - weeks (int): The number of past weeks for which to plot the data. Defaults to 1.\n",
    "    - accounts (Optional[List[str]]): A list of account names to plot.\n",
    "                                          If None, unique users for all *unique* accounts will be plotted\n",
    "                                          in separate subplots.\n",
    "    '''\n",
    "    # Filter df for the specified number of weeks\n",
    "    filter_date = pd.Timestamp.now() - pd.DateOffset(weeks=weeks)\n",
    "    df_filtered_time = df[df['Start'] >= filter_date].copy()\n",
    "\n",
    "    # Ensure 'Start' column is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_filtered_time['Start']):\n",
    "        print(\"Warning: 'Start' column is not datetime. Attempting conversion.\")\n",
    "        df_filtered_time['Start'] = pd.to_datetime(df_filtered_time['Start'], errors='coerce')\n",
    "        df_filtered_time.dropna(subset=['Start'], inplace=True) # Drop rows where conversion failed\n",
    "\n",
    "    # Determine which accounts to plot\n",
    "    if accounts:\n",
    "        accounts_to_plot = [a for a in accounts if a in df_filtered_time['Account'].unique()]\n",
    "        if not accounts_to_plot:\n",
    "            print(f\"No data found for the specified accounts: {', '.join(accounts)} in the last {weeks} weeks after time filtering.\")\n",
    "            return\n",
    "    else:\n",
    "        accounts_to_plot = df_filtered_time['Account'].unique().tolist()\n",
    "        if not accounts_to_plot:\n",
    "            print(f\"No accounts found in the data for the last {weeks} weeks.\")\n",
    "            return\n",
    "\n",
    "    # Create a 'YearMonth' column for chronological ordering\n",
    "    df_filtered_time['YearMonth'] = df_filtered_time['Start'].dt.to_period('M').astype(str)\n",
    "\n",
    "    # Set up subplots\n",
    "    num_accounts = len(accounts_to_plot)\n",
    "    if num_accounts == 0:\n",
    "        print(\"No accounts to plot.\")\n",
    "        return\n",
    "\n",
    "    n_cols = min(3, num_accounts) # Max 3 columns\n",
    "    n_rows = (num_accounts + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 8, n_rows * 6), squeeze=False)\n",
    "    axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "    # Iterate through each account and create a subplot\n",
    "    for i, account_name in enumerate(accounts_to_plot):\n",
    "        ax = axes[i] # Get the current subplot axis\n",
    "\n",
    "        # Filter data for the current account\n",
    "        df_account = df_filtered_time[df_filtered_time['Account'] == account_name].copy()\n",
    "\n",
    "        if df_account.empty:\n",
    "            ax.set_title(f'No Data for {account_name}')\n",
    "            ax.set_xlabel('Time (Year-Month)')\n",
    "            ax.set_ylabel('Number of Unique Users')\n",
    "            ax.tick_params(axis='x', rotation=90)#, ha='right')\n",
    "            ax.text(0.5, 0.5, 'No data', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "            continue\n",
    "\n",
    "        # Group by YearMonth and count unique users for this account\n",
    "        unique_users_account = df_account.groupby('YearMonth')['User'].nunique().reset_index(name='UniqueUserCount')\n",
    "\n",
    "        # Plot unique users per month for the current account using common_plot\n",
    "        # common_plot will handle labels for kind='bar'\n",
    "        common_plot(\n",
    "            df=unique_users_account,\n",
    "            x='YearMonth',\n",
    "            y='UniqueUserCount',\n",
    "            title=f'Unique Users for {account_name}',\n",
    "            xlabel='Time (Year-Month)',\n",
    "            ylabel='Number of Unique Users',\n",
    "            color='purple',\n",
    "            kind='bar', # Changed to bar plot\n",
    "            ax=ax\n",
    "        )\n",
    "        # Manually adjust x-axis ticks rotation if common_plot defaults are not sufficient for bars\n",
    "        ax.tick_params(axis='x', rotation=90)#, ha='right')\n",
    "\n",
    "\n",
    "        # Set the y-axis limit\n",
    "        max_y_account = unique_users_account['UniqueUserCount'].max()\n",
    "        # Adjusted ylim to ensure it's set correctly after common_plot, as common_plot only sets it if ax is None\n",
    "        ax.set_ylim(bottom=0, top=max_y_account * 1.1 if max_y_account > 0 else 1) # Ensure min 1 if no users\n",
    "        ax.set_ylim(bottom=0, top=25)\n",
    "\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Overall title for the figure\n",
    "    overall_title_suffix = f\" for selected accounts: {', '.join(accounts_to_plot)}\" if accounts else \" for All Accounts\"\n",
    "    fig.suptitle(f'Total Unique Users Per Account Over Time (Bar Chart){overall_title_suffix}', fontsize=18, y=1.02) # Updated title for bar chart\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    file_name = f'unique_users_per_account_over_time_bar_chart{overall_title_suffix.replace(\" \", \"_\").replace(\",\", \"\").lower()}.png' # Updated file name\n",
    "    # plt.savefig(file_name)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(f\"Plot '{file_name}' saved successfully.\")\n",
    "\n",
    "\n",
    "plot_unique_users_per_account_over_time(df, weeks=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d78b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique_users_per_account_over_time(df: pd.DataFrame, weeks: int = 1, accounts: Optional[List[str]] = None):\n",
    "    '''\n",
    "    Plots the total number of unique users per account over time in subplots, using bar plots.\n",
    "    Creates new figures for every 3x3 grid of subplots.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Start' (datetime), 'User', and 'Account' columns.\n",
    "    - weeks (int): The number of past weeks for which to plot the data. Defaults to 1.\n",
    "    - accounts (Optional[List[str]]): A list of account names to plot.\n",
    "                                          If None, unique users for all *unique* accounts will be plotted\n",
    "                                          in separate subplots.\n",
    "    '''\n",
    "    # Filter df for the specified number of weeks\n",
    "    filter_date = pd.Timestamp.now() - pd.DateOffset(weeks=weeks)\n",
    "    df_filtered_time = df[df['Start'] >= filter_date].copy()\n",
    "\n",
    "    # Ensure 'Start' column is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_filtered_time['Start']):\n",
    "        print(\"Warning: 'Start' column is not datetime. Attempting conversion.\")\n",
    "        df_filtered_time['Start'] = pd.to_datetime(df_filtered_time['Start'], errors='coerce')\n",
    "        df_filtered_time.dropna(subset=['Start'], inplace=True) # Drop rows where conversion failed\n",
    "\n",
    "    # Determine which accounts to plot\n",
    "    if accounts:\n",
    "        accounts_to_plot = [a for a in accounts if a in df_filtered_time['Account'].unique()]\n",
    "        if not accounts_to_plot:\n",
    "            print(f\"No data found for the specified accounts: {', '.join(accounts)} in the last {weeks} weeks after time filtering.\")\n",
    "            return\n",
    "    else:\n",
    "        accounts_to_plot = df_filtered_time['Account'].unique().tolist()\n",
    "        if not accounts_to_plot:\n",
    "            print(f\"No accounts found in the data for the last {weeks} weeks.\")\n",
    "            return\n",
    "\n",
    "    # Create a 'YearMonth' column for chronological ordering\n",
    "    df_filtered_time['YearMonth'] = df_filtered_time['Start'].dt.to_period('M').astype(str)\n",
    "\n",
    "    # Fixed subplot grid size\n",
    "    PLOT_COLS = 3\n",
    "    PLOT_ROWS = 3\n",
    "    SUBPLOTS_PER_FIGURE = PLOT_COLS * PLOT_ROWS\n",
    "\n",
    "    # Iterate through accounts in chunks and create a new figure for each chunk\n",
    "    for chunk_idx in range(0, len(accounts_to_plot), SUBPLOTS_PER_FIGURE):\n",
    "        accounts_chunk = accounts_to_plot[chunk_idx : chunk_idx + SUBPLOTS_PER_FIGURE]\n",
    "        num_accounts_in_chunk = len(accounts_chunk)\n",
    "\n",
    "        fig, axes = plt.subplots(PLOT_ROWS, PLOT_COLS, figsize=(PLOT_COLS * 8, PLOT_ROWS * 6), squeeze=False)\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, account_name in enumerate(accounts_chunk):\n",
    "            ax = axes[i]\n",
    "\n",
    "            # Filter data for the current account\n",
    "            df_account = df_filtered_time[df_filtered_time['Account'] == account_name].copy()\n",
    "\n",
    "            if df_account.empty:\n",
    "                ax.set_title(f'No Data for {account_name}')\n",
    "                ax.set_xlabel('Time (Year-Month)')\n",
    "                ax.set_ylabel('Number of Unique Users')\n",
    "                ax.tick_params(axis='x', rotation=90)#, ha='right')\n",
    "                ax.text(0.5, 0.5, 'No data', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "                continue\n",
    "\n",
    "            # Group by YearMonth and count unique users for this account\n",
    "            unique_users_account = df_account.groupby('YearMonth')['User'].nunique().reset_index(name='UniqueUserCount')\n",
    "\n",
    "            # Plot unique users per month for the current account using common_plot\n",
    "            common_plot(\n",
    "                df=unique_users_account,\n",
    "                x='YearMonth',\n",
    "                y='UniqueUserCount',\n",
    "                title=f'Unique Users for {account_name}',\n",
    "                xlabel='Time (Year-Month)',\n",
    "                ylabel='Number of Unique Users',\n",
    "                color='purple',\n",
    "                kind='bar', # Changed to bar plot\n",
    "                ax=ax\n",
    "            )\n",
    "            # Manually adjust x-axis ticks rotation if common_plot defaults are not sufficient for bars\n",
    "            ax.tick_params(axis='x', rotation=90)#, ha='right')\n",
    "\n",
    "            # Set the y-axis limit\n",
    "            max_y_account = unique_users_account['UniqueUserCount'].max()\n",
    "            ax.set_ylim(bottom=0, top=max_y_account * 1.1 if max_y_account > 0 else 1)\n",
    "            ax.set_ylim(bottom=0, top=25)  # Adjusted ylim to ensure it's set correctly after common_plot, as common_plot only sets it if ax is None\n",
    "\n",
    "        # Hide any unused subplots in the current figure\n",
    "        for j in range(num_accounts_in_chunk, SUBPLOTS_PER_FIGURE):\n",
    "            fig.delaxes(axes[j])\n",
    "\n",
    "        # Overall title for the current figure\n",
    "        overall_title_suffix = f\" for selected accounts (Part {chunk_idx // SUBPLOTS_PER_FIGURE + 1})\" if accounts else f\" for All Accounts (Part {chunk_idx // SUBPLOTS_PER_FIGURE + 1})\"\n",
    "        fig.suptitle(f'Total Unique Users Per Account Over Time (Bar Chart){overall_title_suffix}', fontsize=18, y=1.02)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "        file_name = f'unique_users_per_account_over_time_bar_chart_part{chunk_idx // SUBPLOTS_PER_FIGURE + 1}{overall_title_suffix.replace(\" \", \"_\").replace(\",\", \"\").lower().replace(\"(\", \"\").replace(\")\", \"\")}.png'\n",
    "        # plt.savefig(file_name)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        print(f\"Plot '{file_name}' saved successfully.\")\n",
    "\n",
    "\n",
    "plot_unique_users_per_account_over_time(df, weeks=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b644712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_yearly_total_cost(df):\n",
    "    \"\"\"\n",
    "    Plots the total AWS and NeSI costs per year across all accounts.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Year', 'aws_cost', and 'nesi_cost' columns.\n",
    "    \"\"\"\n",
    "    # Group by 'Year' and sum 'aws_cost' and 'nesi_cost'\n",
    "    yearly_cost = df.groupby('Year').agg({'aws_cost': 'sum', 'nesi_cost': 'sum'}).reset_index()\n",
    "\n",
    "    # Ensure 'Year' is treated as a category for proper bar plotting\n",
    "    yearly_cost['Year'] = yearly_cost['Year'].astype(str)\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs('plots/yearly_costs/', exist_ok=True)\n",
    "\n",
    "    for cost_type in ['aws_cost', 'nesi_cost']:\n",
    "        cost_title_prefix = 'AWS Total Cost' if cost_type == 'aws_cost' else 'NeSI Total Cost'\n",
    "        cost_subtitle_text = 'Based on 2020 best matched instance for given core count' if cost_type == 'aws_cost' else ''\n",
    "        save_folder = 'plots/yearly_costs/'\n",
    "\n",
    "        # Filter out years with no data for the current cost type to avoid empty plots\n",
    "        years_with_data = yearly_cost[yearly_cost[cost_type] > 0]['Year'].unique().tolist()\n",
    "        if not years_with_data:\n",
    "            print(f\"No {cost_title_prefix} data found for any year.\")\n",
    "            continue\n",
    "        \n",
    "        # Print the yearly total cost table\n",
    "        print(\"\\n--- Yearly Total Costs ---\")\n",
    "        print(yearly_cost[['Year', 'aws_cost', 'nesi_cost']].sort_values(by='Year').to_string())\n",
    "        print(\"--------------------------\\n\")\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "        common_plot(\n",
    "            df=yearly_cost[yearly_cost[cost_type] > 0], # Only plot years with data\n",
    "            x='Year',\n",
    "            y=cost_type,\n",
    "            title=f'',\n",
    "            xlabel='Year',\n",
    "            ylabel='Total Cost (NZD)',\n",
    "            color='purple', # Choose a different color for total yearly plots\n",
    "            kind='bar',\n",
    "            ax=ax,\n",
    "            # ylim=(1000000, 4000000)  # Set y-axis limit to start from 0, auto scale top\n",
    "        )\n",
    "        # Ensure y-axis starts from 0 and scales appropriately\n",
    "        max_cost = yearly_cost[cost_type].max()\n",
    "        ax.set_ylim(bottom=0, top=max_cost * 1.1 if max_cost > 0 else 1)\n",
    "        # Set y-axis ticks\n",
    "        # ax.set_yticks(range(0, int(3e6) + 1, int(1e6)))\n",
    "        # yscale is log\n",
    "        # ax.set_yscale('log')\n",
    "        # Overall title for the current figure (suptitle)\n",
    "        overall_title = f'{cost_title_prefix} Per Year\\n{cost_subtitle_text}'\n",
    "        fig.suptitle(overall_title)#, fontsize=11, y=0.02, va='bottom', ha='center') # Moved to bottom\n",
    "\n",
    "        # Adjust layout to make space for the suptitle at the bottom\n",
    "        plt.tight_layout(rect=[0, 0.08, 1, 1]) # Adjusted bottom margin (0.08 is an example, may need tweaking)\n",
    "        \n",
    "        \n",
    "        plot_file_name = f\"{save_folder}total_yearly_{cost_type}.png\"\n",
    "        # plt.savefig(plot_file_name)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        \n",
    "        print(f\"Plot '{plot_file_name}' saved successfully.\")\n",
    "        \n",
    "        \n",
    "plot_yearly_total_cost(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee89b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_costs_per_month(df):\n",
    "    \"\"\"\n",
    "    Plots AWS and NeSI costs per month for each account, using a 3x3 subplot grid\n",
    "    and creating new figures as needed to accommodate all accounts.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Start' (datetime), 'Account', 'aws_cost', and 'nesi_cost' columns.\n",
    "    \"\"\"\n",
    "    # Group by 'Account', 'Year' and 'Month' and sum 'aws_cost' and 'nesi_cost'\n",
    "    cost_per_month = df.groupby(['Account', 'Year', 'Month']).agg({'aws_cost': 'sum', 'nesi_cost': 'sum'}).reset_index()\n",
    "\n",
    "    # Convert 'Year' and 'Month' to integer, then to string, combine them, and convert to datetime\n",
    "    # This creates a sortable chronological order for the x-axis\n",
    "    cost_per_month['YearMonth'] = pd.to_datetime(\n",
    "        cost_per_month['Year'].astype(int).astype(str) + '-' +\n",
    "        cost_per_month['Month'].astype(int).astype(str)\n",
    "    )\n",
    "\n",
    "    # Get unique accounts for plotting\n",
    "    accounts = cost_per_month['Account'].unique()\n",
    "\n",
    "    # Capitalize 'Account' names for consistent display on plots\n",
    "    cost_per_month['Account'] = cost_per_month['Account'].str.upper()\n",
    "\n",
    "    # Ensure the output directories exist\n",
    "    os.makedirs('plots/monthly_costs/aws/', exist_ok=True)\n",
    "    os.makedirs('plots/monthly_costs/nesi/', exist_ok=True)\n",
    "\n",
    "    # Fixed subplot grid size\n",
    "    PLOT_COLS = 3\n",
    "    PLOT_ROWS = 3\n",
    "    SUBPLOTS_PER_FIGURE = PLOT_COLS * PLOT_ROWS\n",
    "\n",
    "    for cost_type in ['aws_cost', 'nesi_cost']:\n",
    "        cost_title_prefix = 'AWS Cost' if cost_type == 'aws_cost' else 'NeSI Cost'\n",
    "        cost_subtitle_text = 'Based on 2020 best matched instance for given core count' if cost_type == 'aws_cost' else ''\n",
    "        save_folder = 'plots/monthly_costs/aws/' if cost_type == 'aws_cost' else 'plots/monthly_costs/nesi/'\n",
    "\n",
    "        # Filter out accounts with no data for the current cost type to avoid empty plots\n",
    "        accounts_with_data = cost_per_month[cost_per_month[cost_type] > 0]['Account'].unique().tolist()\n",
    "        if not accounts_with_data:\n",
    "            print(f\"No {cost_title_prefix} data found for any account.\")\n",
    "            continue\n",
    "\n",
    "        # Iterate through accounts in chunks and create a new figure for each chunk\n",
    "        for chunk_idx in range(0, len(accounts_with_data), SUBPLOTS_PER_FIGURE):\n",
    "            accounts_chunk = accounts_with_data[chunk_idx : chunk_idx + SUBPLOTS_PER_FIGURE]\n",
    "            num_accounts_in_chunk = len(accounts_chunk)\n",
    "\n",
    "            fig, axes = plt.subplots(PLOT_ROWS, PLOT_COLS, figsize=(PLOT_COLS * 8, PLOT_ROWS * 6), squeeze=False)\n",
    "            axes = axes.flatten()\n",
    "\n",
    "            for i, account_name in enumerate(accounts_chunk):\n",
    "                ax = axes[i]\n",
    "\n",
    "                account_data = cost_per_month[cost_per_month['Account'] == account_name].copy()\n",
    "\n",
    "                if account_data.empty or account_data[cost_type].sum() == 0:\n",
    "                    ax.set_title(f'No {cost_title_prefix} for {account_name}')\n",
    "                    ax.set_xlabel('Date')\n",
    "                    ax.set_ylabel('Cost')\n",
    "                    ax.tick_params(axis='x', rotation=90)#, ha='right')\n",
    "                    ax.text(0.5, 0.5, 'No data', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "                    continue\n",
    "\n",
    "                # Use common_plot for consistency\n",
    "                common_plot(\n",
    "                    df=account_data,\n",
    "                    x='YearMonth',\n",
    "                    y=cost_type,\n",
    "                    title=f'{cost_title_prefix} for {account_name} Per Month',\n",
    "                    xlabel='Date',\n",
    "                    ylabel='Cost',\n",
    "                    color='blue', # Default color for cost plots\n",
    "                    kind='bar',\n",
    "                    ax=ax\n",
    "                )\n",
    "                # Manually adjust x-axis ticks rotation if common_plot defaults are not sufficient for bars\n",
    "                ax.tick_params(axis='x', rotation=90)#, ha='right')\n",
    "\n",
    "                # Ensure y-axis starts from 0 and scales appropriately\n",
    "                max_cost = account_data[cost_type].max()\n",
    "                ax.set_ylim(bottom=0, top=max_cost * 1.1 if max_cost > 0 else 1)\n",
    "\n",
    "\n",
    "            # Hide any unused subplots in the current figure\n",
    "            for j in range(num_accounts_in_chunk, SUBPLOTS_PER_FIGURE):\n",
    "                fig.delaxes(axes[j])\n",
    "\n",
    "            # Overall title for the current figure\n",
    "            overall_title_suffix = f\" (Part {chunk_idx // SUBPLOTS_PER_FIGURE + 1})\"\n",
    "            fig.suptitle(f'Monthly {cost_title_prefix} Per Account{overall_title_suffix}\\n{cost_subtitle_text}', fontsize=18, y=1.02)\n",
    "\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust rect to make space for the suptitle\n",
    "            plot_file_name = f\"{save_folder}{cost_type}_{chunk_idx // SUBPLOTS_PER_FIGURE + 1}.png\"\n",
    "            # plt.savefig(plot_file_name)\n",
    "            plt.show()\n",
    "            plt.close(fig) # Close the figure to free memory\n",
    "            print(f\"Plot '{plot_file_name}' saved successfully.\")\n",
    "            \n",
    "            \n",
    "plot_costs_per_month(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ef231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_total_costs_per_account(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calculates and prints a table showing the total AWS and NeSI costs for each account.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Account', 'aws_cost', and 'nesi_cost' columns.\n",
    "    \"\"\"\n",
    "    # Group by 'Account' and sum 'aws_cost' and 'nesi_cost'\n",
    "    total_costs = df.groupby('Account').agg(\n",
    "        Total_AWS_Cost=('aws_cost', 'sum'),\n",
    "        Total_NeSI_Cost=('nesi_cost', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Capitalize 'Account' names for consistent display\n",
    "    total_costs['Account'] = total_costs['Account'].str.upper()\n",
    "\n",
    "    print(\"\\nTotal AWS and NeSI Costs per Account:\")\n",
    "    # Format the cost columns to 2 decimal places for better readability\n",
    "    total_costs['Total_AWS_Cost'] = total_costs['Total_AWS_Cost'].map('{:.2f}'.format)\n",
    "    total_costs['Total_NeSI_Cost'] = total_costs['Total_NeSI_Cost'].map('{:.2f}'.format)\n",
    "    print(total_costs.to_string(index=False))\n",
    "    \n",
    "print_total_costs_per_account(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_total_costs_per_account(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calculates and prints tables showing the total AWS and NeSI costs for each account,\n",
    "    broken down by year.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Account', 'Year', 'aws_cost', and 'nesi_cost' columns.\n",
    "    \"\"\"\n",
    "    # Get unique years from the DataFrame and drop NaN values\n",
    "    unique_years = sorted(df['Year'].dropna().unique())\n",
    "\n",
    "    if not unique_years:\n",
    "        print(\"No year data found to calculate costs.\")\n",
    "        return\n",
    "\n",
    "    for year in unique_years:\n",
    "        print(f\"\\n--- Total AWS and NeSI Costs per Account for Year: {int(year)} ---\")\n",
    "        \n",
    "        # Filter data for the current year\n",
    "        df_year = df[df['Year'] == year].copy()\n",
    "\n",
    "        if df_year.empty:\n",
    "            print(f\"No data available for year {int(year)}.\")\n",
    "            continue\n",
    "\n",
    "        # Group by 'Account' and sum 'aws_cost' and 'nesi_cost' for the current year\n",
    "        total_costs_year = df_year.groupby('Account').agg(\n",
    "            Total_AWS_Cost=('aws_cost', 'sum'),\n",
    "            Total_NeSI_Cost=('nesi_cost', 'sum')\n",
    "        ).reset_index()\n",
    "\n",
    "        # Capitalize 'Account' names for consistent display\n",
    "        total_costs_year['Account'] = total_costs_year['Account'].str.upper()\n",
    "\n",
    "        # Format the cost columns to 2 decimal places for better readability\n",
    "        total_costs_year['Total_AWS_Cost'] = total_costs_year['Total_AWS_Cost'].map('{:.2f}'.format)\n",
    "        total_costs_year['Total_NeSI_Cost'] = total_costs_year['Total_NeSI_Cost'].map('{:.2f}'.format)\n",
    "        print(total_costs_year.to_string(index=False))\n",
    "        \n",
    "        \n",
    "print_total_costs_per_account(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_capacity_daily(df, weeks=1):\n",
    "    '''\n",
    "    Plot the total available and requested capacity daily.\n",
    "    Total configured capacity is 5535 + 14335 + 1004= 20874 GB\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Start' (datetime), 'ReqMem', and 'User' columns.\n",
    "    - weeks (int): The number of past weeks for which to plot the data. Defaults to 1.\n",
    "    '''\n",
    "    # Filter df for the specified number of weeks\n",
    "    filter_date = pd.Timestamp.now() - pd.DateOffset(weeks=weeks)\n",
    "    df_filtered = df[df['Start'] >= filter_date].copy()\n",
    "\n",
    "    # Ensure ReqMem is in GB (assuming it's initially in MB as per memfix)\n",
    "    # This check prevents re-conversion if 'ReqMem' is already in GB\n",
    "    if 'ReqMem' in df_filtered.columns and df_filtered['ReqMem'].max() > 2048:\n",
    "        df_filtered['ReqMem_GB'] = df_filtered['ReqMem'] / 1024\n",
    "    else:\n",
    "        df_filtered['ReqMem_GB'] = df_filtered['ReqMem'] # Assume it's already GB if max is small\n",
    "\n",
    "    print(f\"Plotting capacity for the last {weeks} weeks\")\n",
    "    print(f\"Total Jobs in the last {weeks} weeks: {len(df_filtered)}\")\n",
    "\n",
    "    # Group by date and calculate total requested capacity and total available capacity\n",
    "    daily_capacity = df_filtered.groupby(df_filtered['Start'].dt.date).agg(\n",
    "        TotalRequestedCapacity=('ReqMem_GB', 'sum'),\n",
    "        TotalAvailableCapacity=('User', lambda x: 2048 * x.nunique()) # Correctly calculates available capacity based on unique users\n",
    "    ).reset_index()\n",
    "\n",
    "    # Convert 'Start' column in daily_capacity back to datetime objects for plotting\n",
    "    daily_capacity['Start'] = pd.to_datetime(daily_capacity['Start'])\n",
    "\n",
    "    print(daily_capacity.head())\n",
    "\n",
    "    # Plotting using matplotlib and seaborn for multiple lines on one plot\n",
    "    fig, current_ax = plt.subplots(figsize=(14, 7)) # Create figure and get axis object directly\n",
    "\n",
    "    # Plot requested capacity\n",
    "    sns.lineplot(data=daily_capacity, x='Start', y='TotalRequestedCapacity',\n",
    "                 label='Total Requested Capacity (GB)', color='dodgerblue', linewidth=2, ax=current_ax)\n",
    "\n",
    "    # Plot available capacity\n",
    "    # sns.lineplot(data=daily_capacity, x='Start', y='TotalAvailableCapacity',\n",
    "    #              label='Total Available Capacity (GB)', color='orange', linewidth=2, ax=current_ax)\n",
    "\n",
    "    # Plot a horizontal line for the total configured capacity (20874 GB)\n",
    "    current_ax.axhline(y=20874, color='red', linestyle='--', label='Total Configured Capacity (Configured: 20874 GB)', linewidth=2)\n",
    "\n",
    "    # Set title and labels with consistent formatting using the axis object\n",
    "    current_ax.set_title('Daily Requested vs Configured Memory Capacity', fontsize=16)\n",
    "    current_ax.set_xlabel('Date', fontsize=12)\n",
    "    current_ax.set_ylabel('Capacity (GB)', fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels for better readability of dates using tick_params\n",
    "    current_ax.tick_params(axis='x', rotation=0) # Removed 'ha' keyword\n",
    "    current_ax.tick_params(axis='y', labelsize=10) # Consistent tick label font size for y-axis\n",
    "\n",
    "    # Add a grid for easier reading of values\n",
    "    current_ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    # Set the y-axis limit\n",
    "    # current_ax.set_ylim(bottom=0, top=7.5e5) # Set lower limit to 0 and upper limit to 21000 GB\n",
    "    \n",
    "    # Place legend below the plot\n",
    "    current_ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), # Adjusted bbox_to_anchor for below plot\n",
    "                      ncol=1, # One column for legend items\n",
    "                      fontsize=10,\n",
    "                      frameon=False) # Remove frame around legend for cleaner look\n",
    "\n",
    "    # Place legend outside the plot area if it overlaps, or in a less obstructive spot\n",
    "    # current_ax.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=10)\n",
    "    \n",
    "\n",
    "    # Adjust layout to prevent overlapping elements\n",
    "    # plt.tight_layout(rect=[0, 0.1, 0.1, 1]) # Adjust rect to make space for the legend\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    \n",
    "plot_capacity_daily(df, weeks=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_capacity_daily(df, weeks=1):\n",
    "    '''\n",
    "    Plot the total available and requested capacity daily.\n",
    "    Total configured capacity is 5535 + 14335 + 1004= 20874 GB\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Start' (datetime), 'ReqMem', and 'User' columns.\n",
    "    - weeks (int): The number of past weeks for which to plot the data. Defaults to 1.\n",
    "    '''\n",
    "    # Filter df for the specified number of weeks\n",
    "    filter_date = pd.Timestamp.now() - pd.DateOffset(weeks=weeks)\n",
    "    df_filtered = df[df['Start'] >= filter_date].copy()\n",
    "\n",
    "    # Ensure ReqMem is in GB (assuming it's initially in MB as per memfix)\n",
    "    # This check prevents re-conversion if 'ReqMem' is already in GB\n",
    "    if 'ReqMem' in df_filtered.columns and df_filtered['ReqMem'].max() > 2048:\n",
    "        df_filtered['ReqMem_GB'] = df_filtered['ReqMem'] / 1024\n",
    "    else:\n",
    "        df_filtered['ReqMem_GB'] = df_filtered['ReqMem'] # Assume it's already GB if max is small\n",
    "\n",
    "    print(f\"Plotting capacity for the last {weeks} weeks\")\n",
    "    print(f\"Total Jobs in the last {weeks} weeks: {len(df_filtered)}\")\n",
    "\n",
    "    # Group by date and calculate total requested capacity and total available capacity\n",
    "    daily_capacity = df_filtered.groupby(df_filtered['Start'].dt.date).agg(\n",
    "        TotalRequestedCapacity=('ReqMem_GB', 'sum'),\n",
    "        TotalAvailableCapacity=('User', lambda x: 20874) # Corrected: total configured capacity is a fixed number\n",
    "    ).reset_index()\n",
    "\n",
    "    # Convert 'Start' column in daily_capacity back to datetime objects for plotting\n",
    "    daily_capacity.rename(columns={'index': 'Start'}, inplace=True) # Rename 'index' to 'Start' for consistency\n",
    "    daily_capacity['Start'] = pd.to_datetime(daily_capacity['Start'])\n",
    "\n",
    "    # Filter out data points where TotalRequestedCapacity is more than 1e6\n",
    "    original_rows = len(daily_capacity)\n",
    "    requested_capacity_threshold = 1e6 # 1e6 GB = 1 TB\n",
    "    daily_capacity = daily_capacity[daily_capacity['TotalRequestedCapacity'] <= requested_capacity_threshold].copy()\n",
    "    filtered_rows = len(daily_capacity)\n",
    "\n",
    "    if original_rows > filtered_rows:\n",
    "        print(f\"Filtered out {original_rows - filtered_rows} days where TotalRequestedCapacity exceeded {requested_capacity_threshold / 1e6:.0f} TB.\")\n",
    "    else:\n",
    "        print(\"No days filtered based on TotalRequestedCapacity threshold.\")\n",
    "\n",
    "\n",
    "    print(daily_capacity.head())\n",
    "\n",
    "    # Plotting using matplotlib and seaborn for multiple lines on one plot\n",
    "    fig, current_ax = plt.subplots(figsize=(14, 7)) # Create figure and get axis object directly\n",
    "\n",
    "    # Plot requested capacity\n",
    "    sns.lineplot(data=daily_capacity, x='Start', y='TotalRequestedCapacity',\n",
    "                 label='Total Requested Capacity (GB)', color='dodgerblue', linewidth=2, ax=current_ax)\n",
    "\n",
    "    # Plot available capacity\n",
    "    sns.lineplot(data=daily_capacity, x='Start', y='TotalAvailableCapacity',\n",
    "                 label='Total Available Capacity (GB)', color='orange', linewidth=2, ax=current_ax)\n",
    "\n",
    "    # Plot a horizontal line for the total configured capacity (20874 GB)\n",
    "    total_configured_capacity = 20874 # Defined as a variable\n",
    "    current_ax.axhline(y=total_configured_capacity, color='red', linestyle='--', label=f'Total Configured Capacity ({total_configured_capacity} GB)', linewidth=2)\n",
    "\n",
    "    # Add text label for the horizontal line\n",
    "    # Position the text just above the line, at the start of the x-axis, with appropriate alignment\n",
    "    text_x_position = daily_capacity['Start'].min() # Position at the start of the data range\n",
    "    text_y_position = total_configured_capacity * 1.01 # Slightly above the line\n",
    "    current_ax.text(text_x_position, text_y_position, f'Configured Capacity: {total_configured_capacity} GB',\n",
    "                    color='red', fontsize=10, verticalalignment='bottom', horizontalalignment='left',\n",
    "                    bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "\n",
    "\n",
    "    # Set title and labels with consistent formatting using the axis object\n",
    "    current_ax.set_title('Daily Requested vs Configured Memory Capacity', fontsize=16)\n",
    "    current_ax.set_xlabel('Date', fontsize=12)\n",
    "    current_ax.set_ylabel('Capacity (GB)', fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels for better readability of dates using tick_params\n",
    "    current_ax.tick_params(axis='x', rotation=0)#, ha='right') # Rotate and align for dates\n",
    "    current_ax.tick_params(axis='y', labelsize=10) # Consistent tick label font size for y-axis\n",
    "\n",
    "    # Add a grid for easier reading of values\n",
    "    current_ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    # Set the y-axis limit - ensure it's dynamic but also accounts for the configured capacity\n",
    "    max_y = max(daily_capacity['TotalRequestedCapacity'].max(), total_configured_capacity)\n",
    "    current_ax.set_ylim(bottom=0, top=max_y * 1.1) # Set lower limit to 0 and upper limit slightly above max value\n",
    "\n",
    "    # Place legend below the plot\n",
    "    current_ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), # Adjusted bbox_to_anchor for below plot\n",
    "                      ncol=1, # One column for legend items\n",
    "                      fontsize=10,\n",
    "                      frameon=False) # Remove frame around legend for cleaner look\n",
    "\n",
    "    # Adjust layout to prevent overlapping elements\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 1]) # Adjust rect to make space for the legend\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    \n",
    "plot_capacity_daily(df, weeks=104) # Call the function with 104 weeks (2 years) of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc0c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_capacity_daily(df: pd.DataFrame, weeks: int = 1, partitions: Optional[List[str]] = None, requested_memory_threshold: float = 2e5):\n",
    "    '''\n",
    "    Plot the total available and requested capacity daily for selected partitions in subplots.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Start' (datetime), 'ReqMem', and 'User' columns.\n",
    "    - weeks (int): The number of past weeks for which to plot the data. Defaults to 1.\n",
    "    - partitions (Optional[List[str]]): A list of partition names to plot.\n",
    "                                          If None, requested capacity for all *unique* partitions will be plotted\n",
    "                                          in separate subplots.\n",
    "    - requested_memory_threshold (float): The maximum allowed TotalRequestedCapacity (in GB) for a day.\n",
    "                                        Days exceeding this will be dropped. Defaults to 1e6 GB (1 TB).\n",
    "    '''\n",
    "    # Define configured capacity for each known partition\n",
    "    # These values are based on the sum provided in the previous prompt: 5535 + 14335 + 1004 = 20874 GB\n",
    "    # Assuming the partitions are 'partition1', 'partition2', 'partition3' or similar.\n",
    "    # You might need to adjust these names based on your actual data's 'Partition' column values.\n",
    "    partition_configured_capacity = {\n",
    "        'parallel': 502*28+250,   # Example: Assuming 'cpu' partition has this capacity\n",
    "        'gpu': 502*3,    # Example: Assuming 'gpu' partition has this capacity\n",
    "        'longrun': 502*2,  # Example: Assuming 'short' partition has this capacity\n",
    "        'quicktest': 502*4,\n",
    "        'bigmem': 1006*4,\n",
    "        # Add other partitions and their capacities as needed.\n",
    "        # A fallback for unknown partitions could be added, e.g., 0 or the total system capacity.\n",
    "    }\n",
    "    # Fallback for partitions not explicitly defined, or a sensible default\n",
    "    default_configured_capacity = 20874 # Using the sum as a generic fallback if a partition isn't mapped\n",
    "\n",
    "    # Filter df for the specified number of weeks\n",
    "    filter_date = pd.Timestamp.now() - pd.DateOffset(weeks=weeks)\n",
    "    df_filtered_time = df[df['Start'] >= filter_date].copy()\n",
    "\n",
    "    # Ensure ReqMem is in GB (assuming it's initially in MB as per memfix)\n",
    "    df_filtered_time['ReqMem_GB'] = df_filtered_time['ReqMem'] / 1024\n",
    "\n",
    "    # Determine which partitions to plot\n",
    "    if partitions:\n",
    "        partitions_to_plot = [p for p in partitions if p in df_filtered_time['Partition'].unique()]\n",
    "        if not partitions_to_plot:\n",
    "            print(f\"No data found for the specified partitions: {', '.join(partitions)} in the last {weeks} weeks after time filtering.\")\n",
    "            return\n",
    "    else:\n",
    "        partitions_to_plot = df_filtered_time['Partition'].unique().tolist()\n",
    "        if not partitions_to_plot:\n",
    "            print(f\"No partitions found in the data for the last {weeks} weeks.\")\n",
    "            return\n",
    "\n",
    "    # Set up subplots\n",
    "    num_partitions = len(partitions_to_plot)\n",
    "    if num_partitions == 0:\n",
    "        print(\"No partitions to plot.\")\n",
    "        return\n",
    "\n",
    "    # Calculate rows and columns for subplot grid, aiming for a squarish layout\n",
    "    n_cols = min(3, num_partitions) # Max 3 columns\n",
    "    n_rows = (num_partitions + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 8, n_rows * 6), squeeze=False)\n",
    "    axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "    # Iterate through each partition and create a subplot\n",
    "    for i, partition_name in enumerate(partitions_to_plot):\n",
    "        ax = axes[i] # Get the current subplot axis\n",
    "\n",
    "        # Get the configured capacity for the current partition, with a fallback\n",
    "        current_configured_capacity = partition_configured_capacity.get(partition_name, default_configured_capacity)\n",
    "\n",
    "        # Filter data for the current partition\n",
    "        df_partition = df_filtered_time[df_filtered_time['Partition'] == partition_name].copy()\n",
    "\n",
    "        if df_partition.empty:\n",
    "            ax.set_title(f'No Data for {partition_name}')\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_ylabel('Capacity (GB)')\n",
    "            ax.tick_params(axis='x', rotation=45, ha='right')\n",
    "            ax.text(0.5, 0.5, 'No data', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "            continue\n",
    "\n",
    "        # Group by date for the current partition\n",
    "        daily_capacity_requested_partition = df_partition.groupby(df_partition['Start'].dt.date)['ReqMem_GB'].sum().reset_index(name='TotalRequestedCapacity')\n",
    "        daily_capacity_requested_partition.rename(columns={'Start': 'Date'}, inplace=True)\n",
    "        daily_capacity_requested_partition['Date'] = pd.to_datetime(daily_capacity_requested_partition['Date'])\n",
    "\n",
    "        # Filter out data points where TotalRequestedCapacity is more than the threshold for the current partition\n",
    "        original_rows_part = len(daily_capacity_requested_partition)\n",
    "        daily_capacity_requested_partition = daily_capacity_requested_partition[daily_capacity_requested_partition['TotalRequestedCapacity'] <= requested_memory_threshold].copy()\n",
    "        filtered_rows_part = len(daily_capacity_requested_partition)\n",
    "\n",
    "        if original_rows_part > filtered_rows_part:\n",
    "            print(f\"Filtered out {original_rows_part - filtered_rows_part} days for partition '{partition_name}' where TotalRequestedCapacity exceeded {requested_memory_threshold / 1e3:.0f} GB ({requested_memory_threshold / 1e6:.0f} TB).\")\n",
    "\n",
    "        if daily_capacity_requested_partition.empty:\n",
    "            ax.set_title(f'No Plottable Data for {partition_name}')\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_ylabel('Capacity (GB)')\n",
    "            ax.tick_params(axis='x', rotation=45, ha='right')\n",
    "            ax.text(0.5, 0.5, 'No plottable data', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "            continue\n",
    "\n",
    "        # Plot requested capacity for the current partition\n",
    "        sns.lineplot(data=daily_capacity_requested_partition, x='Date', y='TotalRequestedCapacity',\n",
    "                     label=f'Requested Capacity ({partition_name} GB)', linewidth=2, ax=ax)\n",
    "\n",
    "        # Plot a horizontal line for the partition's configured capacity\n",
    "        ax.axhline(y=current_configured_capacity, color='red', linestyle='--', label=f'Configured Total ({current_configured_capacity} GB)', linewidth=2)\n",
    "\n",
    "        # Add text label for the horizontal line (adjusted for subplot)\n",
    "        text_x_position = daily_capacity_requested_partition['Date'].min()\n",
    "        text_y_position = current_configured_capacity * 1.01\n",
    "        ax.text(text_x_position, text_y_position, f'Configured: {current_configured_capacity} GB',\n",
    "                color='red', fontsize=8, verticalalignment='bottom', horizontalalignment='left',\n",
    "                bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "\n",
    "\n",
    "        # Set subplot title and labels\n",
    "        ax.set_title(f'Daily Capacity for {partition_name}', fontsize=12)\n",
    "        ax.set_xlabel('Date', fontsize=10)\n",
    "        ax.set_ylabel('Capacity (GB)', fontsize=10)\n",
    "\n",
    "        # Rotate x-axis labels\n",
    "        ax.tick_params(axis='x', rotation=0)#, ha='right')\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "        # Add a grid\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "        # Set the y-axis limit\n",
    "        max_y_partition = max(daily_capacity_requested_partition['TotalRequestedCapacity'].max(), current_configured_capacity)\n",
    "        ax.set_ylim(bottom=0, top=max_y_partition * 1.1)\n",
    "\n",
    "        # Place legend on each subplot\n",
    "        ax.legend(loc='upper left', fontsize=8, frameon=False)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Overall title for the figure\n",
    "    overall_title_suffix = f\" for selected partitions: {', '.join(partitions_to_plot)}\" if partitions else \" for All Partitions\"\n",
    "    fig.suptitle(f'Daily Requested Memory Capacity Per Partition{overall_title_suffix}', fontsize=18, y=1.02) # Adjust y to prevent overlap\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust rect to make space for the suptitle\n",
    "    file_name = f'daily_requested_memory_capacity_per_partition{overall_title_suffix.replace(\" \", \"_\").replace(\",\", \"\").lower()}.png'\n",
    "    # plt.savefig(file_name)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(f\"Plot '{file_name}' saved successfully.\")\n",
    "\n",
    "plot_capacity_daily(df, weeks=104) # Call the function with 104 weeks (2 years) of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_long_waits(df):\n",
    "    '''\n",
    "    Analyzes job wait times and plots a doughnut chart showing the\n",
    "    proportion of jobs that waited more than 4 hours vs. less than or equal to 4 hours.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have a 'Wait' (timedelta) column.\n",
    "    '''\n",
    "    if df.empty:\n",
    "        print(\"Cannot analyze long waits: DataFrame is empty.\")\n",
    "        return 0, 0\n",
    "\n",
    "    # Define the 4-hour threshold\n",
    "    four_hours = pd.Timedelta(hours=4)\n",
    "\n",
    "    # Filter jobs where 'Wait' time is greater than 4 hours\n",
    "    # Ensure 'Wait' column has valid timedelta objects and drop NaNs if any\n",
    "    # Assuming 'Wait' column is already in a timedelta format from preprocess_data\n",
    "    df_clean_wait = df.dropna(subset=['Wait'])\n",
    "\n",
    "    long_wait_jobs = df_clean_wait[df_clean_wait['Wait'] > four_hours]\n",
    "    num_long_waits = len(long_wait_jobs)\n",
    "    total_jobs = len(df_clean_wait)\n",
    "\n",
    "    if total_jobs == 0:\n",
    "        percentage_long_waits = 0\n",
    "    else:\n",
    "        percentage_long_waits = (num_long_waits / total_jobs) * 100\n",
    "\n",
    "    print(f\"\\n--- Job Wait Time Analysis ---\")\n",
    "    print(f\"Total jobs analyzed: {total_jobs}\")\n",
    "    print(f\"Jobs that waited more than 4 hours: {num_long_waits}\")\n",
    "    print(f\"Percentage of jobs waiting > 4 hours: {percentage_long_waits:.2f}%\")\n",
    "\n",
    "    # Prepare data for doughnut chart\n",
    "    # Use pd.cut to categorize wait times\n",
    "    wait_categories = pd.cut(df_clean_wait['Wait'],\n",
    "                             bins=[pd.Timedelta(seconds=0), four_hours, pd.Timedelta.max],\n",
    "                             labels=['<= 4 Hours', '> 4 Hours'],\n",
    "                             right=True,\n",
    "                             include_lowest=True) # Ensure jobs with 0 wait time are included\n",
    "\n",
    "    wait_counts = wait_categories.value_counts().sort_index()\n",
    "\n",
    "    # Define colors for consistency\n",
    "    colors = ['#66b3ff', '#ff9999'] # Light blue for short waits, light red for long waits\n",
    "    # If the order of categories is not consistent, map colors explicitly\n",
    "    # For example: colors = [colors[0] if label == '<= 4 Hours' else colors[1] for label in wait_counts.index]\n",
    "\n",
    "\n",
    "    # Create a Doughnut chart\n",
    "    fig, ax = plt.subplots(figsize=(5, 5)) # Use fig, ax for consistent plotting structure\n",
    "    \n",
    "    # Plot the pie chart wedges\n",
    "    wedges, texts, autotexts = ax.pie(wait_counts,\n",
    "                                      autopct='%1.1f%%',\n",
    "                                      startangle=90,\n",
    "                                      colors=colors,\n",
    "                                      wedgeprops=dict(width=0.3, edgecolor='w')) # Make it a doughnut by setting wedge width\n",
    "\n",
    "    # Draw a circle in the center to make it a doughnut chart\n",
    "    centre_circle = plt.Circle((0,0), 0.70, fc='white')\n",
    "    fig.gca().add_artist(centre_circle)\n",
    "\n",
    "    # Set consistent font sizes for percentages\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_fontsize(12)\n",
    "        autotext.set_color('black') # Ensure text is visible\n",
    "\n",
    "    # Add legend\n",
    "    # Place legend below the plot, consistent with plot_capacity_daily\n",
    "    ax.legend(wedges, wait_counts.index,\n",
    "              title=\"Wait Time Category\",\n",
    "              loc=\"upper center\",\n",
    "              bbox_to_anchor=(0.5, -0.05), # Position below the plot\n",
    "              ncol=len(wait_counts.index), # Arrange items in a single row\n",
    "              fontsize=10,\n",
    "              frameon=False) # No frame around the legend\n",
    "\n",
    "    # Set title with consistent font size\n",
    "    ax.set_title('Distribution of Job Wait Times', fontsize=12)\n",
    "    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "    # Adjust layout to make space for the legend below\n",
    "    plt.tight_layout(rect=[0, 0.1, 0.85, 1]) # Adjust rect to make space for the legend\n",
    "\n",
    "    # plt.savefig('job_wait_time_doughnut_chart.png') # Optional: uncomment to save\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return num_long_waits, percentage_long_waits\n",
    "\n",
    "analyze_long_waits(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_long_waits(df):\n",
    "    '''\n",
    "    Analyzes job wait times and plots a doughnut chart showing the\n",
    "    proportion of jobs in various wait time categories.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have a 'Wait' (timedelta) column.\n",
    "    '''\n",
    "    if df.empty:\n",
    "        print(\"Cannot analyze long waits: DataFrame is empty.\")\n",
    "        return 0, 0\n",
    "\n",
    "    # Define the new granular wait time thresholds\n",
    "    bins = [\n",
    "        pd.Timedelta(seconds=0),\n",
    "        pd.Timedelta(minutes=30),\n",
    "        pd.Timedelta(hours=2),\n",
    "        pd.Timedelta(hours=4),\n",
    "        pd.Timedelta(hours=12),\n",
    "        pd.Timedelta.max # Represents infinity for the last bin\n",
    "    ]\n",
    "    labels = [\n",
    "        '<30 mins',\n",
    "        '>30 mins and <2 hours',\n",
    "        '>2 hours and <4 hours',\n",
    "        '>4 hours and <12 hours',\n",
    "        '>12 hours'\n",
    "    ]\n",
    "\n",
    "    # Filter jobs where 'Wait' time is greater than 4 hours for the specific count\n",
    "    four_hours = pd.Timedelta(hours=4)\n",
    "    df_clean_wait = df.dropna(subset=['Wait'])\n",
    "\n",
    "    long_wait_jobs = df_clean_wait[df_clean_wait['Wait'] > four_hours]\n",
    "    num_long_waits = len(long_wait_jobs)\n",
    "    total_jobs = len(df_clean_wait)\n",
    "\n",
    "    if total_jobs == 0:\n",
    "        percentage_long_waits = 0\n",
    "    else:\n",
    "        percentage_long_waits = (num_long_waits / total_jobs) * 100\n",
    "\n",
    "    print(f\"\\n--- Job Wait Time Analysis ---\")\n",
    "    print(f\"Total jobs analyzed: {total_jobs}\")\n",
    "    print(f\"Jobs that waited more than 4 hours: {num_long_waits}\")\n",
    "    print(f\"Percentage of jobs waiting > 4 hours: {percentage_long_waits:.2f}%\")\n",
    "\n",
    "    # Prepare data for doughnut chart using the new bins and labels\n",
    "    wait_categories = pd.cut(df_clean_wait['Wait'],\n",
    "                             bins=bins,\n",
    "                             labels=labels,\n",
    "                             right=False, # Use right=False to make intervals [lower, upper)\n",
    "                             include_lowest=True)\n",
    "\n",
    "    wait_counts = wait_categories.value_counts().sort_index()\n",
    "\n",
    "    # Define colors for consistency (adjust for 5 categories)\n",
    "    # Using a color map to ensure distinct colors for each segment\n",
    "    colors = plt.cm.tab10.colors[:len(labels)] # Using tab10 colormap, taking first N colors\n",
    "\n",
    "\n",
    "    # Create a Doughnut chart\n",
    "    fig, ax = plt.subplots(figsize=(8, 8)) # Adjusted size for potentially more labels\n",
    "\n",
    "    # Plot the pie chart wedges\n",
    "    wedges, texts, autotexts = ax.pie(wait_counts,\n",
    "                                      autopct='%1.1f%%',\n",
    "                                      startangle=90,\n",
    "                                      colors=colors,\n",
    "                                      wedgeprops=dict(width=0.3, edgecolor='w')) # Make it a doughnut by setting wedge width\n",
    "\n",
    "    # Draw a circle in the center to make it a doughnut chart\n",
    "    centre_circle = plt.Circle((0,0), 0.70, fc='white')\n",
    "    fig.gca().add_artist(centre_circle)\n",
    "\n",
    "    # Set consistent font sizes for percentages\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_fontsize(12)\n",
    "        autotext.set_color('black') # Ensure text is visible\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend(wedges, wait_counts.index,\n",
    "              title=\"Wait Time Category\",\n",
    "              loc=\"upper center\",\n",
    "              bbox_to_anchor=(0.5, -0.05), # Position below the plot\n",
    "              ncol=len(wait_counts.index), # Arrange items in a single row\n",
    "              fontsize=10,\n",
    "              frameon=False) # No frame around the legend\n",
    "\n",
    "    # Set title with consistent font size\n",
    "    ax.set_title('Distribution of Job Wait Times', fontsize=14)\n",
    "    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "    # Adjust layout to make space for the legend below\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 1]) # Adjust rect to make space for the legend\n",
    "\n",
    "    # plt.savefig('job_wait_time_doughnut_chart.png') # Optional: uncomment to save\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return num_long_waits, percentage_long_waits\n",
    "\n",
    "# --- NEW: Analysis and plot for granular wait times ---\n",
    "analyze_long_waits(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0175e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_yearly_partition_long_wait_breakdown(df: pd.DataFrame, partition: str = None):\n",
    "    import math\n",
    "    \"\"\"\n",
    "    Plots the breakdown of jobs with wait times > 4 hours, partitioned by year\n",
    "    and individual partition in subplots. Each subplot shows monthly stacked bars,\n",
    "    where stacks represent different wait time categories. Legends are sorted by\n",
    "    total job count for each wait category within that specific (partition, year) subplot.\n",
    "    Custom y-axis limits are applied based on the year.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed DataFrame containing job data with\n",
    "                           'Start', 'Partition', 'JobID', and 'Wait' columns.\n",
    "        partition (str, optional): If provided, plots only for this specific partition.\n",
    "                                   Defaults to None, plotting all unique partitions.\n",
    "    \"\"\"\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Cannot plot long wait time breakdown: DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    # --- 1. Filter and Categorize Long Wait Jobs ---\n",
    "    df_clean_wait = df.dropna(subset=['Wait', 'Start', 'Partition', 'JobID'])\n",
    "\n",
    "    if df_clean_wait.empty:\n",
    "        print(\"After dropping NaNs, DataFrame is empty for wait time analysis.\")\n",
    "        return\n",
    "\n",
    "    four_hours = pd.Timedelta(hours=4)\n",
    "    long_wait_jobs_df = df_clean_wait[df_clean_wait['Wait'] > four_hours].copy()\n",
    "\n",
    "    if long_wait_jobs_df.empty:\n",
    "        print(\"No jobs found with wait times greater than 4 hours to plot breakdown.\")\n",
    "        return\n",
    "\n",
    "    # Define bins and labels for wait times > 4 hours\n",
    "    wait_bins = [\n",
    "        four_hours,\n",
    "        pd.Timedelta(hours=12),\n",
    "        pd.Timedelta(hours=24),\n",
    "        pd.Timedelta(hours=48),\n",
    "        long_wait_jobs_df['Wait'].max() + pd.Timedelta(seconds=1) # Ensure max value is included\n",
    "    ]\n",
    "    wait_labels = [\n",
    "        '4-12 hours',\n",
    "        '12-24 hours',\n",
    "        '24-48 hours',\n",
    "        '>48 hours'\n",
    "    ]\n",
    "\n",
    "    # Handle cases where max wait time might be less than 48 hours, reducing bins dynamically\n",
    "    effective_bins = [b for b in wait_bins if b <= long_wait_jobs_df['Wait'].max() + pd.Timedelta(seconds=1)]\n",
    "    effective_labels = wait_labels[:len(effective_bins) - 1]\n",
    "\n",
    "    if not effective_labels: # If all long wait times are less than 12 hours (e.g., 4-8 hours)\n",
    "        effective_bins = [four_hours, long_wait_jobs_df['Wait'].max() + pd.Timedelta(seconds=1)]\n",
    "        effective_labels = ['4+ hours']\n",
    "\n",
    "\n",
    "    long_wait_jobs_df['WaitCategory'] = pd.cut(long_wait_jobs_df['Wait'],\n",
    "                                              bins=effective_bins,\n",
    "                                              labels=effective_labels,\n",
    "                                              right=True,\n",
    "                                              include_lowest=True,\n",
    "                                              ordered=True) # Ensure categories are ordered for sorting\n",
    "\n",
    "    long_wait_jobs_df.dropna(subset=['WaitCategory'], inplace=True) # Drop jobs that didn't fit into a category\n",
    "\n",
    "    if long_wait_jobs_df.empty:\n",
    "        print(\"After categorizing wait times, no jobs remain for plotting.\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Preprocessing for Plotting (Year, Month, YearMonth) ---\n",
    "    long_wait_jobs_df['Year'] = long_wait_jobs_df['Start'].dt.year\n",
    "    long_wait_jobs_df['Month'] = long_wait_jobs_df['Start'].dt.month\n",
    "    long_wait_jobs_df['YearMonth'] = long_wait_jobs_df['Start'].dt.to_period('M')\n",
    "\n",
    "    # --- 3. Aggregate Data ---\n",
    "    # Group by YearMonth, Partition, and WaitCategory, then count jobs\n",
    "    # This will be the base data for all subplots\n",
    "    # Add observed=False to suppress the FutureWarning\n",
    "    monthly_partition_wait_counts_raw = long_wait_jobs_df.groupby(\n",
    "        ['YearMonth', 'Partition', 'WaitCategory'], observed=False\n",
    "    )['JobID'].count().unstack(fill_value=0) # Unstack WaitCategory to make them columns\n",
    "\n",
    "    # --- 4. Identify Unique Partitions and Years ---\n",
    "    if partition:\n",
    "        # If a specific partition is provided, filter the long_wait_jobs_df BEFORE getting unique years\n",
    "        long_wait_jobs_df_filtered_by_partition = long_wait_jobs_df[long_wait_jobs_df['Partition'] == partition].copy()\n",
    "        if long_wait_jobs_df_filtered_by_partition.empty:\n",
    "            print(f\"No long wait jobs found for partition '{partition}'.\")\n",
    "            return\n",
    "        unique_partitions_to_plot = [partition]\n",
    "        unique_years = sorted(long_wait_jobs_df_filtered_by_partition['Year'].unique())\n",
    "    else:\n",
    "        # If no specific partition is provided, get unique partitions from the full DataFrame\n",
    "        unique_partitions_to_plot = sorted(long_wait_jobs_df['Partition'].unique())\n",
    "        unique_years = sorted(long_wait_jobs_df['Year'].unique())\n",
    "\n",
    "\n",
    "    if not unique_partitions_to_plot or not unique_years:\n",
    "        print(\"No unique partitions or years found after filtering long wait jobs.\")\n",
    "        return\n",
    "\n",
    "    # --- 5. Subplot Setup ---\n",
    "    num_subplots = len(unique_partitions_to_plot) * len(unique_years)\n",
    "    ncols = min(3, max(1, num_subplots)) # Max 3 columns, at least 1\n",
    "    nrows = math.ceil(num_subplots / ncols)\n",
    "\n",
    "    # Adjust figsize for potential many subplots and legends\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6 * ncols + 5, 6 * nrows), squeeze=False)\n",
    "    axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "    # --- 6. Calculate overall max job count for consistent Y-axis limits (fallback if custom not applied) ---\n",
    "    max_job_count = 0\n",
    "    if not monthly_partition_wait_counts_raw.empty:\n",
    "        # Sum across WaitCategory to get total jobs per YearMonth, Partition\n",
    "        temp_summed = monthly_partition_wait_counts_raw.sum(axis=1)\n",
    "        max_job_count = temp_summed.max()\n",
    "    if max_job_count == 0:\n",
    "        max_job_count = 1 # Avoid division by zero or empty plot range\n",
    "\n",
    "    # --- 7. Iterate through Subplots (Partition by Year) ---\n",
    "    plot_idx = 0\n",
    "    for current_partition in unique_partitions_to_plot: # Use current_partition to avoid shadowing\n",
    "        for year in unique_years:\n",
    "            ax = axes[plot_idx]\n",
    "\n",
    "            # Filter data for the current partition and year\n",
    "            current_year_data = monthly_partition_wait_counts_raw[\n",
    "                monthly_partition_wait_counts_raw.index.get_level_values('YearMonth').map(lambda x: x.year) == year\n",
    "            ]\n",
    "            \n",
    "            # Ensure the partition exists in the current_year_data before attempting .xs()\n",
    "            if current_partition not in current_year_data.index.get_level_values('Partition'):\n",
    "                current_plot_data = pd.DataFrame() # Create an empty DataFrame if partition has no data for the year\n",
    "            else:\n",
    "                current_plot_data = current_year_data.xs(current_partition, level='Partition', drop_level=False)\n",
    "                # Drop the 'Partition' level to make 'YearMonth' the sole index for plotting\n",
    "                current_plot_data = current_plot_data.droplevel('Partition') \n",
    "                # If after droplevel, the dataframe became empty, then set to empty for correct handling\n",
    "                if current_plot_data.empty:\n",
    "                    current_plot_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "            if current_plot_data.empty:\n",
    "                ax.set_title(f'No Long Waits: {current_partition} - {year}', fontsize=12)\n",
    "                ax.axis('off') # Hide axes if no data\n",
    "                plot_idx += 1\n",
    "                continue\n",
    "\n",
    "            # Convert 'YearMonth' PeriodIndex to string for x-axis labels\n",
    "            current_plot_data.index = current_plot_data.index.to_timestamp().strftime('%b') # e.g., Jan, Feb\n",
    "\n",
    "            # Calculate total jobs for each wait category for sorting the legend for THIS subplot\n",
    "            wait_category_totals_subplot = current_plot_data.sum().sort_values(ascending=True)\n",
    "\n",
    "            # Reindex columns to ensure consistent stacking and legend order based on totals\n",
    "            categories_to_plot = wait_category_totals_subplot[wait_category_totals_subplot > 0].index\n",
    "            current_plot_data = current_plot_data[categories_to_plot]\n",
    "\n",
    "            # --- Plotting on the current subplot ---\n",
    "            current_plot_data.plot(kind='bar', stacked=True, ax=ax, cmap='viridis', alpha=0.9)\n",
    "            \n",
    "            # --- Apply Subplot Specific Formatting ---\n",
    "            ax.set_title(f'{current_partition} - {year}', fontsize=14, fontweight='bold')\n",
    "            ax.set_xlabel('Month', fontsize=11)\n",
    "            ax.set_ylabel('Number of Jobs', fontsize=11)\n",
    "            \n",
    "            # --- APPLY CUSTOM Y-AXIS LIMITS BASED ON YEAR (FIXED) ---\n",
    "            if year == 2023: # Changed from \"2023\" to 2023\n",
    "                ax.set_ylim(0, 7500)\n",
    "            elif year == 2024: # Changed from \"2024\" to 2024\n",
    "                ax.set_ylim(0, 20000)\n",
    "            elif year == 2025: # Changed from \"2025\" to 2025\n",
    "                ax.set_ylim(0, 750)\n",
    "            else:\n",
    "                # Fallback to dynamic limit if year is not specified\n",
    "                ax.set_ylim(0, max_job_count * 1.1)\n",
    "\n",
    "            ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "            ax.tick_params(axis='y', labelsize=9)\n",
    "            ax.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "\n",
    "            # --- Update Legend for the current subplot ---\n",
    "            legend_labels = []\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            \n",
    "            sorted_labels_for_legend = [lbl for lbl in wait_category_totals_subplot.index if lbl in labels]\n",
    "            label_to_handle = dict(zip(labels, handles))\n",
    "            sorted_handles = [label_to_handle[lbl] for lbl in sorted_labels_for_legend]\n",
    "\n",
    "\n",
    "            for label in sorted_labels_for_legend:\n",
    "                total_jobs = wait_category_totals_subplot.get(label, 0)\n",
    "                legend_labels.append(f\"{label} ({total_jobs:,})\")\n",
    "\n",
    "            ax.legend(sorted_handles, legend_labels, title='Wait Time Category (Total Jobs)', \n",
    "                      loc='upper left', bbox_to_anchor=(1.02, 1),\n",
    "                      ncol=1,\n",
    "                      fontsize=9,\n",
    "                      frameon=False)\n",
    "            \n",
    "            plot_idx += 1\n",
    "            \n",
    "    # --- Clean up any unused subplots ---\n",
    "    for j in range(plot_idx, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # --- Adjust overall layout ---\n",
    "    fig.suptitle('Monthly Breakdown of Long Wait Times (>4h) by Partition and Year', \n",
    "                 fontsize=18, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.98]) # Adjust layout to make space for suptitle\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "partition = 'gpu'\n",
    "plot_yearly_partition_long_wait_breakdown(df, partition=partition)  # Call the function without a specific partition to plot all partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_long_wait_distribution(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Filters jobs with wait times > 4 hours and plots their distribution across\n",
    "    finer-grained wait time categories as a bar chart.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed DataFrame containing job data with a 'Wait' column.\n",
    "    \"\"\"\n",
    "    df_clean_wait = df.dropna(subset=['Wait'])\n",
    "    four_hours = pd.Timedelta(hours=4)\n",
    "    long_wait_jobs_df = df_clean_wait[df_clean_wait['Wait'] > four_hours].copy()\n",
    "\n",
    "    if long_wait_jobs_df.empty:\n",
    "        print(\"No jobs found with wait times greater than 4 hours to plot detailed distribution.\")\n",
    "        return\n",
    "\n",
    "    # Define bins and labels for wait times > 4 hours\n",
    "    bins = [\n",
    "        four_hours,               # Start from >4 hours\n",
    "        pd.Timedelta(hours=12),\n",
    "        pd.Timedelta(hours=24),\n",
    "        pd.Timedelta(hours=48),\n",
    "        pd.Timedelta.max          # Up to the max wait time\n",
    "    ]\n",
    "    labels = [\n",
    "        '4-12 hours',\n",
    "        '12-24 hours',\n",
    "        '24-48 hours',\n",
    "        '>48 hours'\n",
    "    ]\n",
    "\n",
    "    long_wait_jobs_df['WaitCategory'] = pd.cut(long_wait_jobs_df['Wait'],\n",
    "                                              bins=bins,\n",
    "                                              labels=labels,\n",
    "                                              right=True, # Include the right-most bin edge\n",
    "                                              include_lowest=True) # Include values equal to the lower bound (4 hours)\n",
    "\n",
    "\n",
    "    wait_counts = long_wait_jobs_df['WaitCategory'].value_counts().sort_index()\n",
    "    # Convert series to DataFrame for common_plot\n",
    "    plot_df = wait_counts.reset_index()\n",
    "    plot_df.columns = ['WaitCategory', 'JobCount']\n",
    "    \n",
    "    # Ensure consistent order of categories for plotting\n",
    "    plot_df['WaitCategory'] = pd.Categorical(plot_df['WaitCategory'], categories=labels, ordered=True)\n",
    "    plot_df = plot_df.sort_values('WaitCategory')\n",
    "\n",
    "\n",
    "    print(\"\\n--- Distribution of Jobs with Wait Times > 4 Hours ---\")\n",
    "    common_plot(\n",
    "        df=plot_df,\n",
    "        x='WaitCategory',\n",
    "        y='JobCount',\n",
    "        title='Distribution of Jobs with Wait Times > 4 Hours',\n",
    "        xlabel='Wait Time Category',\n",
    "        ylabel='Number of Jobs',\n",
    "        color='maroon',\n",
    "        kind='bar',\n",
    "        ylim=(0, plot_df['JobCount'].max() * 1.1)\n",
    "    )\n",
    "    \n",
    "# --- NEW: Plotting distribution of jobs with wait times > 4 hours (Bar Chart) ---\n",
    "plot_long_wait_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_long_wait_distribution_D(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Filters jobs with wait times > 4 hours and plots their distribution across\n",
    "    finer-grained wait time categories as a doughnut chart with percentages.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed DataFrame containing job data with a 'Wait' column.\n",
    "    \"\"\"\n",
    "    df_clean_wait = df.dropna(subset=['Wait'])\n",
    "    four_hours = pd.Timedelta(hours=4)\n",
    "    long_wait_jobs_df = df_clean_wait[df_clean_wait['Wait'] > four_hours].copy()\n",
    "\n",
    "    if long_wait_jobs_df.empty:\n",
    "        print(\"No jobs found with wait times greater than 4 hours to plot detailed distribution.\")\n",
    "        return\n",
    "\n",
    "    # Define bins and labels for wait times > 4 hours\n",
    "    bins = [\n",
    "        four_hours,               # Start from >4 hours\n",
    "        pd.Timedelta(hours=12),\n",
    "        pd.Timedelta(hours=24),\n",
    "        pd.Timedelta(hours=48),\n",
    "        pd.Timedelta.max          # Up to the max wait time\n",
    "    ]\n",
    "    labels = [\n",
    "        '4-12 hours',\n",
    "        '12-24 hours',\n",
    "        '24-48 hours',\n",
    "        '>48 hours'\n",
    "    ]\n",
    "\n",
    "    long_wait_jobs_df['WaitCategory'] = pd.cut(long_wait_jobs_df['Wait'],\n",
    "                                              bins=bins,\n",
    "                                              labels=labels,\n",
    "                                              right=True, # Include the right-most bin edge\n",
    "                                              include_lowest=True) # Include values equal to the lower bound (4 hours)\n",
    "\n",
    "\n",
    "    wait_counts = long_wait_jobs_df['WaitCategory'].value_counts().sort_index()\n",
    "\n",
    "    # Define colors for the doughnut chart (adjust for 4 categories)\n",
    "    colors = plt.cm.Set2.colors[:len(labels)] # Using plasma colormap for distinction\n",
    "\n",
    "\n",
    "    print(\"\\n--- Distribution of Jobs with Wait Times > 4 Hours (Doughnut Chart) ---\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    wedges, texts, autotexts = ax.pie(wait_counts,\n",
    "                                      autopct='%1.1f%%',\n",
    "                                      startangle=90,\n",
    "                                      colors=colors,\n",
    "                                      wedgeprops=dict(width=0.3, edgecolor='w'))\n",
    "\n",
    "    centre_circle = plt.Circle((0,0), 0.70, fc='white')\n",
    "    fig.gca().add_artist(centre_circle)\n",
    "\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_fontsize(12)\n",
    "        autotext.set_color('black')\n",
    "\n",
    "    ax.legend(wedges, wait_counts.index,\n",
    "              title=\"Wait Time Category\",\n",
    "              loc=\"upper center\",\n",
    "              bbox_to_anchor=(0.5, -0.05),\n",
    "              ncol=len(wait_counts.index),\n",
    "              fontsize=10,\n",
    "              frameon=False)\n",
    "\n",
    "    ax.set_title('Distribution of Jobs with Wait Times > 4 Hours', fontsize=14)\n",
    "    ax.axis('equal')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "    plt.show()\n",
    "    \n",
    "plot_long_wait_distribution_D(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbfdc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_capacity_cpus_daily(df, weeks=1):\n",
    "    '''\n",
    "    Plot the total available and requested CPU capacity daily.\n",
    "    Total configured capacity is 7296 + 1280 = 9088 CPUs\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Start' (datetime), 'AllocCPUS', and 'User' columns.\n",
    "    - weeks (int): The number of past weeks for which to plot the data. Defaults to 1.\n",
    "    '''\n",
    "    # Filter df for the specified number of weeks\n",
    "    filter_date = pd.Timestamp.now() - pd.DateOffset(weeks=weeks)\n",
    "    df_filtered = df[df['Start'] >= filter_date].copy()\n",
    "\n",
    "    print(f\"Plotting CPU capacity for the last {weeks} weeks\")\n",
    "    print(f\"Total Jobs in the last {weeks} weeks: {len(df_filtered)}\")\n",
    "\n",
    "    # Group by date and calculate total requested CPU capacity\n",
    "    daily_cpu_capacity = df_filtered.groupby(df_filtered['Start'].dt.date).agg(\n",
    "        TotalRequestedCPUs=('AllocCPUS', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Convert 'Start' column in daily_cpu_capacity back to datetime objects for plotting\n",
    "    daily_cpu_capacity['Start'] = pd.to_datetime(daily_cpu_capacity['Start'])\n",
    "\n",
    "    print(daily_cpu_capacity.head())\n",
    "\n",
    "    # Plotting using matplotlib and seaborn for multiple lines on one plot\n",
    "    fig, current_ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Plot requested CPU capacity\n",
    "    sns.lineplot(data=daily_cpu_capacity, x='Start', y='TotalRequestedCPUs',\n",
    "                 label='Total Requested CPUs', color='dodgerblue', linewidth=2, ax=current_ax)\n",
    "\n",
    "    # Total configured CPU capacity\n",
    "    configured_capacity_cpus = 9088\n",
    "    # Plot a horizontal line for the total configured CPU capacity\n",
    "    current_ax.axhline(y=configured_capacity_cpus, color='red', linestyle='--', label=f'Total Configured CPUs ({configured_capacity_cpus})', linewidth=2)\n",
    "\n",
    "    # # Add configured capacity number on the plot above the red horizontal line\n",
    "    # x_min, x_max = current_ax.get_xlim()\n",
    "    # y_text_pos = configured_capacity_cpus + (current_ax.get_ylim()[1] - configured_capacity_cpus) * 0.02\n",
    "    # current_ax.text(x_min + (x_max - x_min) * 0.5, y_text_pos,\n",
    "    #                 f'{configured_capacity_cpus} CPUs',\n",
    "    #                 color='red', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "    # Set title and labels with consistent formatting\n",
    "    current_ax.set_title('Daily Requested vs Configured CPU Capacity', fontsize=16)\n",
    "    current_ax.set_xlabel('Date', fontsize=12)\n",
    "    current_ax.set_ylabel('Capacity (CPUs)', fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels for better readability of dates\n",
    "    current_ax.tick_params(axis='x', rotation=0)\n",
    "    current_ax.tick_params(axis='y', labelsize=10)\n",
    "\n",
    "    # Add a grid for easier reading of values\n",
    "    current_ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Set the y-axis limit based on configured capacity\n",
    "    # current_ax.set_ylim(bottom=0, top=configured_capacity_cpus * 1.05) # Set top slightly above max configured capacity\n",
    "\n",
    "    # Place legend below the plot\n",
    "    current_ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2),\n",
    "                      ncol=1,\n",
    "                      fontsize=10,\n",
    "                      frameon=False)\n",
    "\n",
    "    # Adjust layout to prevent overlapping elements, make space for the legend below\n",
    "    # plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_capacity_cpus_daily(df, weeks=104) # Example for last 104 weeks (2 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f5355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_capacity_cpus_daily(df, weeks=1, requested_cpu_threshold: float = 200000):\n",
    "    '''\n",
    "    Plot the total available and requested CPU capacity daily.\n",
    "    Total configured capacity is 7296 + 1280 = 9088 CPUs\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Start' (datetime), 'AllocCPUS', and 'User' columns.\n",
    "    - weeks (int): The number of past weeks for which to plot the data. Defaults to 1.\n",
    "    - requested_cpu_threshold (float): The maximum allowed TotalRequestedCPUs for a day.\n",
    "                                      Days exceeding this will be dropped.\n",
    "    '''\n",
    "    # Filter df for the specified number of weeks\n",
    "    filter_date = pd.Timestamp.now() - pd.DateOffset(weeks=weeks)\n",
    "    df_filtered = df[df['Start'] >= filter_date].copy()\n",
    "\n",
    "    print(f\"Plotting CPU capacity for the last {weeks} weeks\")\n",
    "    print(f\"Total Jobs in the last {weeks} weeks: {len(df_filtered)}\")\n",
    "\n",
    "    # Group by date and calculate total requested CPU capacity\n",
    "    daily_cpu_capacity = df_filtered.groupby(df_filtered['Start'].dt.date).agg(\n",
    "        TotalRequestedCPUs=('AllocCPUS', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Convert 'Start' column in daily_cpu_capacity back to datetime objects for plotting\n",
    "    daily_cpu_capacity['Start'] = pd.to_datetime(daily_cpu_capacity['Start'])\n",
    "\n",
    "    # Filter out data points where TotalRequestedCPUs is more than the threshold\n",
    "    original_rows = len(daily_cpu_capacity)\n",
    "    daily_cpu_capacity = daily_cpu_capacity[daily_cpu_capacity['TotalRequestedCPUs'] <= requested_cpu_threshold].copy()\n",
    "    filtered_rows = len(daily_cpu_capacity)\n",
    "\n",
    "    if original_rows > filtered_rows:\n",
    "        print(f\"Filtered out {original_rows - filtered_rows} days where TotalRequestedCPUs exceeded {requested_cpu_threshold:.0f} CPUs.\")\n",
    "    else:\n",
    "        print(\"No days filtered based on TotalRequestedCPUs threshold.\")\n",
    "\n",
    "    print(daily_cpu_capacity.head())\n",
    "\n",
    "    # Plotting using matplotlib and seaborn for multiple lines on one plot\n",
    "    fig, current_ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Plot requested CPU capacity\n",
    "    sns.lineplot(data=daily_cpu_capacity, x='Start', y='TotalRequestedCPUs',\n",
    "                 label='Total Requested CPUs', color='dodgerblue', linewidth=2, ax=current_ax)\n",
    "\n",
    "    # Total configured CPU capacity\n",
    "    configured_capacity_cpus = 9088\n",
    "    # Plot a horizontal line for the total configured CPU capacity\n",
    "    current_ax.axhline(y=configured_capacity_cpus, color='red', linestyle='--', label=f'Total Configured CPUs ({configured_capacity_cpus})', linewidth=2)\n",
    "\n",
    "    # Add text label for the horizontal line\n",
    "    text_x_position_cpu = daily_cpu_capacity['Start'].min()\n",
    "    text_y_position_cpu = configured_capacity_cpus * 1.01\n",
    "    current_ax.text(text_x_position_cpu, text_y_position_cpu, f'Configured Capacity: {configured_capacity_cpus} CPUs',\n",
    "                    color='red', fontsize=10, verticalalignment='bottom', horizontalalignment='left',\n",
    "                    bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "\n",
    "    # Set title and labels with consistent formatting\n",
    "    current_ax.set_title('Daily Requested vs Configured CPU Capacity', fontsize=16)\n",
    "    current_ax.set_xlabel('Date', fontsize=12)\n",
    "    current_ax.set_ylabel('Capacity (CPUs)', fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels for better readability of dates\n",
    "    current_ax.tick_params(axis='x', rotation=45) # Use rotation only\n",
    "    current_ax.tick_params(axis='y', labelsize=10)\n",
    "\n",
    "    # Add a grid for easier reading of values\n",
    "    current_ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Set the y-axis limit based on configured capacity and requested data\n",
    "    max_y_cpu = max(daily_cpu_capacity['TotalRequestedCPUs'].max(), configured_capacity_cpus)\n",
    "    current_ax.set_ylim(bottom=0, top=max_y_cpu * 1.1)\n",
    "\n",
    "    # Place legend below the plot\n",
    "    current_ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2),\n",
    "                      ncol=1,\n",
    "                      fontsize=10,\n",
    "                      frameon=False)\n",
    "\n",
    "    # Adjust layout to prevent overlapping elements, make space for the legend below\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_capacity_cpus_daily(df, weeks=104, requested_cpu_threshold=200000) # Example for last 104 weeks (2 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b4d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_capacity_cpus_daily(df: pd.DataFrame, weeks: int = 1, requested_cpu_threshold: float = 20000, partitions: Optional[List[str]] = None):\n",
    "    '''\n",
    "    Plot the total available and requested CPU capacity daily for selected partitions in subplots.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "                         Expected to have 'Start' (datetime), 'AllocCPUS', and 'Partition' columns.\n",
    "    - weeks (int): The number of past weeks for which to plot the data. Defaults to 1.\n",
    "    - requested_cpu_threshold (float): The maximum allowed TotalRequestedCPUs for a day.\n",
    "                                      Days exceeding this will be dropped.\n",
    "    - partitions (Optional[List[str]]): A list of partition names to plot.\n",
    "                                          If None, requested capacity for all *unique* partitions will be plotted\n",
    "                                          in separate subplots.\n",
    "    '''\n",
    "    # Define configured CPU capacity for each known partition\n",
    "    # Based on the sum 7296 + 1280 = 9088 CPUs\n",
    "    partition_configured_capacity_cpus = {\n",
    "        'parallel': 256*28+250/2,   # Example: Assuming 'cpu' partition has this capacity\n",
    "        'gpu': 256*3,    # Example: Assuming 'gpu' partition has this capacity\n",
    "        'longrun': 256*2,  # Example: Assuming 'short' partition has this capacity\n",
    "        'quicktest': 256*4,\n",
    "        'bigmem': 128*4,\n",
    "        # Add other partitions and their capacities as needed.\n",
    "        # A fallback for unknown partitions could be added, e.g., 0 or the total system capacity.\n",
    "    }\n",
    "    # Fallback for partitions not explicitly defined, or a sensible default\n",
    "    default_configured_capacity_cpus = 8052+1280 # Using the sum as a generic fallback if a partition isn't mapped\n",
    "\n",
    "    # Filter df for the specified number of weeks\n",
    "    filter_date = pd.Timestamp.now() - pd.DateOffset(weeks=weeks)\n",
    "    df_filtered_time = df[df['Start'] >= filter_date].copy()\n",
    "\n",
    "    # Determine which partitions to plot\n",
    "    if partitions:\n",
    "        partitions_to_plot = [p for p in partitions if p in df_filtered_time['Partition'].unique()]\n",
    "        if not partitions_to_plot:\n",
    "            print(f\"No data found for the specified partitions: {', '.join(partitions)} in the last {weeks} weeks after time filtering.\")\n",
    "            return\n",
    "    else:\n",
    "        partitions_to_plot = df_filtered_time['Partition'].unique().tolist()\n",
    "        if not partitions_to_plot:\n",
    "            print(f\"No partitions found in the data for the last {weeks} weeks.\")\n",
    "            return\n",
    "\n",
    "    # Set up subplots\n",
    "    num_partitions = len(partitions_to_plot)\n",
    "    if num_partitions == 0:\n",
    "        print(\"No partitions to plot.\")\n",
    "        return\n",
    "\n",
    "    n_cols = min(3, num_partitions) # Max 3 columns\n",
    "    n_rows = (num_partitions + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 8, n_rows * 6), squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Iterate through each partition and create a subplot\n",
    "    for i, partition_name in enumerate(partitions_to_plot):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Get the configured CPU capacity for the current partition, with a fallback\n",
    "        current_configured_capacity_cpus = partition_configured_capacity_cpus.get(partition_name, default_configured_capacity_cpus)\n",
    "\n",
    "        # Filter data for the current partition\n",
    "        df_partition = df_filtered_time[df_filtered_time['Partition'] == partition_name].copy()\n",
    "\n",
    "        if df_partition.empty:\n",
    "            ax.set_title(f'No Data for {partition_name}')\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_ylabel('Capacity (CPUs)')\n",
    "            ax.tick_params(axis='x', rotation=45, ha='right')\n",
    "            ax.text(0.5, 0.5, 'No data', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "            continue\n",
    "\n",
    "        # Group by date and calculate total requested CPU capacity for this partition\n",
    "        daily_cpu_capacity_partition = df_partition.groupby(df_partition['Start'].dt.date)['AllocCPUS'].sum().reset_index(name='TotalRequestedCPUs')\n",
    "        daily_cpu_capacity_partition.rename(columns={'Start': 'Date'}, inplace=True)\n",
    "        daily_cpu_capacity_partition['Date'] = pd.to_datetime(daily_cpu_capacity_partition['Date'])\n",
    "\n",
    "        # Filter out data points where TotalRequestedCPUs is more than the threshold for the current partition\n",
    "        original_rows_part = len(daily_cpu_capacity_partition)\n",
    "        daily_cpu_capacity_partition = daily_cpu_capacity_partition[daily_cpu_capacity_partition['TotalRequestedCPUs'] <= requested_cpu_threshold].copy()\n",
    "        filtered_rows_part = len(daily_cpu_capacity_partition)\n",
    "\n",
    "        if original_rows_part > filtered_rows_part:\n",
    "            print(f\"Filtered out {original_rows_part - filtered_rows_part} days for partition '{partition_name}' where TotalRequestedCPUs exceeded {requested_cpu_threshold:.0f} CPUs.\")\n",
    "\n",
    "        if daily_cpu_capacity_partition.empty:\n",
    "            ax.set_title(f'No Plottable Data for {partition_name}')\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_ylabel('Capacity (CPUs)')\n",
    "            ax.tick_params(axis='x', rotation=0)#, ha='right')\n",
    "            ax.text(0.5, 0.5, 'No plottable data', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "            continue\n",
    "\n",
    "        # Plot requested CPU capacity for the current partition\n",
    "        sns.lineplot(data=daily_cpu_capacity_partition, x='Date', y='TotalRequestedCPUs',\n",
    "                     label=f'Requested CPUs ({partition_name})', linewidth=2, ax=ax)\n",
    "\n",
    "        # Plot a horizontal line for the partition's configured CPU capacity\n",
    "        ax.axhline(y=current_configured_capacity_cpus, color='red', linestyle='--', label=f'Configured Total ({current_configured_capacity_cpus} CPUs)', linewidth=2)\n",
    "\n",
    "        # Add text label for the horizontal line (adjusted for subplot)\n",
    "        text_x_position = daily_cpu_capacity_partition['Date'].min()\n",
    "        text_y_position = current_configured_capacity_cpus * 1.01\n",
    "        ax.text(text_x_position, text_y_position, f'Configured: {current_configured_capacity_cpus} CPUs',\n",
    "                color='red', fontsize=8, verticalalignment='bottom', horizontalalignment='left',\n",
    "                bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "\n",
    "        # Set subplot title and labels\n",
    "        ax.set_title(f'Daily CPU Capacity for {partition_name}', fontsize=12)\n",
    "        ax.set_xlabel('Date', fontsize=10)\n",
    "        ax.set_ylabel('Capacity (CPUs)', fontsize=10)\n",
    "\n",
    "        # Rotate x-axis labels\n",
    "        ax.tick_params(axis='x', rotation=0)#, ha='right')\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "        # Add a grid\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "        # Set the y-axis limit\n",
    "        max_y_partition = max(daily_cpu_capacity_partition['TotalRequestedCPUs'].max(), current_configured_capacity_cpus)\n",
    "        ax.set_ylim(bottom=0, top=max_y_partition * 1.1)\n",
    "\n",
    "        # Place legend on each subplot\n",
    "        ax.legend(loc='upper left', fontsize=8, frameon=False)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Overall title for the figure\n",
    "    overall_title_suffix = f\" for selected partitions: {', '.join(partitions_to_plot)}\" if partitions else \" for All Partitions\"\n",
    "    fig.suptitle(f'Daily Requested CPU Capacity Per Partition{overall_title_suffix}', fontsize=18, y=1.02)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    file_name = f'daily_requested_cpu_capacity_per_partition{overall_title_suffix.replace(\" \", \"_\").replace(\",\", \"\").lower()}.png'\n",
    "    plt.show()\n",
    "    # plt.savefig(file_name)\n",
    "    plt.close()\n",
    "    print(f\"Plot '{file_name}' saved successfully.\")\n",
    "    \n",
    "plot_capacity_cpus_daily(df, weeks=104) # Call the function with 104 weeks (2 years) of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27efb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_usage(df):\n",
    "    '''\n",
    "    Plots the monthly job usage by user account as a stacked area chart.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data,\n",
    "                         expected to have 'YearMonth' and 'Account' columns.\n",
    "    '''\n",
    "    if df.empty:\n",
    "        print(\"Cannot plot monthly usage: DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    # Convert 'Year' and 'Month' to integers and then to a period for easier grouping/plotting\n",
    "    df['Year'] = df['Year'].fillna(0).astype(int) # Handle potential NaN values\n",
    "    df['Month'] = df['Month'].fillna(0).astype(int) # Handle potential NaN values\n",
    "    df['YearMonth'] = pd.to_datetime(df['Year'].astype(str) + '-' + df['Month'].astype(str) + '-01', errors='coerce')\n",
    "\n",
    "    # Drop rows where 'YearMonth' could not be parsed (e.g., if Year or Month was invalid)\n",
    "    df.dropna(subset=['YearMonth'], inplace=True)\n",
    "    \n",
    "    # Filter data for the last two years (assuming current year is 2025 based on sample data)\n",
    "    # Adjust this based on the actual current year when the code is run\n",
    "    current_year = pd.Timestamp.now().year\n",
    "    start_date_two_years_ago = pd.Timestamp(year=current_year - 2, month=pd.Timestamp.now().month, day=1)\n",
    "    df_recent = df[df['YearMonth'] >= start_date_two_years_ago].copy()\n",
    "\n",
    "    # Basic data validation\n",
    "    if 'YearMonth' not in df.columns:\n",
    "        print(\"Error: 'YearMonth' column not found. Please ensure data preprocessing has been run.\")\n",
    "        return\n",
    "    if 'Account' not in df.columns:\n",
    "        print(\"Error: 'Account' column not found. Please ensure data preprocessing has been run.\")\n",
    "        return\n",
    "\n",
    "    # Group by 'YearMonth' and 'Account' to count jobs\n",
    "    monthly_usage = df.groupby(['YearMonth', 'Account']).size().unstack(fill_value=0)\n",
    "\n",
    "    # Convert 'YearMonth' PeriodIndex to string for better x-axis labeling with rotation\n",
    "    monthly_usage.index = monthly_usage.index.astype(str)\n",
    "\n",
    "    fig, current_ax = plt.subplots(figsize=(14, 9)) # Consistent figure size\n",
    "\n",
    "    # Plot as stacked area chart\n",
    "    monthly_usage.plot(kind='area', stacked=True, ax=current_ax, cmap='viridis', alpha=0.8) # Adjusted alpha for visibility\n",
    "\n",
    "    # Apply consistent formatting\n",
    "    current_ax.set_title('Monthly Job Usage by Account', fontsize=16, fontweight='bold')\n",
    "    current_ax.set_xlabel('Month (YYYY-MM)', fontsize=12)\n",
    "    current_ax.set_ylabel('Number of Jobs', fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    current_ax.tick_params(axis='x', rotation=0, labelsize=10)\n",
    "    current_ax.tick_params(axis='y', labelsize=10)\n",
    "\n",
    "    # Add a grid for easier reading of values\n",
    "    current_ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Place legend below the plot, consistent with other plots\n",
    "    current_ax.legend(title='Account', loc='upper center', bbox_to_anchor=(0.5, -0.4),\n",
    "                      ncol=min(4, len(monthly_usage.columns)), # Adjust number of columns based on accounts\n",
    "                      fontsize=10,\n",
    "                      frameon=False) # Remove frame around legend\n",
    "\n",
    "    # Adjust layout to prevent overlapping elements, make space for the legend below\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_monthly_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f06699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_usage(df):\n",
    "    '''\n",
    "    Plots the monthly job usage by user account as a stacked bar chart.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data,\n",
    "                         expected to have 'YearMonth' and 'Account' columns.\n",
    "    '''\n",
    "    if df.empty:\n",
    "        print(\"Cannot plot monthly usage: DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    # Convert 'Year' and 'Month' to integers and then to a period for easier grouping/plotting\n",
    "    df['Year'] = df['Year'].fillna(0).astype(int) # Handle potential NaN values\n",
    "    df['Month'] = df['Month'].fillna(0).astype(int) # Handle potential NaN values\n",
    "    df['YearMonth'] = pd.to_datetime(df['Year'].astype(str) + '-' + df['Month'].astype(str) + '-01', errors='coerce')\n",
    "\n",
    "    # Drop rows where 'YearMonth' could not be parsed (e.g., if Year or Month was invalid)\n",
    "    df.dropna(subset=['YearMonth'], inplace=True)\n",
    "    \n",
    "    # Filter data for the last two years (assuming current year is 2025 based on sample data)\n",
    "    # Adjust this based on the actual current year when the code is run\n",
    "    current_year = pd.Timestamp.now().year\n",
    "    start_date_two_years_ago = pd.Timestamp(year=current_year - 2, month=pd.Timestamp.now().month, day=1)\n",
    "    df_recent = df[df['YearMonth'] >= start_date_two_years_ago].copy()\n",
    "\n",
    "    # Basic data validation\n",
    "    if 'YearMonth' not in df.columns:\n",
    "        print(\"Error: 'YearMonth' column not found. Please ensure data preprocessing has been run.\")\n",
    "        return\n",
    "    if 'Account' not in df.columns:\n",
    "        print(\"Error: 'Account' column not found. Please ensure data preprocessing has been run.\")\n",
    "        return\n",
    "\n",
    "    # Group by 'YearMonth' and 'Account' to count jobs\n",
    "    monthly_usage = df.groupby(['YearMonth', 'Account']).size().unstack(fill_value=0)\n",
    "\n",
    "    # Convert 'YearMonth' PeriodIndex to string for better x-axis labeling with rotation\n",
    "    monthly_usage.index = monthly_usage.index.astype(str)\n",
    "\n",
    "    fig, current_ax = plt.subplots(figsize=(14, 10)) # Consistent figure size\n",
    "\n",
    "    # Use a stacked bar chart instead of a stacked area chart\n",
    "    # Use a different colormap to ensure distinct colors for each account\n",
    "    monthly_usage.plot(kind='bar', stacked=True, ax=current_ax, cmap='tab20_r', alpha=0.9)\n",
    "    \n",
    "    # yscale is log\n",
    "    # current_ax.set_yscale('log')  # Use logarithmic scale for better visibility of smaller values\n",
    "\n",
    "    # Apply consistent formatting\n",
    "    current_ax.set_title('Monthly Job Usage by Account', fontsize=16, fontweight='regular')\n",
    "    current_ax.set_xlabel('Month (YYYY-MM)', fontsize=12)\n",
    "    current_ax.set_ylabel('Number of Jobs', fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    current_ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "    current_ax.tick_params(axis='y', labelsize=10)\n",
    "\n",
    "    # Add a grid for easier reading of values\n",
    "    current_ax.grid(True, linestyle='--', alpha=0.7, axis='y') # Grid on y-axis for bar chart\n",
    "\n",
    "    # Place legend below the plot, consistent with other plots\n",
    "    current_ax.legend(title='Account', loc='upper center', bbox_to_anchor=(0.5, -0.4),\n",
    "                      ncol=min(4, len(monthly_usage.columns)), # Adjust number of columns based on accounts\n",
    "                      fontsize=10,\n",
    "                      frameon=False) # Remove frame around legend\n",
    "\n",
    "    # Adjust layout to prevent overlapping elements, make space for the legend below\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_monthly_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7f26e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_usage(df):\n",
    "    '''\n",
    "    Plots the monthly job usage by user account as a stacked bar chart.\n",
    "    The accounts in the legend are sorted by their total job count in ascending order,\n",
    "    and the legend displays the total job count for each account.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data,\n",
    "                         expected to have 'Year' (int), 'Month' (int), and 'Account' columns.\n",
    "    '''\n",
    "    if df.empty:\n",
    "        print(\"Cannot plot monthly usage: DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    # Convert 'Year' and 'Month' to integers and then to a period for easier grouping/plotting\n",
    "    # Ensure 'Year' and 'Month' are treated as numeric for fillna\n",
    "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(0).astype(int)\n",
    "    df['Month'] = pd.to_numeric(df['Month'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Create 'YearMonth' column\n",
    "    df['YearMonth'] = pd.to_datetime(df['Year'].astype(str) + '-' + df['Month'].astype(str) + '-01', errors='coerce')\n",
    "\n",
    "    # Drop rows where 'YearMonth' could not be parsed (e.g., if Year or Month was invalid)\n",
    "    df.dropna(subset=['YearMonth'], inplace=True)\n",
    "    \n",
    "    # Filter data for the last two years (assuming current year is 2025)\n",
    "    current_year = pd.Timestamp.now().year\n",
    "    start_date_two_years_ago = pd.Timestamp(year=current_year - 2, month=pd.Timestamp.now().month, day=1)\n",
    "    df_recent = df[df['YearMonth'] >= start_date_two_years_ago].copy()\n",
    "\n",
    "    # Basic data validation for filtered DataFrame\n",
    "    if df_recent.empty:\n",
    "        print(\"No recent data available for plotting (last two years).\")\n",
    "        return\n",
    "    if 'YearMonth' not in df_recent.columns:\n",
    "        print(\"Error: 'YearMonth' column not found in recent data. Please ensure data preprocessing has been run.\")\n",
    "        return\n",
    "    if 'Account' not in df_recent.columns:\n",
    "        print(\"Error: 'Account' column not found in recent data. Please ensure data preprocessing has been run.\")\n",
    "        return\n",
    "\n",
    "    # Group by 'YearMonth' and 'Account' to count jobs\n",
    "    monthly_usage = df_recent.groupby(['YearMonth', 'Account']).size().unstack(fill_value=0)\n",
    "\n",
    "    # Calculate the total jobs per account for sorting\n",
    "    account_totals = monthly_usage.sum().sort_values(ascending=True)\n",
    "\n",
    "    # Reindex the columns of monthly_usage based on the sorted totals\n",
    "    monthly_usage = monthly_usage[account_totals.index]\n",
    "\n",
    "    # Convert 'YearMonth' PeriodIndex to string for better x-axis labeling with rotation\n",
    "    monthly_usage.index = monthly_usage.index.strftime('%Y-%m') # Format as YYYY-MM\n",
    "\n",
    "    fig, current_ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "    # Use a stacked bar chart\n",
    "    # Use a reversed tab20 colormap for distinct and professional colors\n",
    "    monthly_usage.plot(kind='bar', stacked=True, ax=current_ax, cmap='tab20_r', alpha=0.9)\n",
    "    \n",
    "    # Apply consistent formatting\n",
    "    current_ax.set_title('Monthly Job Usage by Account (Last Two Years)', fontsize=16, fontweight='bold')\n",
    "    current_ax.set_xlabel('Month (YYYY-MM)', fontsize=12)\n",
    "    current_ax.set_ylabel('Number of Jobs', fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    current_ax.tick_params(axis='x', rotation=90, labelsize=10)\n",
    "    current_ax.tick_params(axis='y', labelsize=10)\n",
    "\n",
    "    # Add a grid for easier reading of values\n",
    "    current_ax.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "\n",
    "    # --- Update Legend to Display Job Counts ---\n",
    "    # Create custom legend handles and labels with counts\n",
    "    legend_labels = []\n",
    "    handles, labels = current_ax.get_legend_handles_labels()\n",
    "    \n",
    "    # Sort handles and labels based on the sorted account_totals\n",
    "    sorted_labels = account_totals.index.tolist()\n",
    "    sorted_handles = [handles[labels.index(lbl)] for lbl in sorted_labels]\n",
    "\n",
    "    for label in sorted_labels:\n",
    "        total_jobs = account_totals[label]\n",
    "        legend_labels.append(f\"{label} ({total_jobs:,})\") # Add comma for thousands separator\n",
    "\n",
    "    current_ax.legend(sorted_handles, legend_labels, title='Account (Total Jobs)', loc='upper center', bbox_to_anchor=(0.5, -0.2),\n",
    "                      ncol=min(4, len(monthly_usage.columns)),\n",
    "                      fontsize=10,\n",
    "                      frameon=False) # Remove frame around legend\n",
    "\n",
    "    # Adjust layout to prevent overlapping elements, make space for the legend below\n",
    "    plt.tight_layout(rect=[0, 0.15, 1, 0.95]) # Adjust rect bottom to give more space for legend\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_monthly_usage(df)  # Call the function to plot monthly usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d09fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_unique_users(df):\n",
    "    '''\n",
    "    Plots the monthly number of unique users by user account as a stacked bar chart.\n",
    "    The accounts in the legend are sorted by their total unique user count in ascending order,\n",
    "    and the legend displays the total unique user count for each account.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data,\n",
    "                         expected to have 'Year' (int), 'Month' (int), 'Account',\n",
    "                         and a 'User' (or similar) column.\n",
    "    '''\n",
    "    if df.empty:\n",
    "        print(\"Cannot plot monthly unique user usage: DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    # --- Data Preprocessing (similar to job usage plot) ---\n",
    "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(0).astype(int)\n",
    "    df['Month'] = pd.to_numeric(df['Month'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    df['YearMonth'] = pd.to_datetime(df['Year'].astype(str) + '-' + df['Month'].astype(str) + '-01', errors='coerce')\n",
    "    df.dropna(subset=['YearMonth'], inplace=True)\n",
    "    \n",
    "    current_year = pd.Timestamp.now().year\n",
    "    start_date_two_years_ago = pd.Timestamp(year=current_year - 2, month=pd.Timestamp.now().month, day=1)\n",
    "    df_recent = df[df['YearMonth'] >= start_date_two_years_ago].copy()\n",
    "\n",
    "    # --- Basic Data Validation ---\n",
    "    if df_recent.empty:\n",
    "        print(\"No recent data available for plotting unique users (last two years).\")\n",
    "        return\n",
    "    if 'YearMonth' not in df_recent.columns:\n",
    "        print(\"Error: 'YearMonth' column not found in recent data. Please ensure data preprocessing has been run.\")\n",
    "        return\n",
    "    if 'Account' not in df_recent.columns:\n",
    "        print(\"Error: 'Account' column not found in recent data. Please ensure data preprocessing has been run.\")\n",
    "        return\n",
    "    if 'User' not in df_recent.columns: # <--- CRITICAL: Check for User column\n",
    "        print(\"Error: 'User' column not found. Cannot plot unique users without user identification.\")\n",
    "        print(\"Please ensure your DataFrame has a 'User' column, or update the code to use the correct user identifier column.\")\n",
    "        return\n",
    "\n",
    "    # --- Key Change: Group by 'User' and count unique users ---\n",
    "    monthly_unique_users = df_recent.groupby(['YearMonth', 'Account'])['User'].nunique().unstack(fill_value=0)\n",
    "\n",
    "    # Calculate total unique users per account for sorting the legend\n",
    "    account_unique_user_totals = monthly_unique_users.sum().sort_values(ascending=True)\n",
    "\n",
    "    # Reindex the columns of monthly_unique_users based on the sorted totals\n",
    "    monthly_unique_users = monthly_unique_users[account_unique_user_totals.index]\n",
    "\n",
    "    # Convert 'YearMonth' to string for better x-axis labeling\n",
    "    monthly_unique_users.index = monthly_unique_users.index.strftime('%Y-%m')\n",
    "\n",
    "    # --- Plotting ---\n",
    "    fig, current_ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "    # Using a reversed 'tab20' colormap for a professional and distinct look\n",
    "    monthly_unique_users.plot(kind='bar', stacked=True, ax=current_ax, cmap='tab20_r', alpha=0.9)\n",
    "    \n",
    "    # --- Apply Consistent Formatting ---\n",
    "    current_ax.set_title('Monthly Unique User Activity by Account (Last Two Years)', fontsize=16, fontweight='bold')\n",
    "    current_ax.set_xlabel('Month (YYYY-MM)', fontsize=12)\n",
    "    current_ax.set_ylabel('Number of Unique Users', fontsize=12) # <--- Updated Y-axis label\n",
    "\n",
    "    current_ax.tick_params(axis='x', rotation=90, labelsize=10)\n",
    "    current_ax.tick_params(axis='y', labelsize=10)\n",
    "    current_ax.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "\n",
    "    # --- Update Legend to Display Unique User Counts ---\n",
    "    legend_labels = []\n",
    "    handles, labels = current_ax.get_legend_handles_labels()\n",
    "    \n",
    "    # Sort handles and labels based on the sorted account_unique_user_totals\n",
    "    sorted_labels = account_unique_user_totals.index.tolist()\n",
    "    sorted_handles = [handles[labels.index(lbl)] for lbl in sorted_labels]\n",
    "\n",
    "    for label in sorted_labels:\n",
    "        total_unique_users = account_unique_user_totals[label]\n",
    "        legend_labels.append(f\"{label} ({total_unique_users:,})\") # Format with thousands separator\n",
    "\n",
    "    current_ax.legend(sorted_handles, legend_labels, title='Account (Total Unique Users)', loc='upper center', bbox_to_anchor=(0.5, -0.2),\n",
    "                      ncol=min(4, len(monthly_unique_users.columns)),\n",
    "                      fontsize=10,\n",
    "                      frameon=False)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.15, 1, 0.95]) # Adjust layout for legend\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_monthly_unique_users(df)  # Call the function to plot monthly unique user usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3bfe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_yearly_unique_users_subplots(df):\n",
    "    '''\n",
    "    Plots the monthly number of unique users by user account for each year\n",
    "    as stacked bar charts in separate subplots. Accounts in each subplot's legend\n",
    "    are sorted by their total unique user count for that specific year,\n",
    "    and the legend displays the total unique user count.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data,\n",
    "                         expected to have 'Year' (int), 'Month' (int), 'Account',\n",
    "                         and a 'User' (or similar) column.\n",
    "    '''\n",
    "    if df.empty:\n",
    "        print(\"Cannot plot yearly unique user usage: DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    # --- Data Preprocessing ---\n",
    "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(0).astype(int)\n",
    "    df['Month'] = pd.to_numeric(df['Month'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    df['YearMonth'] = pd.to_datetime(df['Year'].astype(str) + '-' + df['Month'].astype(str) + '-01', errors='coerce')\n",
    "    df.dropna(subset=['YearMonth'], inplace=True)\n",
    "    \n",
    "    # Filter data for the last two years (or any relevant period if you want all years)\n",
    "    # For year-wise subplots, let's get all years present in the data for flexibility\n",
    "    # You can uncomment the current_year filtering if you only want the most recent years\n",
    "    \n",
    "    # current_year = pd.Timestamp.now().year\n",
    "    # start_date_two_years_ago = pd.Timestamp(year=current_year - 2, month=pd.Timestamp.now().month, day=1)\n",
    "    # df_relevant_years = df[df['YearMonth'] >= start_date_two_years_ago].copy()\n",
    "    \n",
    "    # For plotting all available years in subplots:\n",
    "    df_relevant_years = df.copy()\n",
    "\n",
    "    # --- Basic Data Validation for User ---\n",
    "    if df_relevant_years.empty:\n",
    "        print(\"No relevant data available for plotting unique users.\")\n",
    "        return\n",
    "    if 'User' not in df_relevant_years.columns:\n",
    "        print(\"Error: 'User' column not found. Cannot plot unique users without user identification.\")\n",
    "        print(\"Please ensure your DataFrame has a 'User' column, or update the code to use the correct user identifier column.\")\n",
    "        return\n",
    "    if 'Account' not in df_relevant_years.columns:\n",
    "        print(\"Error: 'Account' column not found.\")\n",
    "        return\n",
    "\n",
    "    # Get unique sorted years for subplot creation\n",
    "    unique_years = sorted(df_relevant_years['Year'].unique())\n",
    "    if not unique_years:\n",
    "        print(\"No valid years found in the DataFrame to plot.\")\n",
    "        return\n",
    "\n",
    "    # Determine subplot grid dimensions\n",
    "    num_years = len(unique_years)\n",
    "    # Adjust cols and rows for better layout (e.g., max 2 or 3 columns)\n",
    "    ncols = min(3, num_years)\n",
    "    nrows = int(np.ceil(num_years / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8 * ncols, 6 * nrows), squeeze=False) # squeeze=False ensures axes is always 2D\n",
    "    axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "    # Determine a common Y-axis limit for better comparison across years\n",
    "    # This involves calculating max unique users across ALL months and accounts for ALL years\n",
    "    max_y_lim = 0\n",
    "    temp_grouped_data = df_relevant_years.groupby(['YearMonth', 'Account'])['User'].nunique().unstack(fill_value=0)\n",
    "    if not temp_grouped_data.empty:\n",
    "        max_y_lim = temp_grouped_data.sum(axis=1).max() # Max of summed unique users per month\n",
    "        if max_y_lim == 0: # Avoid issues if all counts are zero\n",
    "            max_y_lim = 1\n",
    "\n",
    "    for i, year in enumerate(unique_years):\n",
    "        ax = axes[i]\n",
    "        df_year = df_relevant_years[df_relevant_years['Year'] == year].copy()\n",
    "\n",
    "        if df_year.empty:\n",
    "            ax.set_title(f'No Data for {year}', fontsize=14, fontweight='bold')\n",
    "            ax.axis('off') # Hide axes if no data\n",
    "            continue\n",
    "\n",
    "        # Group by 'YearMonth' (which will effectively be just 'Month' for each year) and 'Account'\n",
    "        monthly_unique_users_year = df_year.groupby(['YearMonth', 'Account'])['User'].nunique().unstack(fill_value=0)\n",
    "\n",
    "        # Calculate total unique users per account for sorting the legend for THIS YEAR\n",
    "        account_unique_user_totals_year = monthly_unique_users_year.sum().sort_values(ascending=True)\n",
    "\n",
    "        # Reindex the columns for sorting in the plot\n",
    "        monthly_unique_users_year = monthly_unique_users_year[account_unique_user_totals_year.index]\n",
    "\n",
    "        # Convert 'YearMonth' to string, showing only month for x-axis\n",
    "        monthly_unique_users_year.index = monthly_unique_users_year.index.strftime('%b') # E.g., Jan, Feb\n",
    "\n",
    "        # --- Plotting on the current subplot ---\n",
    "        monthly_unique_users_year.plot(kind='bar', stacked=True, ax=ax, cmap='tab20_r', alpha=0.9)\n",
    "        \n",
    "        # --- Apply Subplot Specific Formatting ---\n",
    "        ax.set_title(f'Unique Users - {year}', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Month', fontsize=11)\n",
    "        ax.set_ylabel('Number of Unique Users', fontsize=11)\n",
    "        ax.set_ylim(0, max_y_lim * 1.1) # Apply consistent Y-axis limit\n",
    "        ax.tick_params(axis='x', rotation=90, labelsize=9)\n",
    "        ax.tick_params(axis='y', labelsize=9)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "\n",
    "        # --- Update Legend for the current subplot ---\n",
    "        legend_labels = []\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        \n",
    "        # Sort handles and labels based on the sorted account_unique_user_totals_year\n",
    "        sorted_labels = account_unique_user_totals_year.index.tolist()\n",
    "        sorted_handles = [handles[labels.index(lbl)] for lbl in sorted_labels]\n",
    "\n",
    "        for label in sorted_labels:\n",
    "            total_unique_users = account_unique_user_totals_year[label]\n",
    "            legend_labels.append(f\"{label} ({total_unique_users:,})\")\n",
    "\n",
    "        ax.legend(sorted_handles, legend_labels, title='Account (Total Unique Users)', \n",
    "                  loc='upper left', bbox_to_anchor=(1.02, 1), # Place legend outside the plot area\n",
    "                  ncol=1, # One column for legend for cleaner look next to subplot\n",
    "                  fontsize=9,\n",
    "                  frameon=False)\n",
    "        \n",
    "    # --- Clean up any unused subplots if num_years is not a perfect multiple of ncols ---\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j]) # Remove empty subplots\n",
    "\n",
    "    # --- Adjust overall layout ---\n",
    "    fig.suptitle('Monthly Unique User Activity by Account - Yearly Breakdown', fontsize=18, fontweight='bold', y=1.02) # Main title\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.98]) # Adjust overall figure layout, leave space for suptitle\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_yearly_unique_users_subplots(df)  # Call the function to plot yearly unique user usage in subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e738eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_total_unique_users_monthly_trend(df: pd.DataFrame):\n",
    "    '''\n",
    "    Plots the total number of unique users per month as a line trend.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The preprocessed DataFrame containing job data,\n",
    "                         expected to have 'Year', 'Month', and 'User' columns.\n",
    "    '''\n",
    "    if df.empty:\n",
    "        print(\"Cannot plot total unique users monthly trend: DataFrame is empty.\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Ensure 'Start' column is datetime type for filtering\n",
    "    df['Start'] = pd.to_datetime(df['Start'])\n",
    "    \n",
    "    # Filter data for the last two years using 'Start' datetime column\n",
    "    current_date = pd.Timestamp.now()\n",
    "    start_date_two_years_ago = pd.Timestamp(year=current_date.year - 2, month=current_date.month, day=1)\n",
    "    df_recent = df[df['Start'] >= start_date_two_years_ago].copy()\n",
    "\n",
    "    if df_recent.empty:\n",
    "        print(\"No recent data available for total unique users monthly trend after filtering for the last 2 years.\")\n",
    "        return\n",
    "\n",
    "    # Group by 'Year' and 'Month' and count unique Users\n",
    "    total_unique_users_monthly = df_recent.groupby(['Year', 'Month'])['User'].nunique().reset_index(name='UniqueUserCount')\n",
    "\n",
    "    # Create a datetime column from 'Year' and 'Month' for plotting\n",
    "    # Explicitly convert 'Year' and 'Month' to int first\n",
    "    total_unique_users_monthly['PlotDate'] = pd.to_datetime(\n",
    "        total_unique_users_monthly['Year'].astype(int).astype(str) + '-' +\n",
    "        total_unique_users_monthly['Month'].astype(int).astype(str) + '-01'\n",
    "    )\n",
    "    print(total_unique_users_monthly.head()) # Debugging line to check the data\n",
    "\n",
    "    fig, current_ax = plt.subplots(figsize=(14, 7)) # Consistent figure size\n",
    "\n",
    "    # Plot as a line chart using common_plot style\n",
    "    common_plot(total_unique_users_monthly, 'PlotDate', 'UniqueUserCount',\n",
    "                'Total Unique Users Per Month (Last 2 Years)', # Updated title for clarity\n",
    "                'Month (YYYY-MM)', 'Number of Unique Users',\n",
    "                color='teal', # Distinct color for this plot\n",
    "                kind='bar',\n",
    "                ax=current_ax)\n",
    "\n",
    "    # # Format x-axis ticks to show month and year clearly\n",
    "    # current_ax.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))\n",
    "    # current_ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "    # current_ax.tick_params(axis='y', labelsize=10)\n",
    "\n",
    "    # Add a grid for easier reading of values\n",
    "    current_ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # super title\n",
    "    fig.suptitle('Total Unique Users Monthly Trend (Last 2 Years)', fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_total_unique_users_monthly_trend(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data for jobs per partition\n",
    "jobs_per_partition = df['Partition'].value_counts().reset_index()\n",
    "jobs_per_partition.columns = ['Partition', 'JobCount']\n",
    "\n",
    "# Plotting jobs per partition\n",
    "common_plot(\n",
    "    df=jobs_per_partition,\n",
    "    x='Partition',\n",
    "    y='JobCount',\n",
    "    title='Number of Jobs per Partition',\n",
    "    xlabel='Partition',\n",
    "    ylabel='Number of Jobs',\n",
    "    color='skyblue',\n",
    "    kind='bar'\n",
    ")\n",
    "\n",
    "# Aggregate data for total allocated CPUs per partition\n",
    "alloc_cpus_per_partition = df.groupby('Partition')['AllocCPUS'].sum().reset_index()\n",
    "alloc_cpus_per_partition.columns = ['Partition', 'TotalAllocCPUs']\n",
    "\n",
    "# Plotting total allocated CPUs per partition\n",
    "common_plot(\n",
    "    df=alloc_cpus_per_partition,\n",
    "    x='Partition',\n",
    "    y='TotalAllocCPUs',\n",
    "    title='Total Allocated CPUs per Partition',\n",
    "    xlabel='Partition',\n",
    "    ylabel='Total Allocated CPUs',\n",
    "    color='lightcoral',\n",
    "    kind='bar'\n",
    ")\n",
    "\n",
    "# Aggregate data for total requested memory per partition\n",
    "req_mem_per_partition = df.groupby('Partition')['ReqMem'].sum().reset_index()\n",
    "req_mem_per_partition.columns = ['Partition', 'TotalReqMem']\n",
    "\n",
    "# Plotting total requested memory per partition\n",
    "common_plot(\n",
    "    df=req_mem_per_partition,\n",
    "    x='Partition',\n",
    "    y='TotalReqMem',\n",
    "    title='Total Requested Memory (MB) per Partition',\n",
    "    xlabel='Partition',\n",
    "    ylabel='Total Requested Memory (MB)',\n",
    "    color='lightgreen',\n",
    "    kind='bar'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53453e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_partition_usage_over_time(df: pd.DataFrame, partition_name: str):\n",
    "    \"\"\"\n",
    "    Plots the usage metrics (number of jobs, total allocated CPUs,\n",
    "    total requested memory) for a specific partition over time, aggregated by month.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "        partition_name (str): The name of the partition to plot.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter data for the specific partition\n",
    "    partition_df = df[df['Partition'] == partition_name].copy()\n",
    "\n",
    "    # Create a 'MonthYear' column for time aggregation\n",
    "    partition_df['MonthYear'] = partition_df['Start'].dt.to_period('M')\n",
    "    \n",
    "    # Convert ReqMem from MB to GB for consistency in memory usage\n",
    "    if 'ReqMem' in partition_df.columns and partition_df['ReqMem'].max() > 2048:\n",
    "        partition_df['ReqMem'] = partition_df['ReqMem'] / 1024  # Convert MB to GB\n",
    "    else:\n",
    "        partition_df['ReqMem'] = partition_df['ReqMem']\n",
    "\n",
    "    # Aggregate data by MonthYear\n",
    "    monthly_usage = partition_df.groupby('MonthYear').agg(\n",
    "        JobCount=('JobID', 'count'),\n",
    "        TotalAllocCPUs=('AllocCPUS', 'sum'),\n",
    "        TotalReqMem=('ReqMem', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Convert 'MonthYear' back to datetime for plotting consistency\n",
    "    monthly_usage['MonthYear'] = monthly_usage['MonthYear'].dt.to_timestamp()\n",
    "\n",
    "    # Plotting Number of Jobs over time for the partition\n",
    "    common_plot(\n",
    "        df=monthly_usage,\n",
    "        x='MonthYear',\n",
    "        y='JobCount',\n",
    "        title=f'Number of Jobs on {partition_name} Partition Over Time',\n",
    "        xlabel='Month',\n",
    "        ylabel='Number of Jobs',\n",
    "        color='blue',\n",
    "        kind='bar',\n",
    "    )\n",
    "\n",
    "    # Plotting Total Allocated CPUs over time for the partition\n",
    "    common_plot(\n",
    "        df=monthly_usage,\n",
    "        x='MonthYear',\n",
    "        y='TotalAllocCPUs',\n",
    "        title=f'Total Allocated CPUs on {partition_name} Partition Over Time',\n",
    "        xlabel='Month',\n",
    "        ylabel='Total Allocated CPUs',\n",
    "        color='orange',\n",
    "        kind='bar',\n",
    "    )\n",
    "\n",
    "    # Plotting Total Requested Memory over time for the partition\n",
    "    common_plot(\n",
    "        df=monthly_usage,\n",
    "        x='MonthYear',\n",
    "        y='TotalReqMem',\n",
    "        title=f'Total Requested Memory (GB) on {partition_name} Partition Over Time',\n",
    "        xlabel='Month',\n",
    "        ylabel='Total Requested Memory (GB)',\n",
    "        color='green',\n",
    "        kind='bar',\n",
    "    )\n",
    "\n",
    "# Example usage:\n",
    "partitions = ['parallel', 'gpu', 'bigmem', 'longrun', 'quicktest']\n",
    "partitions = ['parallel']\n",
    "for partition in partitions:\n",
    "    plot_partition_usage_over_time(df, partition_name=partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107fdaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_yearly_partition_job_usage_subplots(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plots the number of jobs per partition for each year as stacked bar charts in subplots.\n",
    "    Each subplot represents a unique year, with bars stacked by partition.\n",
    "    Legends within each subplot are sorted by total job count for that year's partitions,\n",
    "    and display the total job count for each partition.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed DataFrame containing job data,\n",
    "                           expected to have 'Start' (datetime), 'Partition', and 'JobID' columns.\n",
    "                           'Year' and 'Month' will be derived from 'Start'.\n",
    "    \"\"\"\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Cannot plot partition usage: DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    # --- Data Preprocessing ---\n",
    "    # Ensure 'Start' column is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['Start']):\n",
    "        print(\"Warning: 'Start' column is not datetime. Attempting conversion.\")\n",
    "        df['Start'] = pd.to_datetime(df['Start'], errors='coerce')\n",
    "    \n",
    "    # Drop rows where 'Start' could not be parsed\n",
    "    df.dropna(subset=['Start'], inplace=True)\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"After dropping rows with invalid 'Start' times, the DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    df['Year'] = df['Start'].dt.year\n",
    "    df['Month'] = df['Start'].dt.month\n",
    "    df['YearMonth'] = df['Start'].dt.to_period('M') # Use Period for accurate monthly grouping\n",
    "\n",
    "    # Drop rows with missing critical data AFTER deriving YearMonth\n",
    "    df.dropna(subset=['YearMonth', 'Partition', 'JobID'], inplace=True) \n",
    "\n",
    "    if df.empty:\n",
    "        print(\"After preprocessing and cleaning, the DataFrame is empty for plotting.\")\n",
    "        return\n",
    "    \n",
    "    # For plotting all available years in subplots (no 'last two years' filter here unless desired)\n",
    "    df_relevant_years = df.copy()\n",
    "\n",
    "    # --- Basic Data Validation ---\n",
    "    if 'Partition' not in df_relevant_years.columns:\n",
    "        print(\"Error: 'Partition' column not found. Cannot plot partition usage.\")\n",
    "        return\n",
    "    if 'JobID' not in df_relevant_years.columns:\n",
    "        print(\"Error: 'JobID' column not found. Cannot count jobs.\")\n",
    "        return\n",
    "\n",
    "    # --- Aggregate job counts by YearMonth and Partition ---\n",
    "    # This creates a DataFrame with 'YearMonth' as index and 'Partition' as columns\n",
    "    monthly_partition_jobs = df_relevant_years.groupby(['YearMonth', 'Partition'])['JobID'].count().unstack(fill_value=0)\n",
    "\n",
    "    # Get unique sorted years for subplot creation from the aggregated data's index\n",
    "    unique_years = sorted(monthly_partition_jobs.index.map(lambda x: x.year).unique())\n",
    "    if not unique_years:\n",
    "        print(\"No valid years found in the DataFrame to plot.\")\n",
    "        return\n",
    "\n",
    "    # Determine subplot grid dimensions\n",
    "    num_years = len(unique_years)\n",
    "    ncols = min(3, num_years) # Max 3 columns for subplots for readability\n",
    "    nrows = int(np.ceil(num_years / ncols))\n",
    "\n",
    "    # Adjust figsize to give more room, especially for legends\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6 * ncols + 5, 7 * nrows), squeeze=False)\n",
    "    axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "    # --- Calculate overall max job count for consistent Y-axis limits across all subplots ---\n",
    "    max_job_count = 0\n",
    "    if not monthly_partition_jobs.empty:\n",
    "        # Sum rows (job counts for all partitions for each month) and find the maximum\n",
    "        max_job_count = monthly_partition_jobs.sum(axis=1).max()\n",
    "    if max_job_count == 0:\n",
    "        max_job_count = 1 # Avoid issues with empty or zero data\n",
    "\n",
    "    for i, year in enumerate(unique_years):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Filter monthly_partition_jobs for the current year\n",
    "        monthly_jobs_for_year = monthly_partition_jobs[monthly_partition_jobs.index.map(lambda x: x.year) == year]\n",
    "\n",
    "        if monthly_jobs_for_year.empty:\n",
    "            ax.set_title(f'Job Usage - {year} (No Data)', fontsize=14, fontweight='bold')\n",
    "            ax.axis('off') # Hide axes if no data for the year\n",
    "            continue\n",
    "\n",
    "        # Calculate total jobs per partition for sorting the legend for THIS YEAR\n",
    "        partition_totals_year = monthly_jobs_for_year.sum().sort_values(ascending=True)\n",
    "\n",
    "        # Reindex the columns of monthly_jobs_for_year based on the sorted totals\n",
    "        # This ensures the stacking order and legend order match the sorted totals\n",
    "        # Filter out partitions that might have 0 total jobs for this year to avoid them in legend\n",
    "        partitions_to_plot = partition_totals_year[partition_totals_year > 0].index\n",
    "        monthly_jobs_for_year = monthly_jobs_for_year[partitions_to_plot]\n",
    "\n",
    "\n",
    "        # Convert 'MonthYear' PeriodIndex to string, showing only month for x-axis\n",
    "        # Convert to timestamp first to use strftime for month abbreviation\n",
    "        monthly_jobs_for_year.index = monthly_jobs_for_year.index.to_timestamp().strftime('%b') # E.g., Jan, Feb\n",
    "\n",
    "        # --- Plotting on the current subplot ---\n",
    "        monthly_jobs_for_year.plot(kind='bar', stacked=True, ax=ax, cmap='tab20_r', alpha=0.9)\n",
    "        \n",
    "        # --- Apply Subplot Specific Formatting ---\n",
    "        ax.set_title(f'Job Usage - {year}', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Month', fontsize=11)\n",
    "        ax.set_ylabel('Number of Jobs', fontsize=11)\n",
    "        ax.set_ylim(0, max_job_count * 1.1) # Apply consistent Y-axis limit across all subplots\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "        ax.tick_params(axis='y', labelsize=9)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "        \n",
    "\n",
    "        # --- Update Legend for the current subplot ---\n",
    "        legend_labels = []\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        \n",
    "        # Ensure we only consider labels that actually have data in the current year's plot\n",
    "        # and re-sort them based on partition_totals_year\n",
    "        current_plot_labels_sorted = [lbl for lbl in partition_totals_year.index if lbl in labels]\n",
    "        \n",
    "        # Map labels to their corresponding handles for correct sorting\n",
    "        label_to_handle = dict(zip(labels, handles))\n",
    "        sorted_handles = [label_to_handle[lbl] for lbl in current_plot_labels_sorted]\n",
    "\n",
    "\n",
    "        for label in current_plot_labels_sorted:\n",
    "            total_jobs = partition_totals_year.get(label, 0) # Use .get() for robustness\n",
    "            legend_labels.append(f\"{label} ({total_jobs:,})\")\n",
    "\n",
    "        ax.legend(sorted_handles, legend_labels, title='Partition (Total Jobs)', \n",
    "                  loc='upper left', bbox_to_anchor=(1.02, 1), # Place legend outside the plot area\n",
    "                  ncol=1, # One column for legend for cleaner look next to subplot\n",
    "                  fontsize=9,\n",
    "                  frameon=False)\n",
    "        \n",
    "    # --- Clean up any unused subplots if num_years is not a perfect multiple of ncols ---\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j]) # Remove empty subplots\n",
    "\n",
    "    # --- Adjust overall layout ---\n",
    "    fig.suptitle('Monthly Job Usage by Partition - Yearly Breakdown', fontsize=18, fontweight='bold', y=1.02) # Main title\n",
    "    # Adjust rect to ensure enough space for titles and legends\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.98]) \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_yearly_partition_job_usage_subplots(df)  # Call the function to plot yearly partition job usage in subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c597702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_job_type_usage_over_time(df: pd.DataFrame, metric: str, metric_label: str, time_granularity: str = 'M'):\n",
    "    \"\"\"\n",
    "    Plots the usage of a specified metric over time, separated by 'Single Job' and 'Array Job'.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed DataFrame containing job data with 'JobType' column.\n",
    "        metric (str): The column name for the usage metric to plot (e.g., 'TotalAllocCPUs', 'ReqMem_GB').\n",
    "        metric_label (str): The human-readable label for the metric (e.g., 'Total Allocated CPUs', 'Requested Memory (GB)').\n",
    "        time_granularity (str): The pandas time series frequency for aggregation (e.g., 'M' for monthly).\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure 'MonthYear' column exists for aggregation\n",
    "    df['MonthYear'] = df['Start'].dt.to_period(time_granularity)\n",
    "\n",
    "    job_types = df['JobType'].unique()\n",
    "\n",
    "    for job_type in job_types:\n",
    "        # Filter for the specific job type\n",
    "        job_type_df = df[df['JobType'] == job_type].copy()\n",
    "\n",
    "        # Aggregate data by MonthYear for the current job type\n",
    "        monthly_usage = job_type_df.groupby('MonthYear')[metric].sum().reset_index()\n",
    "\n",
    "        # Convert 'MonthYear' back to datetime for plotting consistency\n",
    "        monthly_usage['MonthYear'] = monthly_usage['MonthYear'].dt.to_timestamp()\n",
    "\n",
    "        # Plotting the metric over time for the current job type\n",
    "        common_plot(\n",
    "            df=monthly_usage,\n",
    "            x='MonthYear',\n",
    "            y=metric,\n",
    "            title=f'{metric_label} for {job_type}s Over Time',\n",
    "            xlabel=f'Time ({time_granularity})',\n",
    "            ylabel=metric_label,\n",
    "            color='purple' if job_type == 'Array Job' else 'teal', # Different colors for clarity\n",
    "            kind='bar'\n",
    "        )\n",
    "\n",
    "# Convert ReqMem from MB to GB for plotting consistency\n",
    "df['ReqMem_GB'] = df['ReqMem'] / 1024\n",
    "# --- NEW: Classify JobType based on JobID string ---\n",
    "# Convert JobID to string to check for substrings\n",
    "df['JobID_str'] = df['JobID'].astype(str)\n",
    "df['JobType'] = df['JobID_str'].apply(lambda x: 'Array Job' if '_' in x or '.' in x else 'Single Job')\n",
    "\n",
    "print(f\"Number of Single Jobs: {df[df['JobType'] == 'Single Job'].shape[0]}\")\n",
    "print(f\"Number of Array Jobs: {df[df['JobType'] == 'Array Job'].shape[0]}\")\n",
    "\n",
    "# Plotting usage for single jobs vs. array jobs\n",
    "# Example: Plotting Total Allocated CPUs over time for each job type\n",
    "plot_job_type_usage_over_time(df, 'AllocCPUS', 'Total Allocated CPUs')\n",
    "\n",
    "# Example: Plotting Total Requested Memory (GB) over time for each job type\n",
    "plot_job_type_usage_over_time(df, 'ReqMem_GB', 'Total Requested Memory (GB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c877a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_yearly_job_type_usage_subplots(df: pd.DataFrame, metric: str, metric_label: str, threshold_value: Optional[float] = None):\n",
    "    \"\"\"\n",
    "    Plots the usage of a specified metric (e.g., allocated CPUs, requested memory)\n",
    "    over time, separated by 'Single Job' and 'Array Job', in year-wise subplots.\n",
    "    Each subplot shows monthly stacked bars. Legends within each subplot are sorted\n",
    "    by the total metric value for each job type in that year, displaying the total.\n",
    "    Optionally, filters out individual data points where the metric value exceeds a given threshold.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed DataFrame containing job data with\n",
    "                           'Start', 'JobType' (derived from JobID), and the specified metric column.\n",
    "        metric (str): The column name for the usage metric to plot (e.g., 'AllocCPUS', 'ReqMem_GB').\n",
    "        metric_label (str): The human-readable label for the metric (e.g., 'Total Allocated CPUs', 'Requested Memory (GB)').\n",
    "        threshold_value (Optional[float]): If provided, individual job records where the 'metric'\n",
    "                                           is greater than this value will be filtered out before aggregation.\n",
    "    \"\"\"\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"Cannot plot yearly job type usage for {metric_label}: DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    # --- Data Preprocessing ---\n",
    "    # Ensure 'Start' column is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['Start']):\n",
    "        print(\"Warning: 'Start' column is not datetime. Attempting conversion.\")\n",
    "        df['Start'] = pd.to_datetime(df['Start'], errors='coerce')\n",
    "    \n",
    "    df.dropna(subset=['Start'], inplace=True) # Drop rows where 'Start' could not be parsed\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"After cleaning invalid 'Start' times, the DataFrame is empty for {metric_label}.\")\n",
    "        return\n",
    "\n",
    "    # Derive Year, Month, YearMonth\n",
    "    df['Year'] = df['Start'].dt.year\n",
    "    df['Month'] = df['Start'].dt.month\n",
    "    df['YearMonth'] = df['Start'].dt.to_period('M') # Use Period for accurate monthly grouping\n",
    "\n",
    "    # Ensure JobType is classified (as per your example usage)\n",
    "    if 'JobID' in df.columns and 'JobType' not in df.columns:\n",
    "        print(\"Classifying 'JobType' based on 'JobID' for plotting.\")\n",
    "        df['JobID_str'] = df['JobID'].astype(str)\n",
    "        df['JobType'] = df['JobID_str'].apply(lambda x: 'Array Job' if '_' in x or '.' in x else 'Single Job')\n",
    "        df.drop(columns=['JobID_str'], inplace=True)\n",
    "    elif 'JobType' not in df.columns:\n",
    "        print(\"Error: 'JobType' column not found and cannot be derived from 'JobID'. Cannot plot.\")\n",
    "        return\n",
    "\n",
    "    # Drop rows with missing critical data AFTER deriving JobType\n",
    "    df.dropna(subset=['YearMonth', 'JobType', metric], inplace=True) \n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"After preprocessing and cleaning, the DataFrame is empty for {metric_label} plotting.\")\n",
    "        return\n",
    "    \n",
    "    df_relevant_years = df.copy() # Use a copy for operations\n",
    "\n",
    "    # --- Apply Threshold Filtering (NEW ADDITION) ---\n",
    "    if threshold_value is not None:\n",
    "        if metric not in df_relevant_years.columns:\n",
    "            print(f\"Error: Metric '{metric}' not found for thresholding. Skipping threshold filter.\")\n",
    "        else:\n",
    "            original_rows_count = len(df_relevant_years)\n",
    "            df_relevant_years = df_relevant_years[df_relevant_years[metric] <= threshold_value].copy()\n",
    "            filtered_rows_count = len(df_relevant_years)\n",
    "            \n",
    "            if original_rows_count > filtered_rows_count:\n",
    "                print(f\"Filtered {original_rows_count - filtered_rows_count} rows ({((original_rows_count - filtered_rows_count) / original_rows_count):.1%}) \"\n",
    "                      f\"where '{metric}' was greater than {threshold_value}.\")\n",
    "            \n",
    "            if df_relevant_years.empty:\n",
    "                print(f\"DataFrame became empty after applying threshold {threshold_value} on '{metric}'. No plot will be generated.\")\n",
    "                return\n",
    "\n",
    "    # --- Aggregate the specified metric by YearMonth and JobType ---\n",
    "    monthly_job_type_metric = df_relevant_years.groupby(['YearMonth', 'JobType'])[metric].sum().unstack(fill_value=0)\n",
    "\n",
    "    # Get unique sorted years for subplot creation\n",
    "    unique_years = sorted(monthly_job_type_metric.index.map(lambda x: x.year).unique())\n",
    "    if not unique_years:\n",
    "        print(\"No valid years found in the DataFrame to plot.\")\n",
    "        return\n",
    "\n",
    "    # Determine subplot grid dimensions\n",
    "    num_years = len(unique_years)\n",
    "    ncols = min(3, num_years)\n",
    "    nrows = int(np.ceil(num_years / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6 * ncols + 5, 7 * nrows), squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # --- Calculate overall max metric value for consistent Y-axis limits across all subplots ---\n",
    "    max_metric_value = 0\n",
    "    if not monthly_job_type_metric.empty:\n",
    "        max_metric_value = monthly_job_type_metric.sum(axis=1).max()\n",
    "    if max_metric_value == 0:\n",
    "        max_metric_value = 1\n",
    "\n",
    "    for i, year in enumerate(unique_years):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        monthly_metric_for_year = monthly_job_type_metric[monthly_job_type_metric.index.map(lambda x: x.year) == year]\n",
    "\n",
    "        if monthly_metric_for_year.empty:\n",
    "            ax.set_title(f'{metric_label} - {year} (No Data)', fontsize=14, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        job_type_totals_year = monthly_metric_for_year.sum().sort_values(ascending=True)\n",
    "\n",
    "        job_types_to_plot = job_type_totals_year[job_type_totals_year > 0].index\n",
    "        monthly_metric_for_year = monthly_metric_for_year[job_types_to_plot]\n",
    "\n",
    "        monthly_metric_for_year.index = monthly_metric_for_year.index.to_timestamp().strftime('%b')\n",
    "\n",
    "        # --- Plotting on the current subplot ---\n",
    "        monthly_metric_for_year.plot(kind='bar', stacked=True, ax=ax, cmap='tab20_r', alpha=0.9)\n",
    "        \n",
    "        # --- Apply Subplot Specific Formatting ---\n",
    "        ax.set_title(f'{metric_label} - {year}', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Month', fontsize=11)\n",
    "        ax.set_ylabel(metric_label, fontsize=11)\n",
    "        ax.set_ylim(0, max_metric_value * 1.1)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "        ax.tick_params(axis='y', labelsize=9)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "\n",
    "        # --- Update Legend for the current subplot ---\n",
    "        legend_labels = []\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        \n",
    "        current_plot_labels_sorted = [lbl for lbl in job_type_totals_year.index if lbl in labels]\n",
    "        \n",
    "        label_to_handle = dict(zip(labels, handles))\n",
    "        sorted_handles = [label_to_handle[lbl] for lbl in current_plot_labels_sorted]\n",
    "\n",
    "        for label in current_plot_labels_sorted:\n",
    "            total_value = job_type_totals_year.get(label, 0)\n",
    "            legend_labels.append(f\"{label} ({total_value:,.0f})\")\n",
    "\n",
    "        ax.legend(sorted_handles, legend_labels, title='Job Type (Total)', \n",
    "                  loc='upper left', bbox_to_anchor=(1.02, 1),\n",
    "                  ncol=1,\n",
    "                  fontsize=9,\n",
    "                  frameon=False)\n",
    "        \n",
    "    # --- Clean up any unused subplots ---\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # --- Adjust overall layout ---\n",
    "    fig.suptitle(f'Monthly {metric_label} by Job Type - Yearly Breakdown', fontsize=18, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.98]) \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "plot_yearly_job_type_usage_subplots(df, 'AllocCPUS', 'Total Allocated CPUs', threshold_value=20000)  # Example with threshold\n",
    "plot_yearly_job_type_usage_subplots(df, 'ReqMem', 'Total Requested Memory (GB)', threshold_value=200000)  # Example with threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b5a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_partition_job_type_usage(df: pd.DataFrame, metric: str, metric_label: str, time_granularity: str = 'M'):\n",
    "    \"\"\"\n",
    "    Plots the usage of a specified metric over time for single and array jobs,\n",
    "    separately for each unique partition.\n",
    "    Excludes partitions containing multiple values (e.g., 'gpu,bigmem') and plots as bar charts.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed DataFrame containing job data with 'JobType' and 'Partition' columns.\n",
    "        metric (str): The column name for the usage metric to plot (e.g., 'TotalAllocCPUs', 'ReqMem_GB').\n",
    "        metric_label (str): The human-readable label for the metric (e.g., 'Total Allocated CPUs', 'Requested Memory (GB)').\n",
    "        time_granularity (str): The pandas time series frequency for aggregation (e.g., 'M' for monthly).\n",
    "    \"\"\"\n",
    "    unique_partitions = df['Partition'].unique()\n",
    "    job_types = df['JobType'].unique()\n",
    "\n",
    "    for partition in unique_partitions:\n",
    "        # Filter out partitions that contain commas or spaces, indicating multiple values\n",
    "        # e.g., \"gpu,bigmem\" or \"partition1 partition2\"\n",
    "        if ',' in partition or ' ' in partition:\n",
    "            print(f\"Skipping multi-value partition: {partition}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n--- Plotting for Partition: {partition} ---\")\n",
    "        partition_df = df[df['Partition'] == partition].copy()\n",
    "\n",
    "        # Ensure 'MonthYear' column exists for aggregation within this partition's data\n",
    "        partition_df['MonthYear'] = partition_df['Start'].dt.to_period(time_granularity)\n",
    "\n",
    "        for job_type in job_types:\n",
    "            # Filter for the specific job type within the current partition\n",
    "            job_type_partition_df = partition_df[partition_df['JobType'] == job_type].copy()\n",
    "\n",
    "            if not job_type_partition_df.empty:\n",
    "                # Aggregate data by MonthYear for the current job type and partition\n",
    "                monthly_usage = job_type_partition_df.groupby('MonthYear')[metric].sum().reset_index()\n",
    "\n",
    "                # Convert 'MonthYear' back to datetime for plotting consistency\n",
    "                monthly_usage['MonthYear'] = monthly_usage['MonthYear'].dt.to_timestamp()\n",
    "\n",
    "                # Plotting the metric over time for the current job type and partition\n",
    "                common_plot(\n",
    "                    df=monthly_usage,\n",
    "                    x='MonthYear',\n",
    "                    y=metric,\n",
    "                    title=f'{metric_label} for {job_type}s on {partition} Over Time',\n",
    "                    xlabel=f'Time ({time_granularity})',\n",
    "                    ylabel=metric_label,\n",
    "                    color='purple' if job_type == 'Array Job' else 'teal', # Consistent colors\n",
    "                    kind='bar' # Changed from 'line' to 'bar' as requested\n",
    "                )\n",
    "            else:\n",
    "                print(f\"No {job_type} data found for partition: {partition}\")\n",
    "\n",
    "                \n",
    "# Convert ReqMem from MB to GB for plotting consistency\n",
    "df['ReqMem_GB'] = df['ReqMem'] / 1024\n",
    "\n",
    "# Classify JobType based on JobID string\n",
    "# Convert JobID to string to check for substrings\n",
    "df['JobID_str'] = df['JobID'].astype(str)\n",
    "df['JobType'] = df['JobID_str'].apply(lambda x: 'Array Job' if '_' in x or '.' in x else 'Single Job')\n",
    "\n",
    "print(f\"Number of Single Jobs: {df[df['JobType'] == 'Single Job'].shape[0]}\")\n",
    "print(f\"Number of Array Jobs: {df[df['JobType'] == 'Array Job'].shape[0]}\")\n",
    "\n",
    "\n",
    "# --- NEW: Plotting usage per partition for single jobs vs. array jobs ---\n",
    "# Example: Plotting Total Allocated CPUs over time for each job type PER PARTITION\n",
    "plot_partition_job_type_usage(df, 'AllocCPUS', 'Total Allocated CPUs')\n",
    "\n",
    "# Example: Plotting Total Requested Memory (GB) over time for each job type PER PARTITION\n",
    "plot_partition_job_type_usage(df, 'ReqMem_GB', 'Total Requested Memory (GB)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cores_requested_per_partition_over_time(df: pd.DataFrame, time_granularity: str = 'M'):\n",
    "    \"\"\"\n",
    "    Plots the number of jobs requesting specific core counts (0-16, 16-32, 32-64, 64-128, and 128+ cores)\n",
    "    over time, for each single-value partition.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "        time_granularity (str): The pandas time series frequency for aggregation (e.g., 'M' for monthly).\n",
    "    \"\"\"\n",
    "    # Define core ranges (bins) and corresponding labels\n",
    "    # Bins are defined such that pd.cut with right=True creates (lower, upper] intervals\n",
    "    core_bins = [0, 16, 32, 64, 128, float('inf')]\n",
    "    core_labels = ['0-16 cores', '16-32 cores', '32-64 cores', '64-128 cores', '128+ cores']\n",
    "\n",
    "    # Categorize jobs by requested cores using the new bins and labels\n",
    "    df['CoreCategory'] = pd.cut(df['ReqCPUS'], bins=core_bins, labels=core_labels, right=True, include_lowest=True)\n",
    "\n",
    "    unique_partitions = df['Partition'].unique()\n",
    "\n",
    "    for partition in unique_partitions:\n",
    "        # Filter out partitions that contain commas or spaces, indicating multiple values\n",
    "        if ',' in partition or ' ' in partition:\n",
    "            print(f\"Skipping multi-value partition for core analysis: {partition}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n--- Plotting Core Request Trends for Partition: {partition} ---\")\n",
    "        partition_df = df[df['Partition'] == partition].copy()\n",
    "\n",
    "        if partition_df.empty:\n",
    "            print(f\"No data for partition: {partition}\")\n",
    "            continue\n",
    "\n",
    "        # Ensure 'MonthYear' column exists for aggregation within this partition's data\n",
    "        partition_df['MonthYear'] = partition_df['Start'].dt.to_period(time_granularity)\n",
    "\n",
    "        # Aggregate job counts by MonthYear and CoreCategory\n",
    "        # Using .unstack() to pivot CoreCategory into columns for easier plotting\n",
    "        core_usage_over_time = partition_df.groupby(['MonthYear', 'CoreCategory']).size().unstack(fill_value=0)\n",
    "        # Convert PeriodIndex to TimestampIndex for plotting with matplotlib/seaborn\n",
    "        core_usage_over_time.index = core_usage_over_time.index.to_timestamp()\n",
    "\n",
    "        # To plot each core category separately using common_plot\n",
    "        # Melt the DataFrame to long format suitable for iterating over categories\n",
    "        plot_df = core_usage_over_time.reset_index().melt(\n",
    "            id_vars='MonthYear',\n",
    "            var_name='CoreCategory',\n",
    "            value_name='JobCount'\n",
    "        )\n",
    "\n",
    "        # Ensure consistent order of CoreCategory in plots\n",
    "        plot_df['CoreCategory'] = pd.Categorical(plot_df['CoreCategory'], categories=core_labels, ordered=True)\n",
    "        plot_df = plot_df.sort_values(['MonthYear', 'CoreCategory'])\n",
    "\n",
    "        # Plot each core category\n",
    "        for core_category in core_labels:\n",
    "            category_df = plot_df[plot_df['CoreCategory'] == core_category].copy()\n",
    "            if not category_df.empty:\n",
    "                common_plot(\n",
    "                    df=category_df,\n",
    "                    x='MonthYear',\n",
    "                    y='JobCount',\n",
    "                    title=f'Jobs Requesting {core_category} on {partition} Over Time',\n",
    "                    xlabel=f'Time ({time_granularity})',\n",
    "                    ylabel='Number of Jobs',\n",
    "                    color=plt.cm.viridis(core_labels.index(core_category) / len(core_labels)), # Dynamic color\n",
    "                    kind='bar' # Plotting as bar chart\n",
    "                )\n",
    "            else:\n",
    "                print(f\"No jobs found for '{core_category}' on partition '{partition}'.\")\n",
    "\n",
    "\n",
    "\n",
    "# --- NEW: Plotting jobs by requested cores per partition over time with updated bins ---\n",
    "plot_cores_requested_per_partition_over_time(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cbe186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def plot_cores_requested_per_partition_over_time(df: pd.DataFrame, time_granularity: str = 'M'):\n",
    "    \"\"\"\n",
    "    Plots the number of jobs requesting specific core counts over time for each partition.\n",
    "    Each figure contains up to 3x3 subplots, each representing a partition and the first year of data.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "        time_granularity (str): The pandas time series frequency for aggregation (e.g., 'M' for monthly).\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"Cannot plot core request breakdown: DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    # --- Robust Date Cleaning and Filtering ---\n",
    "    df_clean = df.copy()\n",
    "    df_clean['Start'] = pd.to_datetime(df_clean['Start'], errors='coerce')\n",
    "    df_clean.dropna(subset=['Start', 'Partition', 'ReqCPUS'], inplace=True)\n",
    "\n",
    "    if df_clean.empty:\n",
    "        print(\"After initial cleaning (NaNs in Start, Partition, ReqCPUS), DataFrame is empty for core request analysis.\")\n",
    "        return\n",
    "\n",
    "    current_year = pd.Timestamp.now().year\n",
    "    df_clean = df_clean[\n",
    "        (df_clean['Start'].dt.year >= 1970) &\n",
    "        (df_clean['Start'].dt.year <= current_year + 1)\n",
    "    ].copy()\n",
    "\n",
    "    if df_clean.empty:\n",
    "        print(\"After filtering 'Start' dates by year range (1970-CurrentYear+1), DataFrame is empty for core request analysis.\")\n",
    "        return\n",
    "    # --- End Robust Date Cleaning ---\n",
    "\n",
    "    # Define core ranges (bins) and corresponding labels\n",
    "    core_bins = [0, 16, 32, 64, 128, float('inf')]\n",
    "    core_labels = ['0-16 cores', '16-32 cores', '32-64 cores', '64-128 cores', '128+ cores']\n",
    "\n",
    "    # Categorize jobs by requested cores using the new bins and labels\n",
    "    df_clean['CoreCategory'] = pd.cut(df_clean['ReqCPUS'], bins=core_bins, labels=core_labels, right=True, include_lowest=True, ordered=True)\n",
    "    df_clean.dropna(subset=['CoreCategory'], inplace=True)\n",
    "\n",
    "    if df_clean.empty:\n",
    "        print(\"After categorizing core requests, no jobs remain for plotting.\")\n",
    "        return\n",
    "\n",
    "    # Ensure 'YearMonth' column exists for aggregation within this partition's data\n",
    "    df_clean['YearMonth'] = df_clean['Start'].dt.to_period(time_granularity)\n",
    "\n",
    "    # Aggregate job counts by Partition, YearMonth and CoreCategory\n",
    "    # Using observed=False for CategoricalDtype to include all categories even if not present in a group\n",
    "    core_usage_over_time = df_clean.groupby(['Partition', 'YearMonth', 'CoreCategory'], observed=False).size().unstack(fill_value=0)\n",
    "\n",
    "    # Get unique partitions, filtering out multi-value or NaN partitions\n",
    "    unique_partitions = []\n",
    "    for p in df_clean['Partition'].unique():\n",
    "        if pd.isna(p) or (isinstance(p, str) and (',' in p or ' ' in p)):\n",
    "            print(f\"Skipping multi-value or invalid partition for core request analysis: {p}\")\n",
    "            continue\n",
    "        unique_partitions.append(p)\n",
    "    unique_partitions = sorted(unique_partitions)\n",
    "\n",
    "    if not unique_partitions:\n",
    "        print(\"No single-value partitions found for plotting core requests.\")\n",
    "        return\n",
    "\n",
    "    # Prepare a list of all (partition, year) combinations that need a subplot\n",
    "    plots_to_generate = []\n",
    "    for partition in unique_partitions:\n",
    "        if partition not in core_usage_over_time.index.get_level_values('Partition'):\n",
    "            continue # Skip if partition has no data after aggregation\n",
    "        partition_data = core_usage_over_time.loc[partition]\n",
    "        unique_years_for_partition = sorted(partition_data.index.get_level_values('YearMonth').year.unique())\n",
    "        for year in unique_years_for_partition:\n",
    "            plots_to_generate.append((partition, year))\n",
    "\n",
    "    if not plots_to_generate:\n",
    "        print(\"No valid (partition, year) combinations found to plot core requests.\")\n",
    "        return\n",
    "\n",
    "    MAX_COLS = 3\n",
    "    MAX_ROWS = 3\n",
    "    SUBPLOTS_PER_FIGURE = MAX_COLS * MAX_ROWS\n",
    "\n",
    "    # Iterate through plots in chunks of SUBPLOTS_PER_FIGURE\n",
    "    for i in range(0, len(plots_to_generate), SUBPLOTS_PER_FIGURE):\n",
    "        current_chunk = plots_to_generate[i:i + SUBPLOTS_PER_FIGURE]\n",
    "        num_plots_in_chunk = len(current_chunk)\n",
    "        current_nrows = math.ceil(num_plots_in_chunk / MAX_COLS)\n",
    "        current_ncols = min(MAX_COLS, num_plots_in_chunk)\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=current_nrows, ncols=current_ncols,\n",
    "                                 figsize=(10 * current_ncols + 2, 6 * current_nrows),\n",
    "                                 squeeze=False)\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for j, (partition, year) in enumerate(current_chunk):\n",
    "            ax = axes[j]\n",
    "            print(f\"Plotting Core Requests: Partition={partition}, Year={year}\")\n",
    "\n",
    "            current_year_data = core_usage_over_time.loc[(partition, slice(None)), :]\n",
    "            current_year_data = current_year_data[current_year_data.index.get_level_values('YearMonth').year == year]\n",
    "\n",
    "            if current_year_data.empty:\n",
    "                ax.set_title(f'No Data: {partition} - {year}', fontsize=12)\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            # Convert YearMonth to string for x-axis labels\n",
    "            current_year_data.index = current_year_data.index.get_level_values('YearMonth').astype(str)\n",
    "\n",
    "            # Ensure all core categories are present as columns, fill missing with 0\n",
    "            current_plot_data = current_year_data.reindex(columns=core_labels, fill_value=0)\n",
    "\n",
    "            # Dynamic Y-axis limit for this subplot\n",
    "            current_subplot_max_y = current_plot_data.sum(axis=1).max()\n",
    "            if current_subplot_max_y == 0:\n",
    "                current_subplot_max_y = 1 # Avoid division by zero if all counts are zero\n",
    "\n",
    "            current_plot_data.plot(kind='bar', stacked=True, ax=ax, colormap='plasma', alpha=0.9)\n",
    "\n",
    "            ax.set_title(f'{partition} - {year}', fontsize=14, fontweight='bold')\n",
    "            ax.set_xlabel('Month', fontsize=11)\n",
    "            ax.set_ylabel('Number of Jobs', fontsize=11)\n",
    "            ax.set_ylim(0, current_subplot_max_y * 1.1) # Dynamic Y-limit\n",
    "            ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "            ax.tick_params(axis='y', labelsize=9)\n",
    "            ax.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "\n",
    "            # Add legend to each subplot\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            # Sort labels according to core_labels order for consistent legend\n",
    "            sorted_labels_for_legend = [lbl for lbl in core_labels if lbl in labels]\n",
    "            label_to_handle = dict(zip(labels, handles))\n",
    "            sorted_handles = [label_to_handle[lbl] for lbl in sorted_labels_for_legend]\n",
    "\n",
    "            legend_labels_with_counts = []\n",
    "            for label in sorted_labels_for_legend:\n",
    "                total_jobs = current_plot_data[label].sum()\n",
    "                legend_labels_with_counts.append(f\"{label} ({total_jobs:,})\")\n",
    "\n",
    "            ax.legend(sorted_handles, legend_labels_with_counts, title='Core Category (Total Jobs)',\n",
    "                      loc='upper right', bbox_to_anchor=(1.3, 1), fontsize=9, frameon=False)\n",
    "\n",
    "        # Hide any unused subplots in the current figure\n",
    "        for k in range(j + 1, len(axes)):\n",
    "            fig.delaxes(axes[k])\n",
    "\n",
    "        fig.suptitle(f'Monthly Breakdown of Core Requests per Partition (Figure {i // SUBPLOTS_PER_FIGURE + 1})',\n",
    "                     fontsize=18, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "        plt.show()\n",
    "\n",
    "    print(\"\\n--- Finished plotting core request trends. ---\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "plot_cores_requested_per_partition_over_time(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5a05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_yearly_partition_long_wait_breakdown(df: pd.DataFrame, partition: str = None):\n",
    "    \"\"\"\n",
    "    Plots the breakdown of jobs with wait times > 4 hours, partitioned by year\n",
    "    and individual partition in subplots. Each subplot shows monthly stacked bars,\n",
    "    where stacks represent different wait time categories. Legends are sorted by\n",
    "    total job count for each wait category within that specific (partition, year) subplot.\n",
    "    Y-axis limits are dynamic for each subplot.\n",
    "    Each figure will contain a maximum of 3x3 subplots, creating new figures as needed.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed DataFrame containing job data with\n",
    "                           'Start', 'Partition', 'JobID', and 'Wait' columns.\n",
    "        partition (str, optional): If provided, plots only for this specific partition.\n",
    "                                   Defaults to None, plotting all unique single-value partitions.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"Cannot plot long wait time breakdown: DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    # --- Robust Date Cleaning and Filtering ---\n",
    "    df_clean_wait = df.copy()\n",
    "    df_clean_wait['Start'] = pd.to_datetime(df_clean_wait['Start'], errors='coerce')\n",
    "    df_clean_wait.dropna(subset=['Wait', 'Start', 'Partition', 'JobID'], inplace=True)\n",
    "\n",
    "    if df_clean_wait.empty:\n",
    "        print(\"After initial cleaning (NaNs in Start, Wait, Partition, JobID), DataFrame is empty for wait time analysis.\")\n",
    "        return\n",
    "\n",
    "    current_year = pd.Timestamp.now().year\n",
    "    df_clean_wait = df_clean_wait[\n",
    "        (df_clean_wait['Start'].dt.year >= 1970) &\n",
    "        (df_clean_wait['Start'].dt.year <= current_year + 1)\n",
    "    ].copy()\n",
    "\n",
    "    if df_clean_wait.empty:\n",
    "        print(\"After filtering 'Start' dates by year range (1970-CurrentYear+1), DataFrame is empty for wait time analysis.\")\n",
    "        return\n",
    "    # --- End Robust Date Cleaning ---\n",
    "\n",
    "    four_hours = pd.Timedelta(hours=4)\n",
    "    long_wait_jobs_df = df_clean_wait[df_clean_wait['Wait'] > four_hours].copy()\n",
    "\n",
    "    if long_wait_jobs_df.empty:\n",
    "        print(\"No jobs found with wait times greater than 4 hours to plot breakdown.\")\n",
    "        return\n",
    "\n",
    "    wait_bins = [\n",
    "        four_hours,\n",
    "        pd.Timedelta(hours=12),\n",
    "        pd.Timedelta(hours=24),\n",
    "        pd.Timedelta(hours=48),\n",
    "        long_wait_jobs_df['Wait'].max() + pd.Timedelta(seconds=1)\n",
    "    ]\n",
    "    wait_labels = [\n",
    "        '4-12 hours',\n",
    "        '12-24 hours',\n",
    "        '24-48 hours',\n",
    "        '>48 hours'\n",
    "    ]\n",
    "\n",
    "    # Handle cases where max wait time might be less than 48 hours, reducing bins dynamically\n",
    "    effective_bins = [b for b in wait_bins if b <= long_wait_jobs_df['Wait'].max() + pd.Timedelta(seconds=1)]\n",
    "    effective_labels = wait_labels[:len(effective_bins) - 1]\n",
    "\n",
    "    if not effective_labels:\n",
    "        effective_bins = [four_hours, long_wait_jobs_df['Wait'].max() + pd.Timedelta(seconds=1)]\n",
    "        effective_labels = ['4+ hours']\n",
    "\n",
    "    long_wait_jobs_df['WaitCategory'] = pd.cut(long_wait_jobs_df['Wait'],\n",
    "                                               bins=effective_bins,\n",
    "                                               labels=effective_labels,\n",
    "                                               right=True,\n",
    "                                               include_lowest=True,\n",
    "                                               ordered=True)\n",
    "\n",
    "    long_wait_jobs_df.dropna(subset=['WaitCategory'], inplace=True)\n",
    "\n",
    "    if long_wait_jobs_df.empty:\n",
    "        print(\"After categorizing wait times, no jobs remain for plotting.\")\n",
    "        return\n",
    "\n",
    "    long_wait_jobs_df['Year'] = long_wait_jobs_df['Start'].dt.year\n",
    "    long_wait_jobs_df['YearMonth'] = long_wait_jobs_df['Start'].dt.to_period('M')\n",
    "\n",
    "    # Aggregate data once\n",
    "    monthly_partition_wait_counts_all = long_wait_jobs_df.groupby(\n",
    "        ['YearMonth', 'Partition', 'WaitCategory'], observed=False\n",
    "    )['JobID'].count().unstack(fill_value=0)\n",
    "\n",
    "    # Determine partitions to plot\n",
    "    if partition:\n",
    "        unique_partitions_to_plot = [p for p in [partition] if p in monthly_partition_wait_counts_all.index.get_level_values('Partition')]\n",
    "        if not unique_partitions_to_plot:\n",
    "            print(f\"Specified partition '{partition}' not found in long wait data or is invalid.\")\n",
    "            return\n",
    "    else:\n",
    "        # Filter for single-value partitions only\n",
    "        all_partitions_in_data = monthly_partition_wait_counts_all.index.get_level_values('Partition').unique()\n",
    "        unique_partitions_to_plot = []\n",
    "        for p in all_partitions_in_data:\n",
    "            if pd.isna(p) or (isinstance(p, str) and (',' in p or ' ' in p)):\n",
    "                print(f\"Skipping multi-value or invalid partition for wait time analysis: {p}\")\n",
    "                continue\n",
    "            unique_partitions_to_plot.append(p)\n",
    "        unique_partitions_to_plot = sorted(unique_partitions_to_plot)\n",
    "        if not unique_partitions_to_plot:\n",
    "            print(\"No single-value partitions found for plotting long wait times.\")\n",
    "            return\n",
    "\n",
    "    # Prepare a list of all (partition, year) combinations that need a subplot\n",
    "    plots_to_generate = []\n",
    "    for current_partition in unique_partitions_to_plot:\n",
    "        partition_data = monthly_partition_wait_counts_all.xs(current_partition, level='Partition', drop_level=False)\n",
    "        if not partition_data.empty:\n",
    "            unique_years_for_partition = sorted(partition_data.index.get_level_values('YearMonth').map(lambda x: x.year).unique())\n",
    "            for year in unique_years_for_partition:\n",
    "                plots_to_generate.append((current_partition, year))\n",
    "\n",
    "    if not plots_to_generate:\n",
    "        print(\"No valid (partition, year) combinations found to plot long wait times.\")\n",
    "        return\n",
    "\n",
    "    MAX_COLS = 3\n",
    "    MAX_ROWS = 3\n",
    "    SUBPLOTS_PER_FIGURE = MAX_COLS * MAX_ROWS\n",
    "\n",
    "    # Iterate through plots in chunks of SUBPLOTS_PER_FIGURE\n",
    "    for i in range(0, len(plots_to_generate), SUBPLOTS_PER_FIGURE):\n",
    "        current_chunk = plots_to_generate[i:i + SUBPLOTS_PER_FIGURE]\n",
    "        num_plots_in_chunk = len(current_chunk)\n",
    "        current_nrows = math.ceil(num_plots_in_chunk / MAX_COLS)\n",
    "        current_ncols = min(MAX_COLS, num_plots_in_chunk)\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=current_nrows, ncols=current_ncols,\n",
    "                                 figsize=(10 * current_ncols + 2, 6 * current_nrows),\n",
    "                                 squeeze=False)\n",
    "        axes = axes.flatten()\n",
    "        for j, (current_partition, year) in enumerate(current_chunk):\n",
    "            ax = axes[j]\n",
    "            print(f\"Plotting Long Waits: Partition={current_partition}, Year={year}\")\n",
    "\n",
    "            current_year_data = monthly_partition_wait_counts_all[\n",
    "                monthly_partition_wait_counts_all.index.get_level_values('YearMonth').map(lambda x: x.year) == year\n",
    "            ]\n",
    "            if current_partition not in current_year_data.index.get_level_values('Partition'):\n",
    "                current_plot_data = pd.DataFrame()\n",
    "            else:\n",
    "                current_plot_data = current_year_data.xs(current_partition, level='Partition', drop_level=False)\n",
    "                current_plot_data = current_plot_data.droplevel('Partition')\n",
    "                if current_plot_data.empty:\n",
    "                    current_plot_data = pd.DataFrame()\n",
    "\n",
    "            if current_plot_data.empty:\n",
    "                ax.set_title(f'No Long Waits: {current_partition} - {year}', fontsize=12)\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            current_plot_data.index = current_plot_data.index.map(lambda x: x.strftime('%b'))\n",
    "\n",
    "            # Dynamic Y-axis limit for this subplot\n",
    "            current_subplot_max_y = current_plot_data.sum(axis=1).max()\n",
    "            if current_subplot_max_y == 0:\n",
    "                current_subplot_max_y = 1  # Avoid division by zero\n",
    "\n",
    "            # Ensure all wait categories are present as columns, fill missing with 0\n",
    "            current_plot_data = current_plot_data.reindex(columns=effective_labels, fill_value=0)\n",
    "            # Sort categories for consistent legend order if desired, here by total count\n",
    "            wait_category_totals_subplot = current_plot_data.sum().sort_values(ascending=True)\n",
    "            categories_to_plot = [lbl for lbl in effective_labels if lbl in wait_category_totals_subplot.index and wait_category_totals_subplot[lbl] > 0]\n",
    "            current_plot_data = current_plot_data[categories_to_plot]  # Reorder columns for plotting\n",
    "\n",
    "            current_plot_data.plot(kind='bar', stacked=True, ax=ax, cmap='viridis', alpha=0.9)\n",
    "            ax.set_title(f'{current_partition} - {year}', fontsize=14, fontweight='bold')\n",
    "            ax.set_xlabel('Month', fontsize=11)\n",
    "            ax.set_ylabel('Number of Jobs', fontsize=11)\n",
    "            ax.set_ylim(0, current_subplot_max_y * 1.1)  # Dynamic Y-limit\n",
    "            ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "            ax.tick_params(axis='y', labelsize=9)\n",
    "            ax.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "\n",
    "            # Add legend to each subplot\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            # Create custom legend labels with total job counts for this subplot\n",
    "            legend_labels_with_counts = []\n",
    "            # Ensure labels are sorted by effective_labels order for consistency, then append count\n",
    "            sorted_labels_for_legend = [lbl for lbl in effective_labels if lbl in labels]\n",
    "            label_to_handle = dict(zip(labels, handles))\n",
    "            sorted_handles = [label_to_handle[lbl] for lbl in sorted_labels_for_legend]\n",
    "\n",
    "            for label in sorted_labels_for_legend:\n",
    "                total_jobs = wait_category_totals_subplot.get(label, 0)\n",
    "                legend_labels_with_counts.append(f\"{label} ({total_jobs:,})\")\n",
    "\n",
    "            ax.legend(sorted_handles, legend_labels_with_counts, title='Wait Time Category (Total Jobs)',\n",
    "                      loc='upper right', bbox_to_anchor=(1.3, 1), fontsize=9, frameon=False)\n",
    "\n",
    "        # Hide any unused subplots in the current figure\n",
    "        for k in range(j + 1, len(axes)):\n",
    "            fig.delaxes(axes[k])\n",
    "\n",
    "        fig.suptitle(f'Monthly Breakdown of Long Wait Times (>4h) (Figure {i // SUBPLOTS_PER_FIGURE + 1})',\n",
    "                     fontsize=18, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "        plt.show()\n",
    "\n",
    "    print(\"\\n--- Finished plotting long wait times. ---\")\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_yearly_partition_long_wait_breakdown(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_core_category_comparison_over_time(df: pd.DataFrame, num_weeks: int = 1):\n",
    "    \"\"\"\n",
    "    Plots the total number of jobs for each core category (0-16, 16-32, etc.)\n",
    "    over a dynamic weekly period (e.g., 1 week, 2 weeks, etc.), allowing comparison across categories.\n",
    "    The data is filtered to include only the last 'num_weeks' from the latest job start date.\n",
    "    The total count for each core group is plotted as a single bar.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed DataFrame containing job data.\n",
    "        num_weeks (int): The number of recent weeks to filter data for.\n",
    "    \"\"\"\n",
    "    # Define core ranges (bins) and corresponding labels\n",
    "    core_bins = [0, 16, 32, 64, 128, float('inf')]\n",
    "    core_labels = ['0-16 cores', '16-32 cores', '32-64 cores', '64-128 cores', '128+ cores']\n",
    "\n",
    "    # Categorize jobs by requested cores\n",
    "    df['CoreCategory'] = pd.cut(df['ReqCPUS'], bins=core_bins, labels=core_labels, right=True, include_lowest=True)\n",
    "\n",
    "    # Determine the latest date in the dataset\n",
    "    latest_date = df['Start'].max()\n",
    "    # Calculate the cutoff date for filtering\n",
    "    cutoff_date = latest_date - pd.Timedelta(weeks=num_weeks)\n",
    "\n",
    "    # Filter data for the specified number of recent weeks\n",
    "    filtered_df = df[df['Start'] >= cutoff_date].copy()\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(f\"No data available for the last {num_weeks} weeks.\")\n",
    "        return\n",
    "\n",
    "    # Aggregate total job counts by CoreCategory for the filtered period\n",
    "    aggregated_data = filtered_df.groupby('CoreCategory').size().reset_index(name='TotalJobCount')\n",
    "\n",
    "    # Ensure consistent order of CoreCategory for plotting\n",
    "    aggregated_data['CoreCategory'] = pd.Categorical(aggregated_data['CoreCategory'], categories=core_labels, ordered=True)\n",
    "    aggregated_data = aggregated_data.sort_values('CoreCategory')\n",
    "\n",
    "    # Plot the total for each core group as a single bar\n",
    "    print(f\"\\n--- Plotting Total Jobs per Core Category for the Last {num_weeks} Weeks ---\")\n",
    "    common_plot(\n",
    "        df=aggregated_data,\n",
    "        x='CoreCategory',\n",
    "        y='TotalJobCount',\n",
    "        title=f'Total Jobs by Core Category (Last {num_weeks} Weeks)',\n",
    "        xlabel='Core Category',\n",
    "        ylabel='Total Number of Jobs',\n",
    "        color='skyblue', # A single color for the comparison bar chart\n",
    "        kind='bar',\n",
    "        ylim=(0, aggregated_data['TotalJobCount'].max() * 1.1) # Set y-limit dynamically based on max count\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Example: Plotting with 4-week periods\n",
    "plot_core_category_comparison_over_time(df, num_weeks=104)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
